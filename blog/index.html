
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Dan Vatterott</title>
  
  <meta name="author" content="Dan Vatterott">
  
  <meta name="description" content="Traditionally, survival functions have been used in medical research to visualize the proportion of people who remain alive following a treatment. I &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://danvatterott.com/blog/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Dan Vatterott" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<!--- MathJax Configuration -->
<script type="text/javascript"
src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js">
</script>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-35559761-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Dan Vatterott</a></h1>
  
    <h2>Data Scientist</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://duckduckgo.com/" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="danvatterott.com">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/about-me/">About Me</a></li>
  <li><a href="/publications/">Publications</a></li>
  <li><a href="/resume/Vatterott_Resume.pdf">Resume</a></li>
  <li><a href="/my-reads/">My Reads</a></li>
  <li><a href="/presentations/">Presentations</a></li>
  <li><a href="/blog/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/12/07/survival-function-in-pyspark/">Creating a Survival Function in PySpark</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-12-07T21:13:48-06:00'><span class='date'><span class='date-month'>Dec</span> <span class='date-day'>7</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>9:13 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Traditionally, <a href="https://en.wikipedia.org/wiki/Survival_function">survival functions</a> have been used in medical research to visualize the proportion of people who remain alive following a treatment. I often use them to understand the length of time between users creating and cancelling their subscription accounts.</p>

<p>Here, I describe how to create a survival function using PySpark. This is not a post about creating a <a href="https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator">Kaplan-Meier estimator</a> or fitting mathematical functions to survival functions. Instead, I demonstrate how to acquire the data necessary for plotting a survival function.</p>

<p>I begin by creating a SparkContext.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
</span><span class="line"><span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="s">&quot;local&quot;</span><span class="p">,</span> <span class="s">&quot;Example&quot;</span><span class="p">)</span>
</span><span class="line"><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Next, I load fake data into a Spark Dataframe. This is the data we will use in this example. Each row is a different user and the Dataframe has columns describing start and end dates for each user. <code>start_date</code> represents when a user created their account and <code>end_date</code> represents when a user canceled their account.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span><span class="line">
</span><span class="line"><span class="n">user_table</span> <span class="o">=</span> <span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="s">&#39;2018-11-01&#39;</span><span class="p">,</span> <span class="s">&#39;2018-11-03&#39;</span><span class="p">],</span>
</span><span class="line">                              <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="s">&#39;2018-01-01&#39;</span><span class="p">,</span> <span class="s">&#39;2018-08-17&#39;</span><span class="p">],</span>
</span><span class="line">                              <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s">&#39;2017-12-31&#39;</span><span class="p">,</span> <span class="s">&#39;2018-01-06&#39;</span><span class="p">],</span>
</span><span class="line">                              <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="s">&#39;2018-11-15&#39;</span><span class="p">,</span> <span class="s">&#39;2018-11-16&#39;</span><span class="p">],</span>
</span><span class="line">                              <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="s">&#39;2018-04-02&#39;</span><span class="p">,</span> <span class="s">&#39;2018-04-12&#39;</span><span class="p">]])</span>
</span><span class="line">              <span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;start_date&#39;</span><span class="p">,</span> <span class="s">&#39;end_date&#39;</span><span class="p">])</span>
</span><span class="line">             <span class="p">)</span>
</span><span class="line"><span class="n">user_table</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>start_date</th>
   <th>end_date</th>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
 </tr>
 <tr>
   <td>2</td>
   <td>2018-01-01</td>
   <td>2018-08-17</td>
 </tr>
 <tr>
   <td>3</td>
   <td>2017-12-31</td>
   <td>2018-01-06</td>
 </tr>
 <tr>
   <td>4</td>
   <td>2018-11-15</td>
   <td>2018-11-16</td>
 </tr>
 <tr>
   <td>5</td>
   <td>2018-04-02</td>
   <td>2018-04-12</td>
 </tr>
</table>

<p>I use <code>start_date</code> and <code>end_date</code> to determine how many days each user was active following their <code>start_date</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">days_till_cancel</span> <span class="o">=</span> <span class="p">(</span><span class="n">user_table</span>
</span><span class="line">                    <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;days_till_cancel&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">datediff</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;end_date&#39;</span><span class="p">),</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;start_date&#39;</span><span class="p">)))</span>
</span><span class="line">                   <span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">days_till_cancel</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>start_date</th>
   <th>end_date</th>
   <th>days_till_cancel</th>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
 </tr>
 <tr>
   <td>2</td>
   <td>2018-01-01</td>
   <td>2018-08-17</td>
   <td>228</td>
 </tr>
 <tr>
   <td>3</td>
   <td>2017-12-31</td>
   <td>2018-01-06</td>
   <td>6</td>
 </tr>
 <tr>
   <td>4</td>
   <td>2018-11-15</td>
   <td>2018-11-16</td>
   <td>1</td>
 </tr>
 <tr>
   <td>5</td>
   <td>2018-04-02</td>
   <td>2018-04-12</td>
   <td>10</td>
 </tr>
</table>

<p>I use a <a href="https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#pyspark.sql.functions.udf">Python UDF</a> to create a vector of the numbers 0 through 13 representing our <em>period of interest</em>. The start date of our <em>period of interest</em> is a user’s <code>start_date</code>. The end date of our <em>period of interest</em> is 13 days following a user’s <code>start_date</code>. I chose 13 days as the <em>period of interest</em> for no particular reason.</p>

<p>I use <a href="https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#pyspark.sql.functions.explode">explode</a> to expand the numbers in each vector (i.e., 0-&gt;13) into different rows. Each user now has a row for each day in the <em>period of interest</em>.</p>

<p>I describe one user’s data below.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">create_day_list</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">udf</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">)],</span> <span class="n">T</span><span class="o">.</span><span class="n">ArrayType</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">()))</span>
</span><span class="line">
</span><span class="line"><span class="n">relevant_days</span> <span class="o">=</span> <span class="p">(</span><span class="n">days_till_cancel</span>
</span><span class="line">                 <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;day_list&#39;</span><span class="p">,</span> <span class="n">create_day_list</span><span class="p">())</span>
</span><span class="line">                 <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;day&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;day_list&#39;</span><span class="p">)))</span>
</span><span class="line">                 <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s">&#39;day_list&#39;</span><span class="p">)</span>
</span><span class="line">                <span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">relevant_days</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>start_date</th>
   <th>end_date</th>
   <th>days_till_cancel</th>
   <th>day</th>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>1</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>2</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>3</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>4</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>5</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>6</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>7</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>8</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>9</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>10</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>11</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>12</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>13</td>
 </tr>
</table>

<p>We want the proportion of users who are active <em>X</em> days after <code>start_date</code>. I create a column <code>active</code> which represents whether users are active or not. I initially assign each user a 1 in each row (1 represents active). I then overwrite 1s with 0s after a user is no longer active. I determine that a user is no longer active by comparing the values in <code>day</code> and <code>days_till_cancel</code>. When <code>day</code> is greater than <code>days_till_cancel</code>, the user is no longer active.</p>

<p>I describe one user’s data below.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">days_active</span> <span class="o">=</span> <span class="p">(</span><span class="n">relevant_days</span>
</span><span class="line">               <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;active&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lit</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span><span class="line">               <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;active&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;day&#39;</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;days_till_cancel&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">otherwise</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;active&#39;</span><span class="p">)))</span>
</span><span class="line">              <span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">days_active</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>start_date</th>
   <th>end_date</th>
   <th>days_till_cancel</th>
   <th>day</th>
   <th>active</th>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>0</td>
   <td>1</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>1</td>
   <td>1</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>2</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>3</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>4</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>5</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>6</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>7</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>8</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>9</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>10</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>11</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>12</td>
   <td>0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2018-11-01</td>
   <td>2018-11-03</td>
   <td>2</td>
   <td>13</td>
   <td>0</td>
 </tr>
</table>

<p>Finally, to acquire the survival function data, I group by <code>day</code> (days following <code>start_date</code>) and average the value in <code>active</code>. This provides us with the proportion of users who are active <em>X</em> days after <code>start_date</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">survival_curve</span> <span class="o">=</span> <span class="p">(</span><span class="n">days_active</span>
</span><span class="line">                  <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">&#39;day&#39;</span><span class="p">)</span>
</span><span class="line">                  <span class="o">.</span><span class="n">agg</span><span class="p">(</span>
</span><span class="line">                      <span class="n">F</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s">&#39;*&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&#39;user_count&#39;</span><span class="p">),</span>
</span><span class="line">                      <span class="n">F</span><span class="o">.</span><span class="n">avg</span><span class="p">(</span><span class="s">&#39;active&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&#39;percent_active&#39;</span><span class="p">),</span>
</span><span class="line">                  <span class="p">)</span>
</span><span class="line">                  <span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s">&#39;day&#39;</span><span class="p">)</span>
</span><span class="line">                 <span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">survival_curve</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>day</th>
   <th>user_count</th>
   <th>percent_active</th>
 </tr>
 <tr>
   <td>0</td>
   <td>5</td>
   <td>1.0</td>
 </tr>
 <tr>
   <td>1</td>
   <td>5</td>
   <td>0.8</td>
 </tr>
 <tr>
   <td>2</td>
   <td>5</td>
   <td>0.6</td>
 </tr>
 <tr>
   <td>3</td>
   <td>5</td>
   <td>0.6</td>
 </tr>
 <tr>
   <td>4</td>
   <td>5</td>
   <td>0.6</td>
 </tr>
 <tr>
   <td>5</td>
   <td>5</td>
   <td>0.6</td>
 </tr>
 <tr>
   <td>6</td>
   <td>5</td>
   <td>0.4</td>
 </tr>
 <tr>
   <td>7</td>
   <td>5</td>
   <td>0.4</td>
 </tr>
 <tr>
   <td>8</td>
   <td>5</td>
   <td>0.4</td>
 </tr>
 <tr>
   <td>9</td>
   <td>5</td>
   <td>0.4</td>
 </tr>
 <tr>
   <td>10</td>
   <td>5</td>
   <td>0.2</td>
 </tr>
 <tr>
   <td>11</td>
   <td>5</td>
   <td>0.2</td>
 </tr>
 <tr>
   <td>12</td>
   <td>5</td>
   <td>0.2</td>
 </tr>
 <tr>
   <td>13</td>
   <td>5</td>
   <td>0.2</td>
 </tr>
</table>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/11/03/looking-towards-the-future-of-automated-machine-learning/">Looking Towards the Future of Automated Machine-learning</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-11-03T08:27:07-05:00'><span class='date'><span class='date-month'>Nov</span> <span class='date-day'>3</span><span class='date-suffix'>rd</span>, <span class='date-year'>2018</span></span> <span class='time'>8:27 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I recently gave a <a href="https://vencafstl.org/event/where-automated-machine-learning-fits-in-your-data-science-toolbox-prepare-ai">presentation</a> at <a href="https://vencafstl.org/">Venture Cafe</a> describing how I see automation changing python, machine-learning workflows in the near future.</p>

<p>In this post, I highlight the presentation’s main points. You can find the slides <a href="https://danvatterott.com/presentations/automation_presentation/">here</a>.</p>

<p>From <a href="https://en.wikipedia.org/wiki/Ray_Kurzweil">Ray Kurzweil’s</a> excitement about a <a href="https://en.wikipedia.org/wiki/Technological_singularity">technological singularity</a> to Elon Musk’s warnings about an <a href="https://www.vanityfair.com/news/2017/03/elon-musk-billion-dollar-crusade-to-stop-ai-space-x">A.I. Apocalypse</a>, automated machine-learning evokes strong feelings. Neither of these futures will be true in the near-term, but where will automation fit in your machine-learning workflows?</p>

<p>Our existing machine-learning workflows might look a little like the following (please forgive the drastic oversimplification of a purely sequential progression across stages!).</p>

<p><img src="/presentations/automation_presentation/slides/data_science_pipeline/ds_pipeline.png" style="background-color:white;" /></p>

<p>Where does automation exist in this workflow? Where can automation improve this workflow?</p>

<p>Not all these stages are within the scope of machine-learning. For instance, while you should automate gathering data, I view this as a data engineering problem. In the image below, I depict the stages that I consider ripe for automation, and the stages I consider wrong for automation. For example, data cleaning is too idiosyncratic to each dataset for true automation. I “X” out model evaluation as wrong for automation. In retrospect, I believe this is a great place for automation, but I don’t know of any existing python packages handling it.</p>

<p><img src="/presentations/automation_presentation/slides/libraries_pipeline/tpot_pipeline.png" style="background-color:white;" /></p>

<p>I depict feature engineering and model selection as the most promising areas for automation. I consider feature engineering as the stage where advances in automation can have the largest impact on your model performance. In the presentation, I include a <a href="https://www.quora.com/What-generally-improves-a-models-score-more-on-average-feature-engineering-or-hyperparameter-tuning">strong quote</a> from a Quora user saying that <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">hyper-parameter tuning</a> (a part of model selection) “hardly matters at all.” I agree with the sentiment of this quote, but it’s not true. Choosing roughly the correct hyper-parameter values is <em>VERY</em> important, and choosing the very best hyper-parameter values can be equally important depending on how your model is used. I highlight feature engineering over model selection because automated model selection is largely solved. For example <a href="http://scikit-learn.org/stable/modules/grid_search.html">grid-search</a> automates model selection. It’s not a fast solution, but given infinite time, it will find the best hyper-parameter values!</p>

<p>There are many python libraries automating these parts of the workflow. I highlight three libraries that automate feature engineering.</p>

<p><img src="/presentations/automation_presentation/slides/feature_automation/tpot-logo.jpg" width="200" style="background-color:white;" /></p>

<p>The first is <a href="https://github.com/EpistasisLab/tpot">teapot</a>. Teapot (more or less) takes all the different operations and models available in <a href="http://scikit-learn.org/stable/">scikit-learn</a>, and allows you to assemble these operations into a pipeline. Many of these operations (e.g., <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a>) are forms of feature engineering. Teapot measures which operations lead to the best model performance. Because Teapot enables users to assemble <em>SO MANY</em> different operations, it utilizes a <a href="https://en.wikipedia.org/wiki/Genetic_algorithm">genetic search algorithm</a> to search through the different possibilities more efficiently than grid-search would.</p>

<p>The second is <a href="https://github.com/ClimbsRocks/auto_ml">auto_ml</a>. In auto_ml users simply pass a dataset to the software and it will do model selection and hyper-parameter tuning for you. Users can also <a href="https://auto-ml.readthedocs.io/en/latest/deep_learning.html#feature-learning">ask the software to train a deep learning model that will learn new features</a> from your dataset. The authors claim this approach can improve model accuracy by 5%.</p>

<p><img src="/presentations/automation_presentation/slides/feature_automation/featuretools.png" width="400" style="background-color:white;" /></p>

<p>The third is <a href="https://github.com/Featuretools/featuretools">feature tools</a>. Feature Tools is the piece of automation software whose future I am most excited about. I find this software exciting because users can feed it pre-aggregated data. Most machine-learning models expect that for each value of the <a href="https://www.quora.com/What-is-a-response-variable-in-statistics">response variable</a>, you supply a vector of explanatory variables. This is an example of aggregated data. Teapot and auto_ml both expect users to supply aggregated data. Lots of important information is lost in the aggregation process, and allowing automation to thoroughly explore different aggregations will lead to predictive features that we would not have created otherwise (any many believe this is why deep learning is so effective). Feature tools explores different aggregations all while creating easily interpreted variables (in contrast to deep learning). While I am excited about the future of feature tools, it is a new piece of software and has a ways to go before I use it in my workflows. Like most automation machine-learning software it’s very slow/resource intensive. Also, the software is not very intuitive. That said, I created a <a href="https://mybinder.org/v2/gh/dvatterott/explore_feature_automation/master">binder notebook</a> demoing feature tools, so check it out yourself!</p>

<p>We should always keep in mind the possible dangers of automation and machine-learning. Removing humans from decisions accentuates biases baked into data and algorithms. These accentuated biases can have dangerous effects. We should carefully choose which decisions we’re comfortable automating and what safeguards to build around these decisions. Check out <a href="https://en.wikipedia.org/wiki/Cathy_O%27Neil">Cathy O’Neil’s</a> amazing <a href="https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction">Weapons for Math Destruction</a> for an excellent treatment of the topic.</p>

<p>This post makes no attempt to give an exhaustive view of automated machine-learning. This is my single view point on where I think automated machine-learning can have an impact on your python workflows in the near-term. For a more thorough view of automated machine-learning, check out this <a href="https://twitter.com/randal_olson/status/992105498894831616">presentation</a> by <a href="http://www.randalolson.com/">Randy Olson</a> (the creator of teapot).</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/09/06/python-aggregate-udfs-in-pyspark/">Python Aggregate UDFs in PySpark</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-09-06T16:04:43-05:00'><span class='date'><span class='date-month'>Sep</span> <span class='date-day'>6</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>4:04 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>PySpark has a great set of <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.agg">aggregate</a> functions (e.g., <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.GroupedData">count, countDistinct, min, max, avg, sum</a>), but these are not enough for all cases (particularly if you’re trying to avoid costly Shuffle operations).</p>

<p>PySpark currently has <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.pandas_udf">pandas_udfs</a>, which can create custom aggregators, but you can only “apply” one pandas_udf at a time. If you want to use more than one, you’ll have to preform multiple groupBys…and there goes avoiding those shuffles.</p>

<p>In this post I describe a little hack which enables you to create simple python UDFs which act on aggregated data (this functionality is only supposed to exist in Scala!).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">types</span> <span class="k">as</span> <span class="n">T</span>
</span><span class="line">
</span><span class="line"><span class="n">a</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="s">&#39;a&#39;</span><span class="p">],</span>
</span><span class="line">                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">],</span>
</span><span class="line">                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">],</span>
</span><span class="line">                    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="s">&#39;c&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;value&#39;</span><span class="p">])</span>
</span><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>value</th>
 </tr>
 <tr>
   <td>1</td>
   <td>'a'</td>
 </tr>
 <tr>
   <td>1</td>
   <td>'b'</td>
 </tr>
 <tr>
   <td>1</td>
   <td>'b'</td>
 </tr>
 <tr>
   <td>2</td>
   <td>'c'</td>
 </tr>
</table>

<p>I use <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.collect_list">collect_list</a> to bring all data from a given group into a single row. I print the output of this operation below.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">collect_list</span><span class="p">(</span><span class="s">&#39;value&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&#39;value_list&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>value_list</th>
 </tr>
 <tr>
   <td>1</td>
   <td>['a', 'b', 'b']</td>
 </tr>
 <tr>
   <td>2</td>
   <td>['c']</td>
 </tr>
</table>

<p>I then create a <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.udf">UDF</a> which will count all the occurences of the letter ‘a’ in these lists (this can be easily done without a UDF but you get the point). This UDF wraps around collect_list, so it acts on the output of collect_list.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">find_a</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span class="line">  <span class="sd">&quot;&quot;&quot;Count &#39;a&#39;s in list.&quot;&quot;&quot;</span>
</span><span class="line">  <span class="n">output_count</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
</span><span class="line">    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="s">&#39;a&#39;</span><span class="p">:</span>
</span><span class="line">      <span class="n">output_count</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">  <span class="k">return</span> <span class="n">output_count</span>
</span><span class="line">
</span><span class="line"><span class="n">find_a_udf</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">udf</span><span class="p">(</span><span class="n">find_a</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">IntegerType</span><span class="p">())</span>
</span><span class="line">
</span><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">find_a_udf</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">collect_list</span><span class="p">(</span><span class="s">&#39;value&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&#39;a_count&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>a_count</th>
 </tr>
 <tr>
   <td>1</td>
   <td>1</td>
 </tr>
 <tr>
   <td>2</td>
   <td>0</td>
 </tr>
</table>

<p>There we go! A UDF that acts on aggregated data! Next, I show the power of this approach when combined with <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.when">when</a> which let’s us control which data enters F.collect_list.</p>

<p>First, let’s create a dataframe with an extra column.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">types</span> <span class="k">as</span> <span class="n">T</span>
</span><span class="line">
</span><span class="line"><span class="n">a</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s">&#39;a&#39;</span><span class="p">],</span>
</span><span class="line">                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s">&#39;a&#39;</span><span class="p">],</span>
</span><span class="line">                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">],</span>
</span><span class="line">                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">],</span>
</span><span class="line">                    <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s">&#39;c&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;value1&#39;</span><span class="p">,</span> <span class="s">&#39;value2&#39;</span><span class="p">])</span>
</span><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>value1</th>
   <th>value2</th>
 </tr>
 <tr>
   <td>1</td>
   <td>1</td>
   <td>'a'</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2</td>
   <td>'a'</td>
 </tr>
 <tr>
   <td>1</td>
   <td>1</td>
   <td>'b'</td>
 </tr>
 <tr>
   <td>1</td>
   <td>2</td>
   <td>'b'</td>
 </tr>
 <tr>
   <td>2</td>
   <td>1</td>
   <td>'c'</td>
 </tr>
</table>

<p>Notice, how I included a when in the collect_list. Note that the UDF still wraps around collect_list.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">find_a_udf</span><span class="p">(</span> <span class="n">F</span><span class="o">.</span><span class="n">collect_list</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;value1&#39;</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;value2&#39;</span><span class="p">))))</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&#39;a_count&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>id</th>
   <th>a_count</th>
 </tr>
 <tr>
   <td>1</td>
   <td>1</td>
 </tr>
 <tr>
   <td>2</td>
   <td>0</td>
 </tr>
</table>

<p>There we go! Hope you find this info helpful!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/08/29/custom-email-alerts-in-airflow/">Custom Email Alerts in Airflow</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-08-29T18:19:42-05:00'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>29</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>6:19 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://airflow.apache.org/">Apache Airflow</a> is great for coordinating automated jobs, and it provides a simple interface for sending email alerts when these jobs fail. Typically, one can request these emails by setting <code>email_on_failure</code> to <code>True</code> in your operators.</p>

<p>These email alerts work great, but I wanted to include additional links in them (I wanted to include a link to my spark cluster which can be grabbed from the <a href="https://airflow.incubator.apache.org/_modules/airflow/contrib/operators/databricks_operator.html#DatabricksSubmitRunOperator">Databricks Operator</a>). Here’s how I created a custom email alert on job failure.</p>

<p>First, I set <code>email_on_failure</code> to <code>False</code> and use the operators’s <code>on_failure_callback</code>. I give <code>on_failure_callback</code> the function described below.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">airflow.utils.email</span> <span class="kn">import</span> <span class="n">send_email</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">notify_email</span><span class="p">(</span><span class="n">contextDict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Send custom email alerts.&quot;&quot;&quot;</span>
</span><span class="line">
</span><span class="line">    <span class="c"># email title.</span>
</span><span class="line">    <span class="n">title</span> <span class="o">=</span> <span class="s">&quot;Airflow alert: {task_name} Failed&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">contextDict</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="c"># email contents</span>
</span><span class="line">    <span class="n">body</span> <span class="o">=</span> <span class="s">&quot;&quot;&quot;</span>
</span><span class="line"><span class="s">    Hi Everyone, &lt;br&gt;</span>
</span><span class="line"><span class="s">    &lt;br&gt;</span>
</span><span class="line"><span class="s">    There&#39;s been an error in the {task_name} job.&lt;br&gt;</span>
</span><span class="line"><span class="s">    &lt;br&gt;</span>
</span><span class="line"><span class="s">    Forever yours,&lt;br&gt;</span>
</span><span class="line"><span class="s">    Airflow bot &lt;br&gt;</span>
</span><span class="line"><span class="s">    &quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">contextDict</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="n">send_email</span><span class="p">(</span><span class="s">&#39;you_email@address.com&#39;</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">body</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>send_email</code> is a function imported from Airflow. <code>contextDict</code> is a dictionary given to the callback function on error. Importantly, <code>contextDict</code> contains lots of relevant information. This includes the Task Instance (key=’ti’) and Operator Instance (key=’task’) associated with your error. I was able to use the Operator Instance, to grab the relevant cluster’s address and I included this address in my email (this exact code is not present here).</p>

<p>To use the <code>notify_email</code>, I set <code>on_failure_callback</code> equal to <code>notify_email</code>.</p>

<p>I write out a short example airflow dag below.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">airflow.models</span> <span class="kn">import</span> <span class="n">DAG</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">airflow.operators</span> <span class="kn">import</span> <span class="n">PythonOperator</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">airflow.utils.dates</span> <span class="kn">import</span> <span class="n">days_ago</span>
</span><span class="line">
</span><span class="line"><span class="n">args</span> <span class="o">=</span> <span class="p">{</span>
</span><span class="line">  <span class="s">&#39;owner&#39;</span><span class="p">:</span> <span class="s">&#39;me&#39;</span><span class="p">,</span>
</span><span class="line">  <span class="s">&#39;description&#39;</span><span class="p">:</span> <span class="s">&#39;my_example&#39;</span><span class="p">,</span>
</span><span class="line">  <span class="s">&#39;start_date&#39;</span><span class="p">:</span> <span class="n">days_ago</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">
</span><span class="line"><span class="c"># run every day at 12:05 UTC</span>
</span><span class="line"><span class="n">dag</span> <span class="o">=</span> <span class="n">DAG</span><span class="p">(</span><span class="n">dag_id</span><span class="o">=</span><span class="s">&#39;example_dag&#39;</span><span class="p">,</span> <span class="n">default_args</span><span class="o">=</span><span class="n">args</span><span class="p">,</span> <span class="n">schedule_interval</span><span class="o">=</span><span class="s">&#39;0 5 * * *&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">print_hello</span><span class="p">():</span>
</span><span class="line">  <span class="k">return</span> <span class="s">&#39;hello!&#39;</span>
</span><span class="line">
</span><span class="line"><span class="n">py_task</span> <span class="o">=</span> <span class="n">PythonOperator</span><span class="p">(</span><span class="n">task_id</span><span class="o">=</span><span class="s">&#39;example&#39;</span><span class="p">,</span>
</span><span class="line">                         <span class="n">python_callable</span><span class="o">=</span><span class="n">print_hello</span><span class="p">,</span>
</span><span class="line">                         <span class="n">on_failure_callback</span><span class="o">=</span><span class="n">notify_email</span><span class="p">,</span>
</span><span class="line">                         <span class="n">dag</span><span class="o">=</span><span class="n">dag</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">py_task</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Note where set <code>on_failure_callback</code> equal to <code>notify_email</code> in the <code>PythonOperator</code>.</p>

<p>Hope you find this helpful! Don’t hesitate to reach out if you have a question.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/07/08/aggregating-sparse-and-dense-vectors-in-pyspark/">Aggregating Sparse and Dense Vectors in PySpark</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-07-08T19:24:04-05:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>7:24 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Many (if not all of) PySpark’s machine learning algorithms require the input data is concatenated into a single column (using the <a href="https://spark.apache.org/docs/2.3.0/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler">vector assembler</a> command). This is all well and good, but applying non-machine learning algorithms (e.g., any aggregations) to data in this format can be a real pain. Here, I describe how to aggregate (average in this case) data in sparse and dense vectors.</p>

<p>I start by importing the necessary libraries and creating a spark dataframe, which includes a column of sparse vectors. Note that I am using ml.linalg SparseVector and not the SparseVector from mllib. This makes a big difference!</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">types</span> <span class="k">as</span> <span class="n">T</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.ml.linalg</span> <span class="kn">import</span> <span class="n">SparseVector</span><span class="p">,</span> <span class="n">DenseVector</span>
</span><span class="line"><span class="c"># note that using Sparse and Dense Vectors from ml.linalg. There are other Sparse/Dense vectors in spark.</span>
</span><span class="line">
</span><span class="line"><span class="n">df</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
</span><span class="line">  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">SparseVector</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="mf">3.0</span><span class="p">})),</span>
</span><span class="line">  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">SparseVector</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">{</span><span class="mi">9</span><span class="p">:</span> <span class="mf">100.0</span><span class="p">})),</span>
</span><span class="line">  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">SparseVector</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})),</span>
</span><span class="line"><span class="p">])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&quot;row_num&quot;</span><span class="p">,</span> <span class="s">&quot;features&quot;</span><span class="p">])</span>
</span><span class="line">
</span><span class="line"><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>row_num</th>
   <th>features</th>
 </tr>
 <tr>
   <td>1</td>
   <td>(10,[1,2,3,4,5],[1.0, 1.0, 2.0, 1.0, 3.0])</td>
 </tr>
 <tr>
   <td>2</td>
   <td>(10,[9],[100.0])</td>
 </tr>
 <tr>
   <td>3</td>
   <td>(10,[1],[1.0])</td>
 </tr>
</table>

<p>Next, I write a <a href="https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#pyspark.sql.functions.udf">udf</a>, which changes the sparse vector into a dense vector and then changes the dense vector into a python list. The python list is then turned into a spark array when it comes out of the udf.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">sparse_to_array</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
</span><span class="line">  <span class="n">v</span> <span class="o">=</span> <span class="n">DenseVector</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</span><span class="line">  <span class="n">new_array</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
</span><span class="line">  <span class="k">return</span> <span class="n">new_array</span>
</span><span class="line">
</span><span class="line"><span class="n">sparse_to_array_udf</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">udf</span><span class="p">(</span><span class="n">sparse_to_array</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">ArrayType</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">FloatType</span><span class="p">()))</span>
</span><span class="line">
</span><span class="line"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;features_array&#39;</span><span class="p">,</span> <span class="n">sparse_to_array_udf</span><span class="p">(</span><span class="s">&#39;features&#39;</span><span class="p">))</span>
</span><span class="line"><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>row_num</th>
   <th>features</th>
   <th>features_array</th>
 </tr>
 <tr>
   <td>1</td>
   <td>(10,[1,2,3,4,5],[1.0, 1.0, 2.0, 1.0, 3.0])</td>
   <td>[0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0]</td>
 </tr>
 <tr>
   <td>2</td>
   <td>(10,[9],[100.0])</td>
   <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]</td>
 </tr>
 <tr>
   <td>3</td>
   <td>(10,[1],[1.0])</td>
   <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>
 </tr>
</table>

<p>Now that the data is in a PySpark array, we can apply the desired PySpark aggregation to each item in the array.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">df_agg</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">avg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;features_array&#39;</span><span class="p">)[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&quot;averages&quot;</span><span class="p">))</span>
</span><span class="line"><span class="n">df_agg</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>averages</th>
 </tr>
 <tr>
   <td>[0.0, 0.66667, 0.33333, 0.66667, 0.33333, 1.0, 0.0, 0.0, 0.0, 33.33333]</td>
 </tr>
</table>

<p>Now, let’s run through the same exercise with dense vectors. We start by creating a spark dataframe with a column of dense vectors.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">df</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span>
</span><span class="line">  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">DenseVector</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])),</span>
</span><span class="line">  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">DenseVector</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">])),</span>
</span><span class="line">  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">DenseVector</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])),</span>
</span><span class="line"><span class="p">])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&quot;row_num&quot;</span><span class="p">,</span> <span class="s">&quot;features&quot;</span><span class="p">])</span>
</span><span class="line">
</span><span class="line"><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>row_num</th>
   <th>features</th>
 </tr>
 <tr>
   <td>1</td>
   <td>[0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0]</td>
 </tr>
 <tr>
   <td>2</td>
   <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]</td>
 </tr>
 <tr>
   <td>3</td>
   <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>
 </tr>
</table>

<p>Next, we create another PySpark udf which changes the dense vector into a PySpark array.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">dense_to_array</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
</span><span class="line">  <span class="n">new_array</span> <span class="o">=</span> <span class="nb">list</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">])</span>
</span><span class="line">  <span class="k">return</span> <span class="n">new_array</span>
</span><span class="line">
</span><span class="line"><span class="n">dense_to_array_udf</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">udf</span><span class="p">(</span><span class="n">dense_to_array</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">ArrayType</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">FloatType</span><span class="p">()))</span>
</span><span class="line">
</span><span class="line"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;features_array&#39;</span><span class="p">,</span> <span class="n">dense_to_array_udf</span><span class="p">(</span><span class="s">&#39;features&#39;</span><span class="p">))</span>
</span><span class="line"><span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>row_num</th>
   <th>features</th>
   <th>features_array</th>
 </tr>
 <tr>
   <td>1</td>
   <td>[0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0]</td>
   <td>[0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0]</td>
 </tr>
 <tr>
   <td>2</td>
   <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]</td>
   <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]</td>
 </tr>
 <tr>
   <td>3</td>
   <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>
   <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>
 </tr>
</table>

<p>Finally, we can use our standard PySpark aggregators to each item in the PySpark array.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">df_agg</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">F</span><span class="o">.</span><span class="n">avg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;features_array&#39;</span><span class="p">)[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&quot;averages&quot;</span><span class="p">))</span>
</span><span class="line"><span class="n">df_agg</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>averages</th>
 </tr>
 <tr>
   <td>[0.0, 0.66667, 0.33333, 0.66667, 0.33333, 1.0, 0.0, 0.0, 0.0, 33.33333]</td>
 </tr>
</table>

<p>There we go! Hope you find this info helpful!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/06/13/integrating-apache-airflow-and-databricks/">Integrating Apache Airflow and Databricks</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-06-13T18:05:52-05:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>6:05 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Cron is great for automation, but when tasks begin to rely on each other (task C can only run after both tasks A and B finish) cron does not do the trick.</p>

<p><a href="https://airflow.apache.org/">Apache Airflow</a> is open source software (from airbnb) designed to handle the relationship between tasks. I recently setup an airflow server which coordinates automated jobs on <a href="https://databricks.com/">databricks</a> (great software for coordinating spark clusters). Connecting databricks and airflow ended up being a little trickier than it should have been, so I am writing this blog post as a resource to anyone else who attempts to do the same in the future.</p>

<p>For the most part I followed <a href="https://medium.com/a-r-g-o/installing-apache-airflow-on-ubuntu-aws-6ebac15db211">this tutorial from A-R-G-O</a> when setting up airflow. Databricks also has a decent <a href="https://docs.databricks.com/user-guide/dev-tools/data-pipelines.html">tutorial</a> on setting up airflow. The difficulty here is that the airflow software for talking to databricks clusters (DatabricksSubmitRunOperator) was not introduced into airflow until version 1.9 and the A-R-G-O tutorial uses airflow 1.8.</p>

<p>Airflow 1.9 uses Celery version &gt;= 4.0 (I ended up using Celery version 4.1.1). Airflow 1.8 requires Celery &lt; 4.0. In fact, the A-R-G-O tutorial notes that using Celery &gt;= 4.0 will result in the error:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">airflow worker: Received and deleted unknown message. Wrong destination?!?</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I can attest that this is true! If you use airflow 1.9 with Celery &lt; 4.0, everything might appear to work, but airflow will randomly stop scheduling jobs after awhile (check the airflow-scheduler logs if you run into this). You need to use Celery &gt;= 4.0! Preventing the Wrong destination error is easy, but the fix is hard to find (hence why I wrote this post).</p>

<p>After much ado, here’s the fix! If you follow the A-R-G-O tutorial, install airflow 1.9, celery &gt;=4.0 AND set broker_url in airflow.cfg as follows:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">broker_url = pyamqp://guest:guest@localhost:5672//</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Note that compared to the A-R-G-O tutorial, I am just adding “py” in front of amqp. Easy!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/06/02/random-weekly-reminders/">Random Weekly Reminders</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-06-02T17:58:52-05:00'><span class='date'><span class='date-month'>Jun</span> <span class='date-day'>2</span><span class='date-suffix'>nd</span>, <span class='date-year'>2018</span></span> <span class='time'>5:58 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I constantly use google calendar to schedule reminder emails, but I want some of my reminders to be stochastic!</p>

<p>Google calendar wants all their events to occur on a regular basis (e.g., every Sunday), but I might want a weekly reminder email which occurs on a random day each the week.</p>

<p>I wrote a quick set of <a href="https://github.com/dvatterott/reminder_email">python scripts</a> which handle this situation.</p>

<p>The script <a href="https://github.com/dvatterott/reminder_email/blob/master/find_days.py">find_days.py</a> chooses a random day each week (over a month) on which a reminder email should be sent. These dates are piped to a text file (dates.txt). The script <a href="https://github.com/dvatterott/reminder_email/blob/master/send_email.py">send_email.py</a> reads this text file and sends a reminder email to me if the current date matches one of the dates in dates.txt.</p>

<p>I use <a href="https://help.ubuntu.com/community/CronHowto">cron</a> to automatically run these scripts on a regular basis. Cron runs find_days.py on the first of each month and runs send_email.py every day. I copied my cron script as <a href="https://github.com/dvatterott/reminder_email/blob/master/cron_job.txt">cron_job.txt</a>.</p>

<p>I use mailutils and postfix to send the reminder emails from the machine. Check out <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-postfix-as-a-send-only-smtp-server-on-ubuntu-14-04">this tutorial</a> for how to set up a send only mail server. The trickiest part of this process was repeatedly telling gmail that my emails were not spam.</p>

<p>Now I receive my weekly reminder on an unknown date so I can <em>act</em> spontaneous!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/05/03/regression-of-a-proportion-in-python/">Regression of a Proportion in Python</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-05-03T21:20:09-05:00'><span class='date'><span class='date-month'>May</span> <span class='date-day'>3</span><span class='date-suffix'>rd</span>, <span class='date-year'>2018</span></span> <span class='time'>9:20 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I frequently predict proportions (e.g., proportion of year during which a customer is active). This is a regression task because the dependent variables is a float, but the dependent variable is bound between the 0 and 1. Googling around, I had a hard time finding the a good way to model this situation, so I’ve written here what I think is the most straight forward solution.</p>

<p>I am guessing there’s a better way to do this with MCMC, so please comment below if you know a better way.</p>

<p>Let’s get started by importing some libraries for making random data.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Create random regression data.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c"># fix random state</span>
</span><span class="line"><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">coef</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
</span><span class="line">                             <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span class="line">                             <span class="n">n_informative</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
</span><span class="line">                             <span class="n">effective_rank</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span>
</span><span class="line">                             <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span class="line">                             <span class="n">noise</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span>
</span><span class="line">                             <span class="n">bias</span><span class="o">=</span><span class="mf">100.0</span><span class="p">,</span>
</span><span class="line">                             <span class="n">coef</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Shrink down the dependent variable so it’s bound between 0 and 1.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">y_min</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="n">y_min</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>  <span class="c"># min value will be 0</span>
</span><span class="line"><span class="n">y_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="n">y_max</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y</span><span class="p">]</span>  <span class="c"># max value will be 1</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Make a quick plot to confirm that the data is bound between 0 and 1.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
</span><span class="line"><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</span><span class="line">
</span><span class="line"><span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">&#39;whitegrid&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/prop_regression/hist.png" /></p>

<p>All the data here is fake which worries me, but beggars can’t be choosers and this is just a quick example.</p>

<p>Below, I apply a plain GLM to the data. This is what you would expect if you treated this as a plain regression problem</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="kn">as</span> <span class="nn">sm</span>
</span><span class="line">
</span><span class="line"><span class="n">linear_glm</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
</span><span class="line"><span class="n">linear_result</span> <span class="o">=</span> <span class="n">linear_glm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</span><span class="line"><span class="c"># print(linear_result.summary2())  # too much output for a blog post</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Here’s the actual values plotted (x-axis) against the predicted values (y-axis). The model does a decent job, but check out the values on the y-axis - the linear model predicts negative values!</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">linear_result</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/prop_regression/linear.png" /></p>

<p>Obviously the linear model above isn’t correctly modeling this data since it’s guessing values that are impossible.</p>

<p>I followed <a href="https://stats.idre.ucla.edu/stata/faq/how-does-one-do-regression-when-the-dependent-variable-is-a-proportion/">this tutorial</a> which recommends using a GLM with a logit link and the binomial family. Checking out the <a href="http://www.statsmodels.org/stable/generated/statsmodels.genmod.families.family.Binomial.html#statsmodels.genmod.families.family.Binomial">statsmodels module reference</a>, we can see the default link for the binomial family is logit.</p>

<p>Below I apply a GLM with a logit link and the binomial family to the data.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">binom_glm</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">GLM</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">sm</span><span class="o">.</span><span class="n">families</span><span class="o">.</span><span class="n">Binomial</span><span class="p">())</span>
</span><span class="line"><span class="n">binom_results</span> <span class="o">=</span> <span class="n">binom_glm</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</span><span class="line"><span class="c">#print(binom_results.summary2())  # too much output for a blog post</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Here’s the actual data (x-axis) plotted against teh predicted data. You can see the fit is much better!</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">binom_results</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="s">&#39;o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/prop_regression/binomial.png" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</span><span class="line"><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">m</span> <span class="o">-</span><span class="n">p</span> <span class="n">numpy</span><span class="p">,</span><span class="n">matplotlib</span><span class="p">,</span><span class="n">sklearn</span><span class="p">,</span><span class="n">seaborn</span><span class="p">,</span><span class="n">statsmodels</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>CPython 3.6.3
IPython 6.1.0

numpy 1.13.3
matplotlib 2.0.2
sklearn 0.19.1
seaborn 0.8.0
statsmodels 0.8.0

compiler   : GCC 7.2.0
system     : Linux
release    : 4.13.0-38-generic
machine    : x86_64
processor  : x86_64
CPU cores  : 4
interpreter: 64bit
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/03/17/exploring-roc-curves/">Exploring ROC Curves</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-03-17T14:06:15-05:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>2:06 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I’ve always found ROC curves a little confusing. Particularly when it comes to ROC curves with imbalanced classes. This blog post is an exploration into receiver operating characteristic (i.e. <a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py">ROC</a>) curves and how they react to imbalanced classes.</p>

<p>I start by loading the necessary libraries.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
</span><span class="line"><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Seed the random number generator so that everything here is reproducible.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I write a few functions that will create fake date, plot fake date, and plot ROC curves.</p>

<p>I describe each function in turn below:</p>
<ul style="padding-left: 25px;">
 <li><strong>grab_probability</strong> draws a sample of "probabilities" drawn from a uniform distribution bound between 0 and 1.</li>
 <li><strong>create_fake_binary_data</strong> creates a vector of 0s and 1s. The mean of the vector is controlled by the positive input.</li>
 <li><strong>probability_hist</strong> plots a normalized histogram (each bar depicts the proportion of data in it) bound between 0 and 1. </li>
 <li><strong>plot_roc_curve</strong> does not need an explanation.</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">grab_probability</span><span class="p">(</span><span class="n">sample_size</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Draw probabilties&quot;&quot;&quot;</span>
</span><span class="line">    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,))</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">create_fake_binary_data</span><span class="p">(</span><span class="n">positive</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Create a vector of binary data with the mean specified in positive&quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">negative</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="n">positive</span>
</span><span class="line">    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
</span><span class="line">    <span class="n">y</span><span class="p">[:</span><span class="nb">int</span><span class="p">(</span><span class="n">negative</span><span class="o">*</span><span class="n">sample_size</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class="line">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">y</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">probability_hist</span><span class="p">(</span><span class="n">probs</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Create histogram of probabilities&quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
</span><span class="line">    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Plot roc curve&quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">lw</span> <span class="o">=</span> <span class="n">lw</span>
</span><span class="line">    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">()</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;darkorange&#39;</span><span class="p">,</span>
</span><span class="line">             <span class="n">lw</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">&#39;ROC curve (area = </span><span class="si">%0.2f</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">&#39;--&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;False Positive Rate&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;True Positive Rate&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Receiver operating characteristic example&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">&quot;lower right&quot;</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I have found one of the best ways to learn about an algorithm is to give it fake data. That way, I know the data, and can examine exactly what the algorithm does with the data. I then change the data and examine how the algorithm reacts to this change.</p>

<p>The first dataset I create is random data with balanced classes.</p>

<p>I create <em>probability</em> with the grab_probability function. This is a vector of numbers between 0 and 1. These data are meant to simulate the probabilities that would be produced by a model that is no better than chance.</p>

<p>I also create the vector <em>y</em> which is random ones and zeroes. I will call the ones the positive class and the zeroes the negative class.</p>

<p>The plot below is a histogram of <em>probability</em>. The y-axis is the proportion of samples in each bin. The x-axis is probability levels. You can see the probabilities appear to be from a uniform distribution.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">sample_size</span> <span class="o">=</span> <span class="mi">1000</span>
</span><span class="line"><span class="n">positive</span> <span class="o">=</span> <span class="mf">0.5</span>
</span><span class="line">
</span><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="n">create_fake_binary_data</span><span class="p">(</span><span class="n">positive</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
</span><span class="line"><span class="n">probability</span> <span class="o">=</span> <span class="n">grab_probability</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">probability_hist</span><span class="p">(</span><span class="n">probability</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_7_0.png" /></p>

<p>There’s no association between <em>y</em> and the <em>probability</em>, so I don’t expect the area under the curve to be different than chance (i.e., have an area under the curve of about 0.5). I plot the ROC curve to confirm this below.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probability</span><span class="p">)</span>
</span><span class="line"><span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_9_0.png" /></p>

<p>Let’s talk about the axes here. The y-axis is the proportion of true positives (i.e., <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">TPR</a> - True Positive Rate). This is how often the model correctly identifies members of the positive class. The x-axis is the proportion of false positives (FPR - False Positive Rate). This how often the model incorrectly assigns examples to the positive class.</p>

<p>One might wonder how the TPR and FPR can change. Doesn’t a model always produce the same guesses? The TPR and FPR can change because we can choose how liberal or conservative the model should be with assigning examples to the positive class. The lower left-hand corner of the plot above is when the model is maximally conservative (and assigns no examples to the positive class). The upper right-hand corner is when the model is maximally liberal and assigns every example to the positive class.</p>

<p>I used to assume that when a model is neutral in assigning examples to the positive class, that point would like halfway between the end points, but this is not the case. The threshold creates points along the curve, but doesn’t dictate where these points lie. If this is confusing, continue to think about it as we march through the proceeding plots.</p>

<p>The ROC curve is the balance between true and false positives as a threshold varies. To help visualize this balance, I create a function which plots the two classes as a stacked histogram, cumulative density functions, and the relative balance between the two classes.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">probability_histogram_class</span><span class="p">(</span><span class="n">probability</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
</span><span class="line">    <span class="n">counts</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">([</span><span class="n">probability</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">probability</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">]],</span> <span class="n">stacked</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">bins</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">bins</span><span class="p">))</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
</span><span class="line">
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">probability</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">],</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;tab:orange&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">bins</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">bins</span><span class="p">))</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">probability</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">],</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&#39;tab:blue&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">bins</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">bins</span><span class="p">))</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">()</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
</span><span class="line">    <span class="n">proportion</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="o">-</span><span class="n">proportion</span><span class="p">)</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">bins</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">bins</span><span class="p">))</span>
</span><span class="line">    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The idea behind this plot is we can visualize the model’s threshold moving from LEFT to RIGHT through the plots. As the threshold decreases, the model will guess the positive class more often. This means more and more of each class will be included when calculating the numerator of TPR and FPR.</p>

<p>The top left plot is a stacked histogram. Orange depicts members of the positive class and blue depicts members of the negative class. On the x-axis (of all four plots) is probability.</p>

<p>If we continue thinking about the threshold as decreasing as the plots moves from left to right, we can think of the top right plot (a reversed <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">CDF</a> of the positive class) as depicting the proportion of the positive class assigned to the positive class as the threshold varies (setting the TPR). We can think of the bottom right plot (a reversed CDF of the negative class) as depicting the proportion of the negative class assigned to the positive class as the threshold varies (setting the FPR).</p>

<p>In the bottom left plot, I plot the proportion of positive class that falls in each bin from the histogram in the top plot.  Because the proportion of positive and negative class are equal as the threshold varies (as depicted in the bottom plot) we consistently assign both positive and negative examples to the positive class at equal rates and the ROC stays along the identity and the area under the curve is 0.5.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">probability</span> <span class="o">=</span> <span class="n">grab_probability</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">probability_histogram_class</span><span class="p">(</span><span class="n">probability</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_13_0.png" /></p>

<p>Next, I do the same process as above but with fake probabilities that are predictive of the label. The function biased_probability produces probabilities that tend to be greater for the positive class and lesser for the negative class.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">biased_probability</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Return probabilities biased towards correct answer&quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">probability</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),))</span>
</span><span class="line">    <span class="n">probability</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)),))</span> <span class="o">+</span> <span class="mf">0.25</span>
</span><span class="line">    <span class="n">probability</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y</span><span class="o">==</span><span class="mi">0</span><span class="p">)),))</span> <span class="o">-</span> <span class="mf">0.25</span>
</span><span class="line">    <span class="n">probability</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">probability</span><span class="p">])</span>
</span><span class="line">    <span class="k">return</span> <span class="n">probability</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I create this data for a balanced class problem again. using the same y vector, I adjust the probabilities so that they are predcitive of the values in this y vector. Below, you can see the probability data as a histogram. The data no longer appear to be drawn from a uniform distribution. Instead, there are modes near 0 and 1.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">probability</span> <span class="o">=</span> <span class="n">biased_probability</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">probability_hist</span><span class="p">(</span><span class="n">probability</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_17_0.png" /></p>

<p>Now, we get a nice roc curve which leaves the identity line. Not surprising since I designed the probabilities to be predictive. Notice how quickly the model acheives a TPR of 1. Remember this when looking at the plots below.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probability</span><span class="p">)</span>
</span><span class="line"><span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_19_0.png" /></p>

<p>In the upper left plot below, we can clearly see that the positive class occurs more often than the negative class on the right side of the plot.</p>

<p>Now remember that the lower left hand side of the roc plot is when we are most conservative. This corresponds to the right hand side of these plots where the model is confident that these examples are from the positive class.</p>

<p>If we look at the cdfs of right side. We can see the positive class (in orange) has many examples on the right side of these plots while the negative class (in blue) has no examples on this side. This is why the TPR immediately jumps to about 0.5 in the roc curve above. We also see the positive class has no examples on the left side of these plots while the negative class has many. This is why the TPR saturates at 1 well before the FPR does.</p>

<p>In other words, because there model is quite certain that some examples are from the positive class the ROC curve quickly jumps up on the y-axis. Because the model is quite certain as to which examples are from the negative class, the ROC curves saturates on the y-axis well before the end of the x-axis.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">probability</span> <span class="o">=</span> <span class="n">biased_probability</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">probability_histogram_class</span><span class="p">(</span><span class="n">probability</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_21_0.png" /></p>

<p>After those two examples, I think we have a good handle on the ROC curve in the balanced class situation. Now let’s make some fake data when the classes are unbalanced. The probabilities will be completely random.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">sample_size</span> <span class="o">=</span> <span class="mi">1000</span>
</span><span class="line"><span class="n">positive</span> <span class="o">=</span> <span class="mf">0.7</span>
</span><span class="line">
</span><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="n">create_fake_binary_data</span><span class="p">(</span><span class="n">positive</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
</span><span class="line"><span class="n">probability</span> <span class="o">=</span> <span class="n">grab_probability</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="s">&#39;Average Test Value: </span><span class="si">%0.2f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</span><span class="line"><span class="k">print</span><span class="p">(</span><span class="s">&#39;Average Probability: </span><span class="si">%0.2f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probability</span><span class="p">))</span>
</span><span class="line">
</span><span class="line"><span class="n">probability_hist</span><span class="p">(</span><span class="n">probability</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>Average Test Value: 0.70
Average Probability: 0.49
</code></pre>

<p><img src="/images/roc_post/output_23_1.png" /></p>

<p>Again, this is fake data, so the probabilities do not reflect the fact that the classes are imbalanced.</p>

<p>Below, we can see that the ROC curve agrees that the data are completely random.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probability</span><span class="p">)</span>
</span><span class="line"><span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_25_0.png" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">probability_histogram_class</span><span class="p">(</span><span class="n">probability</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_26_0.png" /></p>

<p>Now, lets create biased probabilities and see if the ROC curve differs from chance</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
</span><span class="line">
</span><span class="line"><span class="n">probability</span> <span class="o">=</span> <span class="n">biased_probability</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probability</span><span class="p">)</span>
</span><span class="line"><span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_28_0.png" /></p>

<p>It does as we expect.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">probability_histogram_class</span><span class="p">(</span><span class="n">probability</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_30_0.png" /></p>

<p>Importantly, the probabilities now reflect the biased classes</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">probability</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>0.602536255717
</code></pre>

<p>Using these same probabilities, lets remove the relationship between the probabilities and the output variable by shuffling the data.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probability</span><span class="p">)</span>
</span><span class="line"><span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">roc_auc</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_35_0.png" /></p>

<p>Beautiful! the ROC curve stays on the identity line. We can see that this is because while the positive class is predicted more often, the positive class is evently distributed across the different thresholds.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">probability_histogram_class</span><span class="p">(</span><span class="n">probability</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="/images/roc_post/output_37_0.png" /></p>

<p>Importantly, this demonstrates that even with imbalanced classes, if a model is at chance, then the ROC curve will reflect this chance perforomance. I do a similar demonstration with fake data <a href="https://github.com/dvatterott/jupyter_notebooks/blob/master/ROC_curves_realData.ipynb">here</a>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="o">%</span><span class="n">load_ext</span> <span class="n">watermark</span>
</span><span class="line"><span class="o">%</span><span class="n">watermark</span> <span class="o">-</span><span class="n">v</span> <span class="o">-</span><span class="n">m</span> <span class="o">-</span><span class="n">p</span> <span class="n">numpy</span><span class="p">,</span><span class="n">matplotlib</span><span class="p">,</span><span class="n">sklearn</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<pre><code>CPython 3.6.3
IPython 6.1.0

numpy 1.13.3
matplotlib 2.0.2
sklearn 0.19.1

compiler   : GCC 7.2.0
system     : Linux
release    : 4.13.0-36-generic
machine    : x86_64
processor  : x86_64
CPU cores  : 4
interpreter: 64bit
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2018/02/06/is-not-in-with-pyspark/">'Is Not in' With PySpark</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2018-02-06T21:10:32-06:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>6</span><span class='date-suffix'>th</span>, <span class='date-year'>2018</span></span> <span class='time'>9:10 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In SQL it’s easy to find people in one list who are not in a second list (i.e., the “not in” command), but there is no similar command in PySpark. Well, at least not <a href="https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.isin">a command</a> that doesn’t involve collecting the second list onto the master instance.</p>

<p><strong>EDIT</strong><br />
Check the note at the bottom regarding “anti joins”. Using an anti join is much cleaner than the code described here.</p>

<p>Here is a tidbit of code which replicates SQL’s “not in” command, while keeping your data with the workers (it will require a shuffle).</p>

<p>I start by creating some small dataframes.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">pyspark</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span><span class="line"><span class="n">a</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="s">&#39;a&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="s">&#39;c&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;valueA&#39;</span><span class="p">])</span>
</span><span class="line"><span class="n">b</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="s">&#39;a&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="s">&#39;d&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="s">&#39;e&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;valueB&#39;</span><span class="p">])</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Take a quick look at dataframe <em>a</em>.</p>
<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<table style="width:5%">
 <tr>
   <th>id</th>
   <th>valueA</th>
 </tr>
 <tr>
   <td>1</td>
   <td>a</td>
 </tr>
 <tr>
   <td>2</td>
   <td>b</td>
 </tr>
 <tr>
   <td>3</td>
   <td>c</td>
 </tr>
</table>

<p>And dataframe <em>b</em>.</p>
<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">b</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<table style="width:5%">
 <tr>
   <th>id</th>
   <th>valueA</th>
 </tr>
 <tr>
   <td>1</td>
   <td>a</td>
 </tr>
 <tr>
   <td>4</td>
   <td>d</td>
 </tr>
 <tr>
   <td>5</td>
   <td>e</td>
 </tr>
</table>

<p>I create a new column in <em>a</em> that is all ones. I could have used an existing column, but this way I know the column is never null.</p>
<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;inA&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lit</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<table style="width:5%">
 <tr>
   <th>id</th>
   <th>valueA</th>
   <th>inA</th>
 </tr>
 <tr>
   <td>1</td>
   <td>a</td>
   <td>1</td>
 </tr>
 <tr>
   <td>2</td>
   <td>b</td>
   <td>1</td>
 </tr>
 <tr>
   <td>3</td>
   <td>c</td>
   <td>1</td>
 </tr>
</table>

<p>I join <em>a</em> and <em>b</em> with a left join. This way all values in <em>b</em> which are not in <em>a</em> have null values in the column “inA”.</p>
<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">b</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;left&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<table style="width:5%">
 <tr>
   <th>id</th>
   <th>valueA</th>
   <th>valueB</th>
   <th>inA</th>
 </tr>
 <tr>
   <td>5</td>
   <td>e</td>
   <td>null</td>
   <td>null</td>
 </tr>
 <tr>
   <td>1</td>
   <td>a</td>
   <td>a</td>
   <td>1</td>
 </tr>
 <tr>
   <td>4</td>
   <td>d</td>
   <td>null</td>
   <td>null</td>
 </tr>
</table>

<p>By filtering out rows in the new dataframe <em>c</em>, which are not null, I remove all values of <em>b</em>, which were also in <em>a</em>.</p>
<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;left&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&#39;inA&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">isNull</span><span class="p">())</span>
</span><span class="line"><span class="n">c</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
<table style="width:5%">
 <tr>
   <th>id</th>
   <th>valueA</th>
   <th>valueB</th>
   <th>inA</th>
 </tr>
 <tr>
   <td>5</td>
   <td>e</td>
   <td>null</td>
   <td>null</td>
 </tr>
 <tr>
   <td>4</td>
   <td>d</td>
   <td>null</td>
   <td>null</td>
 </tr>
</table>

<p><strong>EDIT</strong><br />
I recently gave the <a href="https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.join">PySpark documentation</a> a more thorough reading and realized that PySpark’s join command has a left_anti option. The left_anti option produces the same functionality as described above, but in a single join command (no need to create a dummy column and filter).</p>

<p>For example, the following code will produce rows in b where the id value is not present in a.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">c</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;left_anti&#39;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/posts/2">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
    <div id="social-icons">
        
  <span class="fa-stack fa-lg">
    <a href="mailto:dvatterott@gmail.com"><i class="fa fa-envelope fa-1x"></i></a>
  </span>

        
  <span class="fa-stack fa-lg">
    <a href="http://www.linkedin.com/in/dan-vatterott"><i class="fa fa-linkedin fa-1x"></i></a>
  </span>

        
  <span class="fa-stack fa-lg">
    <a href="https://twitter.com/dvatterott"><i class="fa fa-twitter fa-1x"></i></a>
  </span>

        
  <span class="fa-stack fa-lg">
    <a href="https://github.com/dvatterott"><i class="fa fa-github fa-1x"></i></a>
  </span>


        
  <span class="fa-stack fa-lg">
    <a href="https://scholar.google.com/citations?hl=en&user=-S7mhDQAAAAJ&hl"><i class="fa fa-graduation-cap fa-1x"></i></a>
  </span>

    </div>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2018/12/07/survival-function-in-pyspark/">Creating a Survival Function in PySpark</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/11/03/looking-towards-the-future-of-automated-machine-learning/">Looking Towards the Future of Automated Machine-learning</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/09/06/python-aggregate-udfs-in-pyspark/">Python Aggregate UDFs in PySpark</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/08/29/custom-email-alerts-in-airflow/">Custom Email Alerts in Airflow</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/07/08/aggregating-sparse-and-dense-vectors-in-pyspark/">Aggregating Sparse and Dense Vectors in PySpark</a>
      </li>
    
  </ul>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2018 - Dan Vatterott -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'danvatterott';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
