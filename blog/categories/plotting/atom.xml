<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Plotting | Dan Vatterott]]></title>
  <link href="https://danvatterott.com/blog/categories/plotting/atom.xml" rel="self"/>
  <link href="https://danvatterott.com/"/>
  <updated>2022-02-25T14:33:11-06:00</updated>
  <id>https://danvatterott.com/</id>
  <author>
    <name><![CDATA[Dan Vatterott]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Are We in a TV Golden Age?]]></title>
    <link href="https://danvatterott.com/blog/2017/07/15/are-we-in-a-tv-golden-age/"/>
    <updated>2017-07-15T15:12:26-05:00</updated>
    <id>https://danvatterott.com/blog/2017/07/15/are-we-in-a-tv-golden-age</id>
    <content type="html"><![CDATA[<p>I recently found myself in a argument with my wife regarding whether TV was better now than previously. I believed that TV was better now than 20 years ago. My wife contended that there was simply more TV content being produced, and that this led to more good shows, but shows are not inherently any better.</p>

<p>This struck me as a great opportunity to do some quick data science. For this post, I scraped the names (from wikipedia) and ratings (from <a href="https://www.themoviedb.org/">TMDb</a>) of all American TV shows. I did the same for major American movies, so that I could have a comparison group (maybe all content is better or worse). The ratings are given by TMDb’s users and are scores between 1 and 10 (where 10 is a great show/movie and 1 is a lousy show/movie).</p>

<p>All the code for this post can be found <a href="https://github.com/dvatterott/tv_vs_movies">on my github</a>.</p>

<p>I decided to operationalize my “golden age of TV” hypothesis as the average TV show is better now than previously. This would be expressed as a positive slope (beta coefficient) when building a linear regression that outputs the rating of a show given the date on which the show first aired. My wife predicted a slope near zero or negative (shows are no better or worse than previously).</p>

<p>Below, I plot the ratings of TV shows and movies across time. Each show is a dot in the scatter plot. Show rating (average rating given my TMBb) is on the y-axis. The date of the show’s first airing is on the x-axis. When I encountered shows with the same name, I just tacked a number onto the end. For instance, show “x” would become show “x_1.” The size of each point in the scatter plot is the show’s “popularity”, which is a bit of a black box, but it’s given by TMBb’s API. TMDb does not give a full description of how they calculate popularity, but they do say its a function of how many times an item is viewed on TMDb, how many times an item is rated, and how many times the item has been added to watch or favorite list. I decided to depict it here just to give the figures a little more detail. The larger the dot, the more popular the show.</p>

<p>Here’s a plot of all TV shows across time.</p>

<iframe src="{{ root_url }}/images/tv_movies/index_tv.html" marginwidth="0" marginheight="0" scrolling="no" width="800" height="500"></iframe>

<p>To test the “golden age of TV” hypothesis, I coded up a linear regression in javascript (below). I put the regression’s output as a comment at the end of the code.
Before stating whether the hypothesis was rejected or not, I should note that that I removed shows with less than 10 votes because these shows had erratic ratings.</p>

<p>As you can see, there is no evidence that TV is better now that previously. In fact, if anything, this dataset says that TV is worse (but more on this later).</p>

<p>{% codeblock lang:javascript %}
function linearRegression(y,x){</p>

<pre><code>var lr = {};
var n = y.length;
var sum_x = 0;
var sum_y = 0;
var sum_xy = 0;
var sum_xx = 0;
var sum_yy = 0;

for (var i = 0; i &lt; y.length; i++) {

    sum_x += x[i];
    sum_y += y[i];
    sum_xy += (x[i]*y[i]);
    sum_xx += (x[i]*x[i]);
    sum_yy += (y[i]*y[i]);
}

lr['slope'] = (n * sum_xy - sum_x * sum_y) / (n*sum_xx - sum_x * sum_x);
lr['intercept'] = (sum_y - lr.slope * sum_x)/n;
lr['r2'] = Math.pow((n*sum_xy - sum_x*sum_y)/Math.sqrt((n*sum_xx-sum_x*sum_x)*(n*sum_yy-sum_y*sum_y)),2);

return lr;
</code></pre>

<p>};</p>

<p>var yval = data
    .filter(function(d) { return d.vote_count &gt; 10 })
    .map(function (d) { return parseFloat(d.vote_average); });
var xval = data
    .filter(function(d) { return d.vote_count &gt; 10 })
    .map(function (d) { return d.first_air_date.getTime() / 1000; });
var lr = linearRegression(yval,xval);
// Object { slope: -3.754543948800799e-10, intercept: 7.0808230581192815, r2: 0.038528573017115 }</p>

<p>{% endcodeblock %}</p>

<p>I wanted to include movies as a comparison to TV. Here’s a plot of all movies across time.</p>

<iframe src="{{ root_url }}/images/tv_movies/index_movie.html" marginwidth="0" marginheight="0" scrolling="no" width="800" height="500"></iframe>

<p>It’s important to note that I removed all movies with less than 1000 votes. This is completely 100% unfair, BUT I am very proud of my figures here and things get a little laggy when including too many movies in the plot. Nonetheless, movies seem to be getting worse over time! More dramatically than TV shows!</p>

<p>{% codeblock lang:javascript %}
var yval = data
    .filter(function(d) { return d.vote_count &gt; 1000 })
    .map(function (d) { return parseFloat(d.vote_average); });
var xval = data
    .filter(function(d) { return d.vote_count &gt; 1000 })
    .map(function (d) { return d.first_air_date.getTime() / 1000; });
var lr = linearRegression(yval,xval);
// Object { slope: -8.11645196776367e-10, intercept: 7.659366705415847, r2: 0.16185069580043676 }
{% endcodeblock %}</p>

<p>Okay, so this was a fun little analysis, but I have to come out and say that I wasn’t too happy with my dataset and the conclusions we can draw from this analysis are only as good as the dataset.</p>

<p>The first limitation is that recent content is much more likely to receive a rating than older content, which could systematically bias the ratings of older content (e.g., only good shows from before 2000 receive ratings). It’s easy to imagine how this would lead us to believing that all older content is better than it actually was.</p>

<p>Also, TMDb seems to have IMDB type tastes by which I mean its dominated by young males. For instance, while I don’t like the show “Keeping up the Kardashians,” it’s definitely not the worst show ever. Also, “Girls” is an amazing show which gets no respect here. The quality of a show is in the eye of the beholder, which in this case seems to be boys.</p>

<p>I would have used Rotten Tomatoes’ API, but they don’t provide access to TV ratings.</p>

<p>Even with all these caveats in mind, it’s hard to defend my “golden age of TV” hypothesis. Instead, it seems like there is just more content being produced, which leads to more good shows (yay!), but the average show is no better or worse than previously.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating Videos of NBA Action With Sportsvu Data]]></title>
    <link href="https://danvatterott.com/blog/2016/06/16/creating-videos-of-nba-action-with-sportsvu-data/"/>
    <updated>2016-06-16T07:11:47-05:00</updated>
    <id>https://danvatterott.com/blog/2016/06/16/creating-videos-of-nba-action-with-sportsvu-data</id>
    <content type="html"><![CDATA[<p>All basketball teams have a camera system called <a href="https://en.wikipedia.org/wiki/SportVU">SportVU</a> installed in their arenas. These camera systems track players and the ball throughout a basketball game.</p>

<p>The data produced by sportsvu camera systems used to be freely available on NBA.com, but was recently removed (I have no idea why). Luckily, the data for about 600 games are available on <a href="https://github.com/neilmj/BasketballData">neilmj’s github</a>. In this post, I show how to create a video recreation of a given basketball play using the sportsvu data.</p>

<p>This code is also available as a jupyter notebook on my <a href="https://github.com/dvatterott/jupyter_notebooks">github</a>.</p>

<p>{% codeblock lang:python %}
#import some libraries
import matplotlib.pyplot as plt, pandas as pd, numpy as np, matplotlib as mpl
from <strong>future</strong> import print_function</p>

<p>mpl.rcParams[‘font.family’] = [‘Bitstream Vera Sans’]
{% endcodeblock %}</p>

<p>The data is provided as a json. Here’s how to import the python json library and load the data. I’m a T-Wolves fan, so the game I chose is a wolves game.</p>

<p>{% codeblock lang:python %}
import json #import json library
json_data = open(‘/home/dan-laptop/github/BasketballData/2016.NBA.Raw.SportVU.Game.Logs/0021500594.json’) #import the data from wherever you saved it.
data = json.load(json_data) #load the data
{% endcodeblock %}</p>

<p>Let’s take a quick look at the data. It’s a dictionary with three keys: gamedate, gameid, and events. Gamedate and gameid are the date of this game and its specific id number, respectively. Events is the structure with data we’re interested in.</p>

<p>{% codeblock lang:python %}
data.keys()
{% endcodeblock %}</p>

<pre><code>[u'gamedate', u'gameid', u'events']
</code></pre>

<p>Lets take a look at the first event. The first event has an associated eventid number. We will use these later. There’s also data for each player on the visiting and home team. We will use these later too. Finally, and most importantly, there’s the “moments.” There are 25 moments for each second of the “event” (the data is sampled at 25hz).</p>

<p>{% codeblock lang:python %}
data[‘events’][0].keys()
{% endcodeblock %}</p>

<pre><code>[u'eventId', u'visitor', u'moments', u'home']
</code></pre>

<p>Here’s the first moment of the first event. The first number is the quarter. The second number is the time of the event in milliseconds. The third number is the number of seconds left in the quarter (the 1st quarter hasn’t started yet, so 12 * 60 = 720). The fourth number is the number of seconds left on the shot clock. I am not sure what fourth number (None) represents.</p>

<p>The final matrix is 11x5 matrix. The first row describes the ball. The first two columns are the teamID and the playerID of the ball (-1 for both because the ball does not belong to a team and is not a player). The 3rd and 4th columns are xy coordinates of the ball. The final column is the height of the ball (z coordinate).</p>

<p>The next 10 rows describe the 10 players on the court. The first 5 players belong to the home team and the last 5 players belong to the visiting team. Each player has his teamID, playerID, xy&amp;z coordinates (although I don’t think players’ z coordinates ever change).</p>

<p>{% codeblock lang:python %}
data[‘events’][0][‘moments’][0]
{% endcodeblock %}</p>

<pre><code>[1,
 1452903036782,
 720.0,
 24.0,
 None,
 [[-1, -1, 44.16456, 26.34142, 5.74423],
  [1610612760, 201142, 45.46259, 32.01456, 0.0],
  [1610612760, 201566, 10.39347, 24.77219, 0.0],
  [1610612760, 201586, 25.86087, 25.55881, 0.0],
  [1610612760, 203460, 47.28525, 17.76225, 0.0],
  [1610612760, 203500, 43.68634, 26.63098, 0.0],
  [1610612750, 708, 55.6401, 25.55583, 0.0],
  [1610612750, 2419, 47.95942, 31.66328, 0.0],
  [1610612750, 201937, 67.28725, 25.10267, 0.0],
  [1610612750, 203952, 47.28525, 17.76225, 0.0],
  [1610612750, 1626157, 49.46814, 24.24193, 0.0]]]
</code></pre>

<p>Alright, so we have the sportsvu data, but its not clear what each event is. Luckily, the NBA also provides play by play (pbp) data. I write a function for acquiring play by play game data. This function collects (and trims) the play by play data for a given sportsvu data set.</p>

<p>{% codeblock lang:python %}
def acquire_gameData(data):
    import requests
    header_data = { #I pulled this header from the py goldsberry library
        ‘Accept-Encoding’: ‘gzip, deflate, sdch’,
        ‘Accept-Language’: ‘en-US,en;q=0.8’,
        ‘Upgrade-Insecure-Requests’: ‘1’,
        ‘User-Agent’: ‘Mozilla/5.0 (Windows NT 10.0; WOW64)’\
        ‘ AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.82 ‘\
        ‘Safari/537.36’,
        ‘Accept’: ‘text/html,application/xhtml+xml,application/xml;q=0.9’\
        ‘,image/webp,<em>/</em>;q=0.8’,
        ‘Cache-Control’: ‘max-age=0’,
        ‘Connection’: ‘keep-alive’
    }
    game_url = ‘http://stats.nba.com/stats/playbyplayv2?EndPeriod=0&amp;EndRange=0&amp;GameID=’+data[‘gameid’]+\
                ‘&amp;RangeType=0&amp;StartPeriod=0&amp;StartRange=0’ #address for querying the data
    response = requests.get(game_url,headers = header_data) #go get the data
    headers = response.json()[‘resultSets’][0][‘headers’] #get headers of data
    gameData = response.json()[‘resultSets’][0][‘rowSet’] #get actual data from json object
    df = pd.DataFrame(gameData, columns=headers) #turn the data into a pandas dataframe
    df = df[[df.columns[1], df.columns[2],df.columns[7],df.columns[9],df.columns[18]]] #there’s a ton of data here, so I trim  it doown
    df[‘TEAM’] = df[‘PLAYER1_TEAM_ABBREVIATION’]
    df = df.drop(‘PLAYER1_TEAM_ABBREVIATION’, 1)
    return df
{% endcodeblock %}</p>

<p>Below I show what the play by play data looks like. There’s a column for event number (eventnum). These event numbers match up with the event numbers from the sportsvu data, so we will use this later for seeking out specific plays in the sportsvu data. There’s a column for the event type (eventmsgtype). This column has a number describing what occured in the play. I list these number codes in the comments below.</p>

<p>There’s also short text descriptions of the plays in the home description and visitor description columns. Finally, I use the team column to represent the primary team involved in a play.</p>

<p>I stole the idea of using play by play data from <a href="http://projects.rajivshah.com/sportvu/PBP_NBA_SportVu.html">Raji Shah</a>.</p>

<p>{% codeblock lang:python %}
df = acquire_gameData(data)
df.head()
#EVENTMSGTYPE
#1 - Make 
#2 - Miss 
#3 - Free Throw 
#4 - Rebound 
#5 - out of bounds / Turnover / Steal 
#6 - Personal Foul 
#7 - Violation 
#8 - Substitution 
#9 - Timeout 
#10 - Jumpball 
#12 - Start Q1? 
#13 - Start Q2?
{% endcodeblock %}</p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EVENTNUM</th>
      <th>EVENTMSGTYPE</th>
      <th>HOMEDESCRIPTION</th>
      <th>VISITORDESCRIPTION</th>
      <th>TEAM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>12</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>10</td>
      <td>Jump Ball Adams vs. Towns: Tip to Ibaka</td>
      <td>None</td>
      <td>OKC</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>5</td>
      <td>Westbrook Out of Bounds Lost Ball Turnover (P1...</td>
      <td>None</td>
      <td>OKC</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>None</td>
      <td>MISS Wiggins 16' Jump Shot</td>
      <td>MIN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>4</td>
      <td>Westbrook REBOUND (Off:0 Def:1)</td>
      <td>None</td>
      <td>OKC</td>
    </tr>
  </tbody>
</table>
</div>

<p>When viewing the videos, its nice to know what players are on the court. I like to depict this by labeling each player with their number. Here I create a dictionary that contains each player’s id number (these are assigned by nba.com) as the key and their jersey number as the associated value.</p>

<p>{% codeblock lang:python %}
player_fields = data[‘events’][0][‘home’][‘players’][0].keys()
home_players = pd.DataFrame(data=[i for i in data[‘events’][0][‘home’][‘players’]], columns=player_fields)
away_players = pd.DataFrame(data=[i for i in data[‘events’][0][‘visitor’][‘players’]], columns=player_fields)
players = pd.merge(home_players, away_players, how=’outer’)
jerseydict = dict(zip(players.playerid.values, players.jersey.values))
{% endcodeblock %}</p>

<p>Alright, almost there! Below I write some functions for creating the actual video! First, there’s a short function for placing an image of the basketball court beneath our depiction of players moving around. This image is from gmf05’s github, but I will provide it on <a href="https://github.com/dvatterott/nba_project">mine</a> too.</p>

<p>Much of this code is either straight from <a href="https://github.com/gmf05/nba/blob/master/scripts/notebooks/svmovie.ipynb">gmf05’s github</a> or slightly modified.</p>

<p>{% codeblock lang:python %}
# Animation function / loop
def draw_court(axis):
    import matplotlib.image as mpimg
    img = mpimg.imread(‘./nba_court_T.png’) #read image. I got this image from gmf05’s github.
    plt.imshow(img,extent=axis, zorder=0) #show the image.</p>

<p>def animate(n): #matplotlib’s animation function loops through a function n times that draws a different frame on each iteration
    for i,ii in enumerate(player_xy[n]): #loop through all the players
        player_circ[i].center = (ii[1], ii[2]) #change each players xy position
        player_text[i].set_text(str(jerseydict[ii[0]])) #draw the text for each player. 
        player_text[i].set_x(ii[1]) #set the text x position
        player_text[i].set_y(ii[2]) #set text y position
    ball_circ.center = (ball_xy[n,0],ball_xy[n,1]) #change ball xy position
    ball_circ.radius = 1.1 #i could change the size of the ball according to its height, but chose to keep this constant
    return tuple(player_text) + tuple(player_circ) + (ball_circ,)</p>

<p>def init(): #this is what matplotlib’s animation will create before drawing the first frame. 
    for i in range(10): #set up players
        player_text[i].set_text(‘’)
        ax.add_patch(player_circ[i])
    ax.add_patch(ball_circ) #create ball
    ax.axis(‘off’) #turn off axis
    dx = 5
    plt.xlim([0-dx,100+dx]) #set axis
    plt.ylim([0-dx,50+dx])<br />
    return tuple(player_text) + tuple(player_circ) + (ball_circ,)
{% endcodeblock %}</p>

<p>The event that I want to depict is event 41. In this event, Karl Anthony Towns misses a shot, grabs his own rebounds, and puts it back in.</p>

<p>{% codeblock lang:python %}
df[37:38]
{% endcodeblock %}</p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>EVENTNUM</th>
      <th>EVENTMSGTYPE</th>
      <th>HOMEDESCRIPTION</th>
      <th>VISITORDESCRIPTION</th>
      <th>TEAM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>37</th>
      <td>41</td>
      <td>1</td>
      <td>None</td>
      <td>Towns 1' Layup (2 PTS)</td>
      <td>MIN</td>
    </tr>
  </tbody>
</table>
</div>

<p>We need to find where event 41 is in the sportsvu data structure, so I created a function for finding the location of a particular event. I then create a matrix with position data for the ball and a matrix with position data for each player for event 41.</p>

<p>{% codeblock lang:python %}
#the order of events does not match up, so we have to use the eventIds. This loop finds the correct event for a given id#.
search_id = 41
def find_moment(search_id):
    for i,events in enumerate(data[‘events’]):
        if events[‘eventId’] == str(search_id):
            finder = i
            break
    return finder</p>

<p>event_num = find_moment(search_id) 
ball_xy = np.array([x[5][0][2:5] for x in data[‘events’][event_num][‘moments’]]) #create matrix of ball data
player_xy = np.array([np.array(x[5][1:])[:,1:4] for x in data[‘events’][event_num][‘moments’]]) #create matrix of player data
{% endcodeblock %}</p>

<p>Okay. We’re actually there! Now we get to create the video. We have to create figure and axes objects for the animation to draw on. Then I place a picture of the basketball court on this plot. Finally, I create the circle and text objects that will move around throughout the video (depicting the ball and players). The location of these objects are then updated in the animation loop.</p>

<p>{% codeblock lang:python %}
import matplotlib.animation as animation</p>

<p>fig = plt.figure(figsize=(15,7.5)) #create figure object
ax = plt.gca() #create axis object</p>

<p>draw_court([0,100,0,50]) #draw the court
player_text = range(10) #create player text vector
player_circ = range(10) #create player circle vector
ball_circ = plt.Circle((0,0), 1.1, color=[1, 0.4, 0]) #create circle object for bal
for i in range(10): #create circle object and text object for each player
    col=[‘w’,’k’] if i&lt;5 else [‘k’,’w’] #color scheme
    player_circ[i] = plt.Circle((0,0), 2.2, facecolor=col[0],edgecolor=’k’) #player circle
    player_text[i] = ax.text(0,0,’‘,color=col[1],ha=’center’,va=’center’) #player jersey # (text)</p>

<p>ani = animation.FuncAnimation(fig, animate, frames=np.arange(0,np.size(ball_xy,0)), init_func=init, blit=True, interval=5, repeat=False,\
                             save_count=0) #function for making video
ani.save(‘Event_%d.mp4’ % (search_id),dpi=100,fps=25) #function for saving video
plt.close(‘all’) #close the plot
{% endcodeblock %}</p>

<p>{% video {{ root_url }}/images/Event_41.mp4 %}</p>

<p>I’ve been told this video does not work for all users. I’ve also posted it on <a href="https://youtu.be/ZPvQOorvVtI">youtube</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NBA Shot Charts: Updated]]></title>
    <link href="https://danvatterott.com/blog/2016/05/13/nba-shot-charts-updated/"/>
    <updated>2016-05-13T10:08:22-05:00</updated>
    <id>https://danvatterott.com/blog/2016/05/13/nba-shot-charts-updated</id>
    <content type="html"><![CDATA[<p>For some reason I recently got it in my head that I wanted to go back and create more NBA shot charts. <a href="http://www.danvatterott.com/blog/2015/12/22/creating-nba-shot-charts/">My previous shotcharts</a> used colored circles to depict the frequency and effectiveness of shots at different locations. This is an extremely efficient method of representing shooting profiles, but I thought it would be fun to create shot charts that represent a player’s shooting profile continously across the court rather than in discrete hexagons.</p>

<p>By depicting the shooting data continously, I lose the ability to represent one dimenion - I can no longer use the size of circles to depict shot frequency at a location. Nonetheless, I thought it would be fun to create these charts.</p>

<p>I explain how to create them below. I’ve also included the ability to compare a player’s shooting performance to the league average.</p>

<p>In my previous shot charts, I query nba.com’s API when creating a players shot chart, but querying nba.com’s API for every shot taken in 2015-16 takes a little while (for computing league average), so I’ve uploaded this data to <a href="https://github.com/dvatterott/nba_project">my github</a> and call the league data as a file rather than querying nba.com API.</p>

<p>This code is also available as a jupyter notebook on <a href="https://github.com/dvatterott/jupyter_notebooks">my github</a>.</p>

<p>{% codeblock lang:python %}
#import some libraries and tell ipython we want inline figures rather than interactive figures.
%matplotlib inline
import matplotlib.pyplot as plt, pandas as pd, numpy as np, matplotlib as mpl
{% endcodeblock %}</p>

<p>Here, I create a function for querying shooting data from NBA.com’s API. This is the same function I used in my previous post regarding shot charts.</p>

<p>You can find a player’s ID number by going to the players nba.com page and looking at the page address. There is <a href="https://github.com/seemethere/nba_py">a python library</a> that you can use for querying player IDs (and other data from the nba.com API), but I’ve found this library to be a little shaky.</p>

<p>{% codeblock lang:python %}
def aqcuire_shootingData(PlayerID,Season):
    import requests
    header_data = { #I pulled this header from the py goldsberry library
        ‘Accept-Encoding’: ‘gzip, deflate, sdch’,
        ‘Accept-Language’: ‘en-US,en;q=0.8’,
        ‘Upgrade-Insecure-Requests’: ‘1’,
        ‘User-Agent’: ‘Mozilla/5.0 (Windows NT 10.0; WOW64)’\
        ‘ AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.82 ‘\
        ‘Safari/537.36’,
        ‘Accept’: ‘text/html,application/xhtml+xml,application/xml;q=0.9’\
        ‘,image/webp,<em>/</em>;q=0.8’,
        ‘Cache-Control’: ‘max-age=0’,
        ‘Connection’: ‘keep-alive’
    }
    shot_chart_url = ‘http://stats.nba.com/stats/shotchartdetail?CFID=33&amp;CFPARAMS=’+Season+’&amp;ContextFilter=’\
                    ‘&amp;ContextMeasure=FGA&amp;DateFrom=&amp;DateTo=&amp;GameID=&amp;GameSegment=&amp;LastNGames=0&amp;LeagueID=’\
                    ‘00&amp;Location=&amp;MeasureType=Base&amp;Month=0&amp;OpponentTeamID=0&amp;Outcome=&amp;PaceAdjust=’\
                    ‘N&amp;PerMode=PerGame&amp;Period=0&amp;PlayerID=’+PlayerID+’&amp;PlusMinus=N&amp;Position=&amp;Rank=’\
                    ‘N&amp;RookieYear=&amp;Season=’+Season+’&amp;SeasonSegment=&amp;SeasonType=Regular+Season&amp;TeamID=’\
                    ‘0&amp;VsConference=&amp;VsDivision=&amp;mode=Advanced&amp;showDetails=0&amp;showShots=1&amp;showZones=0’
    response = requests.get(shot_chart_url,headers = header_data)
    headers = response.json()[‘resultSets’][0][‘headers’]
    shots = response.json()[‘resultSets’][0][‘rowSet’]
    shot_df = pd.DataFrame(shots, columns=headers)
    return shot_df
{% endcodeblock %}</p>

<p>Create a function for drawing the nba court. This function was taken directly from <a href="http://savvastjortjoglou.com/nba-shot-sharts.html">Savvas Tjortjoglou’s post on shot charts</a>.</p>

<p>{% codeblock lang:python %}
def draw_court(ax=None, color=’black’, lw=2, outer_lines=False):
    from matplotlib.patches import Circle, Rectangle, Arc
    if ax is None:
        ax = plt.gca()
    hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False)
    backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color)
    outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color,
                          fill=False)
    inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color,
                          fill=False)
    top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180,
                         linewidth=lw, color=color, fill=False)
    bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0,
                            linewidth=lw, color=color, linestyle=’dashed’)
    restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw,
                     color=color)
    corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw,
                               color=color)
    corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color)
    three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw,
                    color=color)
    center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0,
                           linewidth=lw, color=color)
    center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0,
                           linewidth=lw, color=color)
    court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw,
                      bottom_free_throw, restricted, corner_three_a,
                      corner_three_b, three_arc, center_outer_arc,
                      center_inner_arc]
    if outer_lines:
        outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw,
                                color=color, fill=False)
        court_elements.append(outer_lines)</p>

<pre><code>for element in court_elements:
    ax.add_patch(element)

ax.set_xticklabels([])
ax.set_yticklabels([])
ax.set_xticks([])
ax.set_yticks([])
return ax {% endcodeblock %}
</code></pre>

<p>Write a function for acquiring each player’s picture. This isn’t essential, but it makes things look nicer. This function takes a playerID number and the amount to zoom in on an image as the inputs. It by default places the image at the location 500,500.</p>

<p>{% codeblock lang:python %}
def acquire_playerPic(PlayerID, zoom, offset=(500,500)):
    from matplotlib import  offsetbox as osb
    import urllib
    pic = urllib.urlretrieve(“http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”,PlayerID+”.png”)
    player_pic = plt.imread(pic[0])
    img = osb.OffsetImage(player_pic, zoom)
    #img.set_offset(offset)
    img = osb.AnnotationBbox(img, offset,xycoords=’data’,pad=0.0, box_alignment=(1,0), frameon=False)
    return img
{% endcodeblock %}</p>

<p>Here is where things get a little complicated. Below I write a function that divides the shooting data into a 25x25 matrix. Each shot taken within the xy coordinates encompassed by a given bin counts towards the shot count in that bin. In this way, the method I am using here is very similar to my previous hexbins (circles). So the difference just comes down to I present the data rather than how I preprocess it.</p>

<p>This function takes a dataframe with a vector of shot locations in the X plane, a vector with shot locations in the Y plane, a vector with shot type (2 pointer or 3 pointer), and a vector with ones for made shots and zeros for missed shots. The function by default bins the data into a 25x25 matrix, but the number of bins is editable. The 25x25 bins are then expanded to encompass a 500x500 space.</p>

<p>The output is a dictionary containing matrices for shots made, attempted, and points scored in each bin location. The dictionary also has the player’s ID number.</p>

<p>{% codeblock lang:python %}
def shooting_matrices(df,bins=25):
    from math import floor</p>

<pre><code>df['SHOT_TYPE2'] = [int(x[0][0]) for x in df['SHOT_TYPE']] #create a vector with whether the shot is a 2 or 3 pointer
points_matrix = np.zeros((bins,bins)) #create a matrix to fill with shooting data.

shot_attempts, xtest, ytest, p = plt.hist2d(df[df['LOC_Y']&lt;425.1]['LOC_X'], #use histtd to bin the data. These are attempts
                                            df[df['LOC_Y']&lt;425.1]['LOC_Y'],
                                            bins=bins,range=[[-250,250],[-25,400]]); #i limit the range of the bins because I don't care about super far away shots and I want the bins standardized across players
plt.close()

shot_made, xtest2, ytest2, p = plt.hist2d(df[(df['LOC_Y']&lt;425.1) &amp; (df['SHOT_MADE_FLAG']==1)]['LOC_X'], #again use hist 2d to bin made shots
                                df[(df['LOC_Y']&lt;425.1) &amp; (df['SHOT_MADE_FLAG']==1)]['LOC_Y'],
                                bins=bins,range=[[-250,250],[-25,400]]);
plt.close()
differy = np.diff(ytest)[0] #get the leading yedge
differx = np.diff(xtest)[0] #get the leading xedge
for i,(x,y) in enumerate(zip(df['LOC_X'],df['LOC_Y'])):
    if x &gt;= 250 or x &lt;= -250 or y &lt;= -25.1 or y &gt;= 400: continue
    points_matrix[int(floor(np.divide(x+250,differx))),int(floor(np.divide(y+25,differy)))] += np.float(df['SHOT_MADE_FLAG'][i]*df['SHOT_TYPE2'][i])
    #loop through all the shots and tally the points made in each bin location.

shot_attempts = np.repeat(shot_attempts,500/bins,axis=0) #repeat the shot attempts matrix so that it fills all xy points
shot_attempts = np.repeat(shot_attempts,500/bins,axis=1)
shot_made = np.repeat(shot_made,500/bins,axis=0) #repeat shot made so that it fills all xy points (rather than just bin locations)
shot_made = np.repeat(shot_made,500/bins,axis=1)
points_matrix = np.repeat(points_matrix,500/bins,axis=0) #again repeat with points
points_matrix = np.repeat(points_matrix,500/bins,axis=1)
return {'attempted':shot_attempts,'made':shot_made,'points':points_matrix,'id':str(np.unique(df['PLAYER_ID'])[0])} {% endcodeblock %}
</code></pre>

<p>Below I load the league average data. I also have the code that I used to originally download the data and to preprocess it.</p>

<p>{% codeblock lang:python %}
import pickle</p>

<h1 id="df--aqcuireshootingdata02015-16-here-is-how-i-acquired-data-about-every-shot-taken-in-2015-16">df = aqcuire_shootingData(‘0’,’2015-16’) #here is how I acquired data about every shot taken in 2015-16</h1>
<p>#df2 = pd.read_pickle(‘nba_shots_201516_2016_Apr_27.pkl’) #here is how you can read all the league shot data
#league_shotDict = shooting_matrices(df2) #turn the shot data into the shooting matrix
#pickle.dump(league_shotDict, open(‘league_shotDictionary_2016.pkl’, ‘wb’ )) #save the data</p>

<h1 id="i-should-make-it-so-this-is-the-plot-size-by-default-but-people-can-change-it-if-they-want-this-would-be-slower">I should make it so this is the plot size by default, but people can change it if they want. this would be slower.</h1>
<p>league_shotDict = pickle.load(open(‘league_shotDictionary_2016.pkl’, ‘rb’ )) #read in the a precreated shot chart for the entire league
{% endcodeblock %}</p>

<p>I really like playing with the different color maps, so here is a new color map I created for these shot charts.</p>

<p>{% codeblock lang:python %}
cmap = plt.cm.CMRmap_r #start with the CMR map in reverse.</p>

<p>maxer = 0.6 #max value to take in the CMR map</p>

<p>the_range = np.arange(0,maxer+0.1,maxer/4) #divide the map into 4 values
the_range2 = [0.0,0.25,0.5,0.75,1.0] #or use these values</p>

<p>mapper = [cmap(x) for x in the_range] #grab color values for this dictionary
cdict = {‘red’:[],’green’:[],’blue’:[]} #fill teh values into a color dictionary
for item,place in zip(mapper,the_range2):
    cdict[‘red’].append((place,item[0], item[0]))
    cdict[‘green’].append((place,item[1],item[1]))
    cdict[‘blue’].append((place,item[2],item[2]))</p>

<p>mymap = mpl.colors.LinearSegmentedColormap(‘my_colormap’, cdict, 1024) #linearly interpolate between color values
{% endcodeblock %}</p>

<p>Below, I write a function for creating the nba shot charts. The function takes a dictionary with martrices for shots attempted, made, and points scored. The matrices should be 500x500. By default, the shot chart depicts the number of shots taken across locations, but it can also depict the number of shots made, field goal percentage, and point scored across locations.</p>

<p>The function uses a gaussian kernel with standard deviation of 5 to smooth the data (make it look pretty). Again, this is editable. By default the function plots a players raw data, but it will plot how a player compares to league average if the input includes a matrix of league average data.</p>

<p>{% codeblock lang:python %}
def create_shotChart(shotDict,fig_type=’attempted’,smooth=5,league_shotDict=[],mymap=mymap):
    from scipy.ndimage.filters import gaussian_filter</p>

<pre><code>if fig_type == 'fg': #how to treat the data if depicting fg percentage
    interest_measure = shotDict['made']/shotDict['attempted']
    #interest_measure[np.isnan(interest_measure)] = np.nanmean(interest_measure)
    #interest_measure = np.nan_to_num(interest_measure) #replace places where divide by 0 with a 0
else:
    interest_measure = shotDict[fig_type] #else take the data from dictionary.

if league_shotDict: #if we have league data, we have to select the relevant league data.
    if fig_type == 'fg':
        league = league_shotDict['made']/league_shotDict['attempted']
        league = np.nan_to_num(league)
        interest_measure[np.isfinite(interest_measure)] += -league[np.isfinite(interest_measure)] #compare league data and invidual player's data
        interest_measure = np.nan_to_num(interest_measure) #replace places where divide by 0 with a 0
        maxer = 0 + 1.5*np.std(interest_measure) #min and max values for color map
        minner = 0- 1.5*np.std(interest_measure)
    else:
        player_percent = interest_measure/np.sum([x[::20] for x in player_shotDict[fig_type][::20]]) #standardize data before comparing
        league_percent = league_shotDict[fig_type]/np.sum([x[::20] for x in league_shotDict[fig_type][::20]]) #standardize league data
        interest_measure = player_percent-league_percent #compare league and individual data
        maxer = np.mean(interest_measure) + 1.5*np.std(interest_measure) #compute max and min values for color map
        minner = np.mean(interest_measure) - 1.5*np.std(interest_measure)

    cmap = 'bwr' #use bwr color map if comparing to league average
    label = ['&lt;Avg','Avg', '&gt;Avg'] #color map legend label

else:
    cmap = mymap #else use my color map
    interest_measure = np.nan_to_num(interest_measure) #replace places where divide by 0 with a 0
    maxer = np.mean(interest_measure) + 1.5*np.std(interest_measure) #compute max for colormap
    minner = 0
    label = ['Less','','More'] #color map legend label

ppr_smooth = gaussian_filter(interest_measure,smooth) #smooth the data

fig = plt.figure(figsize=(12,7),frameon=False)#(12,7)
ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) #where to place the plot within the figure
draw_court(outer_lines=False) #draw court
ax.set_xlim(-250,250)
ax.set_ylim(400, -25)

ax2 = fig.add_axes(ax.get_position(), frameon=False)

colrange = mpl.colors.Normalize(vmin=minner, vmax=maxer, clip=False) #standardize color range
ax2.imshow(ppr_smooth.T,cmap=cmap,norm=colrange,alpha=0.7,aspect='auto') #plot data
ax2.set_xticklabels([])
ax2.set_yticklabels([])
ax2.set_xticks([])
ax2.set_xlim(0, 500)
ax2.set_ylim(500, 0)
ax2.set_yticks([]);

ax3 = fig.add_axes([0.92, 0.1, 0.02, 0.8]) #place colormap legend
cb = mpl.colorbar.ColorbarBase(ax3,cmap=cmap, orientation='vertical')
if fig_type == 'fg': #colormap label
    cb.set_label('Field Goal Percentage')
else:
    cb.set_label('Shots '+fig_type)

cb.set_ticks([0,0.5,1.0])
ax3.set_yticklabels(label,rotation=45);

zoom = np.float(12)/(12.0*2) #place player pic
img = acquire_playerPic(player_shotDict['id'], zoom)
ax2.add_artist(img)

plt.show()
return ax {% endcodeblock %}
</code></pre>

<p>Alright, thats that. Now lets create some plots. I am a t-wolves fan, so I will plot data from Karl Anthony Towns.</p>

<p>First, here is the default plot - attempts.</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/attempts1.png" /></p>

<p>Here’s KAT’s shots made</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict,fig_type=’made’);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/made1.png" /></p>

<p>Here’s field goal percentage. I don’t like this one too much. It’s hard to use similar scales for attempts and field goal percentage even though I’m using standard deviations rather than absolute scales.</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict, fig_type=’fg’);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/fg1.png" /></p>

<p>Here’s points across the court.</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict, fig_type=’points’);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/points1.png" /></p>

<p>Here’s how KAT’s attempts compare to the league average. You can see the twolve’s midrange heavy offense.</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict, league_shotDict=league_shotDict);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/attempts2.png" /></p>

<p>How KAT’s shots made compares to league average.</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict, fig_type=’made’,league_shotDict=league_shotDict);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/made2.png" /></p>

<p>How KAT’s field goal percentage compares to league average. Again, the scale on these is not too good.</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict, fig_type=’fg’,league_shotDict=league_shotDict);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/fg2.png" /></p>

<p>And here is how KAT’s points compare to league average.</p>

<p>{% codeblock lang:python %}
df = aqcuire_shootingData(‘1626157’,’2015-16’)
player_shotDict = shooting_matrices(df)
create_shotChart(player_shotDict, fig_type=’points’,league_shotDict=league_shotDict);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/nba_shot_charts/points2.png" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grouping NBA Players]]></title>
    <link href="https://danvatterott.com/blog/2016/02/21/grouping-nba-players/"/>
    <updated>2016-02-21T14:14:23-06:00</updated>
    <id>https://danvatterott.com/blog/2016/02/21/grouping-nba-players</id>
    <content type="html"><![CDATA[<p>In basketball, we typically talk about 5 positions: point guard, shooting guard, small forward, power forward, and center. Based on this, one might expect NBA players to fall into 5 distinct groups- Point guards perform similar to other point guards, shooting guards perform similar to other shooting guards, etc. Is this the case? Do NBA players fall neatly into position groups?</p>

<p>To answer this question, I will look at how NBA players “group” together. For example, there might be a group of players who collect lots of rebounds, shoot poorly from behind the 3 point line, and block lots of shots. I might call these players forwards. If we allow player performance to create groups, what will these groups look like?</p>

<p>To group players, I will use k-means clustering (https://en.wikipedia.org/wiki/K-means_clustering).</p>

<p>When choosing a clustering algorithm, its important to think about how the clustering algorithm defines clusters. k-means minimizes the distance between data points (players in my case) and the center of K different points. Because distance is between the cluster center and a given point, k-means assumes clusters are spherical. When thinking about clusters of NBA players, do I think these clusters will be spherical? If not, then I might want try a different clustering algorithm.</p>

<p>For now, I will assume generally spherical clusters and use k-means. At the end of this post, I will comment on whether this assumption seems valid.</p>

<p>{% codeblock lang:python %}
#import libraries and tell ipython we want inline figures rather than interactive figures.
import matplotlib.pyplot as plt, pandas as pd, numpy as np, matplotlib as mpl, requests, time</p>

<p>%matplotlib inline
pd.options.display.mpl_style = ‘default’ #load matplotlib for plotting
plt.style.use(‘ggplot’) #im addicted to ggplot. so pretty.
mpl.rcParams[‘font.family’] = [‘Bitstream Vera Sans’]</p>

<p>{% endcodeblock %}</p>

<p>We need data. Collecting the data will require a couple steps. First, I will create a matrix of all players who ever played in the NBA (via the NBA.com API).</p>

<p>{% codeblock lang:python %}
url = ‘http://stats.nba.com/stats/commonallplayers?IsOnlyCurrentSeason=0&amp;LeagueID=00&amp;Season=2015-16’
# the critical part of the URL is IsOnlyCurrentSeason=0. The 0 means all seasons.
response = requests.get(url) #get data
headers = response.json()[‘resultSets’][0]
players = response.json()[‘resultSets’][0][‘rowSet’]
players_df = pd.DataFrame(players, columns=headers[‘headers’]) #turn data into dataframe
{% endcodeblock %}</p>

<p>In the 1979-1980 season, the NBA started using the 3-point line. The 3-point has dramatically changed basketball, so players performed different before it. While this change in play was not instantaneous, it does not make sense to include players before the 3-point line.</p>

<p>{% codeblock lang:python %}
players_df[‘TO_YEAR’] = players_df[‘TO_YEAR’].apply(lambda x:int(x)) #change data in the TO_YEAR column from strings to numbers
players_df = players_df[players_df[‘TO_YEAR’]&gt;1979] #only use players after 3 pt line
{% endcodeblock %}</p>

<p>I have a list of all the players after 1979, but I want data about all these players. When grouping the players, I am not interested in how much a player played. Instead, I want to know HOW a player played. To remove variability associated with playing time, I will gather data that is standardized for 36 minutes of play. For example, if a player averages 4 points and 12 minutes a game, this player averages 12 points per 36 minutes.</p>

<p>Below, I have written a function that will collect every player’s performance per 36 minutes. The function collects data one player at a time, so its VERY slow. If you want the data, it can be found on my github (https://github.com/dvatterott/nba_project).</p>

<p>{% codeblock lang:python %}
def careerPer36(playerID):
    url = ‘http://stats.nba.com/stats/playercareerstats?LeagueID=00&amp;PerMode=Per36&amp;PlayerID=’+str(playerID)
    header_data = { #I pulled this header from the py goldsberry library
            ‘Accept-Encoding’: ‘gzip, deflate, sdch’,
            ‘Accept-Language’: ‘en-US,en;q=0.8’,
            ‘Upgrade-Insecure-Requests’: ‘1’,
            ‘User-Agent’: ‘Mozilla/5.0 (Windows NT 10.0; WOW64)’\
            ‘ AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.82 ‘\
            ‘Safari/537.36’,
            ‘Accept’: ‘text/html,application/xhtml+xml,application/xml;q=0.9’\
            ‘,image/webp,<em>/</em>;q=0.8’,
            ‘Cache-Control’: ‘max-age=0’,
            ‘Connection’: ‘keep-alive’
        }
    try:
        response = requests.get(url,headers = header_data) #get the data
        #print playerID #testing purposes
    except:
        time.sleep(5) #sometime the nba api gets mad about all the requests, so i take a quick break
        response = requests.get(url,headers = header_data)
    headers = response.json()[‘resultSets’][1] #find headers
    players = response.json()[‘resultSets’][1][‘rowSet’] #actual data
    players_df = pd.DataFrame(players, columns=headers[‘headers’]) #create dataframe
    return players_df</p>

<h1 id="df--pddataframe">df = pd.DataFrame()</h1>
<p>#player_list = players_df[‘PERSON_ID’]
#df = df.append([careerPer36(x) for x in player_list]) #BEWARE. this takes forever.
#df.index = range(np.size(df,0))
#df.to_pickle(‘nba_career_stats_‘+time.strftime(“%Y_%b_%d”, time.gmtime())+’.pkl’)
df = pd.read_pickle(‘nba_career_stats_2016_Feb_14.pkl’)
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
df.columns
{% endcodeblock %}</p>

<pre><code>Index([u'PLAYER_ID', u'LEAGUE_ID',   u'TEAM_ID',        u'GP',        u'GS',
             u'MIN',       u'FGM',       u'FGA',    u'FG_PCT',      u'FG3M',
            u'FG3A',   u'FG3_PCT',       u'FTM',       u'FTA',    u'FT_PCT',
            u'OREB',      u'DREB',       u'REB',       u'AST',       u'STL',
             u'BLK',       u'TOV',        u'PF',       u'PTS'],
      dtype='object')
</code></pre>

<p>Great! Now we have data that is scaled for 36 minutes of play (per36 data) from every player between 1979 and 2016. Above, I printed out the columns. I don’t want all this data. For instance, I do not care about how many minutes a player played. Also, some of the data is redundant. For instance, if I know a player’s field goal attempts (FGA) and field goal percentage (FG_PCT), I can calculate the number of made field goals (FGM). I removed the data columns that seem redundant. I do this because I do not want redundant data exercising too much influence on the grouping process.</p>

<p>Below, I create new data columns for 2 point field goal attempts and 2 point field goal percentage. I also remove all players who played less than 50 games. I do this because these players have not had the opportunity to establish consistent performance.</p>

<p>{% codeblock lang:python %}
df = df[df[‘GP’]&gt;50] #only players with more than 50 games.
df = df.fillna(0) #some players have “None” in some cells. Turn these into 0s
df[‘FG2M’] = df[‘FGM’]-df[‘FG3M’] #find number of 2pt field goals
df[‘FG2A’] = df[‘FGA’]-df[‘FG3A’] #2 point field goal attempts
df[‘FG2_PCT’] = df[‘FG2M’]/df[‘FG2A’] #2 point field goal percentage
saveIDs = df[‘PLAYER_ID’] #save player IDs for later
df = df.drop([‘PLAYER_ID’,’LEAGUE_ID’,’TEAM_ID’,’GP’,’GS’,’MIN’,’FGM’,’FGA’,’FG_PCT’,’FG3M’,’FTM’,’REB’,’PTS’,’FG2M’],1) #pull out unncessary columns
{% endcodeblock %}</p>

<p>It’s always important to visualize the data, so lets get an idea what we’re working with!</p>

<p>The plot below is called a scatter matrix. This type of plot will appear again, so lets go through it carefully. Each subplot has the feature (stat) labeled on its row which serves as its y-axis. The column feature serves as the x-axis. For example the subplot in the second column of the first row plots 3-point field goal attempts by 3-point field goal percentage. As you can see, players that have higher 3-point percentages tend to take more 3-pointers… makes sense.</p>

<p>On the diagonals, I plot the Kernel Density Estimation for the sample histogram. More players fall into areas where where the line is higher on the y-axis. For instance, no players shoot better than ~45% from behind the 3 point line.</p>

<p>One interesting part about scatter matrices is the plots below the diagonal are a reflection of the plots above the diagonal. For example, the data in the second column of the first row and the first column of the second row are the same. The only difference is the axes have switched.</p>

<p>{% codeblock lang:python %}
axs = pd.tools.plotting.scatter_matrix(df, alpha=0.2, figsize=(12, 12), diagonal=’kde’); #the diagonal will show kernel density
[ax.set_yticks([]) for ax in axs[:,0]] #turn off the ticks that take up way too much space in such a crammed figure
[ax.set_xticks([]) for ax in axs[-1,:]];
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/scatter_mat1_nba.png" /></p>

<p>There are a couple things to note in the graph above. First, there’s a TON of information there. Second, it looks like there are some strong correlations. For example, look at the subplots depicting offensive rebounds by defensive rebounds.</p>

<p>While I tried to throw out redundant data, I clearly did not throw out all redundant data. For example, players that are good 3-point shooters are probably also good free throw shooters. These players are simply good shooters, and being a good shooter contributes to multiple data columns above.</p>

<p>When I group the data, I do not want an ability such as shooting to contribute too much. I want to group players equally according to all their abilities. Below I use a PCA to seperate variance associated with the different “components” (e.g., shooting ability) of basketball performance.</p>

<p>For an explanation of PCA I recommend this link - https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/.</p>

<p>{% codeblock lang:python %}
from sklearn.decomposition import PCA
from sklearn.preprocessing import scale</p>

<p>X = df.as_matrix() #take data out of dataframe
X = scale(X) #standardize the data before giving it to the PCA.
#I standardize the data because some features such as PF or steals have lower magnitudes than other features such as FG2A
#I want both to contribute equally to the PCA, so I make sure they’re on the same scale.</p>

<p>pca = PCA() #great PCA object
pca.fit(X) #pull out principle components
var_expl = pca.explained_variance_ratio_ #find amount of variance explained by each component
tot_var_expl = np.array([sum(var_expl[0:i+1]) for i,x in enumerate(var_expl)]) #create vector with cumulative variance</p>

<p>plt.figure(figsize=(12,4)) #create cumulative proportion of variance plot
plt.subplot(1,2,1)
plt.plot(range(1,len(tot_var_expl)+1), tot_var_expl*100,’o-‘)
plt.axis([0, len(tot_var_expl)+1, 0, 100])
plt.xlabel(‘Number of PCA Components Included’)
plt.ylabel(‘Percentage of variance explained (%)’)</p>

<p>plt.subplot(1,2,2) #create scree plot
plt.plot(range(1,len(var_expl)+1), var_expl*100,’o-‘)
plt.axis([0, len(var_expl)+1, 0, 100])
plt.xlabel(‘PCA Component’);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/PCA_nba.png" /></p>

<p>On the left, I plot the amount of variance explained after including each additional PCA component. Using all the components explains all the variability, but notice how little the last few components contribute. It doesn’t make sense to include a component that only explains 1% of the variability…but how many components to include!?</p>

<p>I chose to include the first 5 components because no component after the 5th explained more than 5% of the data. This part of the analysis is admittedly arbitrary, but 5% is a relatively conservative cut-off.</p>

<p>Below is the fun part of the data. We get to look at what features contribute to the different principle components.</p>

<ul>
  <li>Assists and 3-point shooting contribute to the first component. I will call this the <strong>Outside Skills</strong> component.</li>
  <li>Free throw attempts, assists, turnovers and 2-point field goals contribute to the second component. I will call this the <strong>Rim Scoring</strong> component.</li>
  <li>Free throw percentage and 2-point field goal percentage  contribute to the third component. I will call this the <strong>Pure Points</strong> component.</li>
  <li>2-point field goal percentage and steals contribute to the fourth component. I will call this the <strong>Defensive Big Man</strong> component.</li>
  <li>3-point shooting and free throws contribute to the fifth component. I will call this the <strong>Dead Eye</strong> component.</li>
</ul>

<p>One thing to keep in mind here is that each component explains less variance than the last. So while 3 point shooting contributes to both the 1st and 5th component, more 3 point shooting variability is probably explained by the 1st component.</p>

<p>It would be great if we had a PCA component that was only shooting and another that was only rebounding since we typically conceive these to be different skills. Yet, there are multiple aspects of each skill. For example, a 3-point shooter not only has to be a dead-eye shooter, but also has to find ways to get open. Additionally, being good at “getting open” might be something akin to basketball IQ which would also contribute to assists and steals!</p>

<p>{% codeblock lang:python %}
factor_names = [‘Outside Skills’,’Rim Scoring’,’Pure Points’,’Defensive Big Man’,’Dead Eye’] #my component names
loadings_df = pd.DataFrame(pca.components_, columns=df.columns)
#loadings_df[0:5] #all the factor loadings appear below.
{% endcodeblock %}</p>

<p>Cool, we have our 5 PCA components. Now lets transform the data into our 5 component PCA space (from our 13 feature space - e.g., FG3A, FG3_PCT, ect.). To do this, we give each player a score on each of the 5 PCA components.</p>

<p>Next, I want to see how players cluster together based on their scores on these components. First, let’s investigate how using more or less clusters (i.e., groups) explains different amounts of variance.</p>

<p>{% codeblock lang:python %}
from scipy.spatial.distance import cdist, pdist, euclidean
from sklearn.cluster import KMeans
from sklearn import metrics</p>

<h1 id="httpstackoverflowcomquestions6645895calculating-the-percentage-of-variance-measure-for-k-means">http://stackoverflow.com/questions/6645895/calculating-the-percentage-of-variance-measure-for-k-means</h1>
<p>#The above link was helpful when writing this code.</p>

<p>reduced_data = PCA(n_components=5, whiten=True).fit_transform(X) #transform data into the 5 PCA components space
#kmeans assumes clusters have equal variance, and whitening helps keep this assumption.</p>

<p>k_range = range(2,31) #looking amount of variance explained by 1 through 30 cluster
k_means_var = [KMeans(n_clusters=k).fit(reduced_data) for k in k_range] #fit kmeans with 1 cluster to 30 clusters</p>

<h1 id="get-labels-and-calculate-silhouette-score">get labels and calculate silhouette score</h1>
<p>labels = [i.labels_ for i in k_means_var]
sil_score = [metrics.silhouette_score(reduced_data,i,metric=’euclidean’) for i in labels]</p>

<p>centroids = [i.cluster_centers_ for i in k_means_var] #get the center of each cluster
k_euclid = [cdist(reduced_data,cent,’euclidean’) for cent in centroids] #calculate distance between each item and each cluster center
dist = [np.min(ke,axis=1) for ke in k_euclid] #get the distance between each item and its cluster</p>

<p>wcss = [sum(d<strong>2) for d in dist] #within cluster sum of squares
tss = sum(pdist(reduced_data)</strong>2/reduced_data.shape[0]) #total sum of squares
bss = tss-wcss #between cluster sum of squares</p>

<p>plt.clf()
plt.figure(figsize=(12,4)) #create cumulative proportion of variance plot
plt.subplot(1,2,1)
plt.plot(k_range, bss/tss*100,’o-‘)
plt.axis([0, np.max(k_range), 0, 100])
plt.xlabel(‘Number of Clusters’)
plt.ylabel(‘Percentage of variance explained (%)’);</p>

<p>plt.subplot(1,2,2) #create scree plot
plt.plot(k_range, np.transpose(sil_score)<em>100,’o-‘)
plt.axis([0, np.max(k_range), 0, 40])
plt.xlabel(‘Number of Clusters’);
plt.ylabel(‘Average Silhouette Score</em>100’);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/cluster_eval_nba.png" /></p>

<p>As you can in the left hand plot, adding more clusters explains more of the variance, but there are diminishing returns. Each additional cluster explains a little less data than the last (much like each PCA component explained less variance than the previous component).</p>

<p>The particularly intersting point here is the point where the second derivative is greatest, when the amount of change changes the most (the elbow). The elbow occurs at the 6th cluster.</p>

<p>Perhaps not coincidently, 6 clusters also has the highest silhouette score (right hand plot). The silhouette score computes the average distance between a player and all other players in this player’s cluster. It then divides this distance by the distance between this player and all players in the next nearest cluster. Silhouette scores range between -1 and 1 (where negative one means the player is in the wrong cluster, 0 means the clusters completely overlap, and 1 means the clusters are extermely well separated).</p>

<p>Six clusters has the highest silhouette score at 0.19. 0.19 is not great, and suggests a different clustering algorithm might be better. More on this later.</p>

<p>Because 6 clusters is the elbow and has the highest silhouette score, I will use 6 clusters in my grouping analysis. Okay, now that I decided on 6 clusters lets see what players fall into what clusters!</p>

<p>{% codeblock lang:python %}
final_fit = KMeans(n_clusters=6).fit(reduced_data) #fit 6 clusters
df[‘kmeans_label’] = final_fit.labels_ #label each data point with its clusters
df[‘PLAYER_ID’] = saveIDs #of course we want to know what players are in what cluster
player_names = [pd.DataFrame(players_df[players_df[‘PERSON_ID’]==x][‘DISPLAY_LAST_COMMA_FIRST’]).to_string(header=False,index=False) for x in df[‘PLAYER_ID’]]
# because playerID #s mean nothing to me, lets get the names too
df[‘Name’] = player_names</p>

<h1 id="lets-also-create-a-dataframe-with-data-about-where-the-clusters-occur-in-the-5-component-pca-space">lets also create a dataframe with data about where the clusters occur in the 5 component PCA space.</h1>
<p>cluster_locs = pd.DataFrame(final_fit.cluster_centers_,columns=[‘component %s’% str(s) for s in range(np.size(final_fit.cluster_centers_,1))])
cluster_locs.columns = factor_names
{% endcodeblock %}</p>

<p>Awesome. Now lets see how all the clusters look. These clusters were created in 5 dimensional space, which is not easy to visualize. Below I plot another scatter matrix. The scatter matrix allows us to visualize the clusters in different 2D combinations of the 5D space.</p>

<p>{% codeblock lang:python %}
from scipy.stats import gaussian_kde
plt.clf()</p>

<p>centroids = final_fit.cluster_centers_ #find centroids so we can plot them
colors = [‘r’,’g’,’y’,’b’,’c’,’m’] #cluster colors
Clusters = [‘Cluster 0’,’Cluster 1’,’Cluster 2’,’Cluster 3’,’Cluster 4’,’Cluster 5’] #cluster…names</p>

<p>numdata, numvars = reduced_data.shape #players by PCA components
fig, axes = plt.subplots(nrows=numvars, ncols=numvars, figsize=(10,10)) #create a scatter matrix with 5**2 cells
fig.subplots_adjust(hspace=0.05, wspace=0.05)</p>

<p>recs=[]
for col in colors: #make some patches for the legend
    recs.append(mpl.patches.Rectangle((0,0),1,1,fc=col))</p>

<p>fig.legend(recs,Clusters,8,ncol=6) #create legend with patches above</p>

<p>for i,ax in enumerate(axes.flat):
    # Hide all ticks and labels
    plt.setp(ax.get_yticklabels(), visible=False) #tick labels are too much with this many subplots
    plt.setp(ax.get_xticklabels(), visible=False)
    ax.grid(False) #again, too much
    if i%5==0:ax.set_ylabel(factor_names[i/5]) #label outer y axes
    if i&gt;19:ax.set_xlabel(factor_names[i-20]) #label outer x axes</p>

<p>for i, j in zip(*np.triu_indices_from(axes, k=1)):
    for x, y in [(i,j), (j,i)]:
        #plot individual data points and cluster centers
        axes[y,x].plot(reduced_data[:, x], reduced_data[:, y], ‘k.’, markersize=2)
        axes[y,x].scatter(centroids[:,x], centroids[:,y],marker=’x’,s=169,linewidth=3,color=colors, zorder=10)</p>

<h1 id="create-kernel-density-estimation-for-each-pca-factor-on-the-diagonals">create kernel density estimation for each PCA factor on the diagonals</h1>
<p>for i, label in enumerate(factor_names):
    density = gaussian_kde(reduced_data[:,i])
    density.covariance_factor = lambda : .25
    density._compute_covariance()
    x = np.linspace(min(reduced_data[:,i]),max(reduced_data[:,1]))
    axes[i,i].plot(x,density(x))</p>

<p>{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/scatter_mat2_nba.png" /></p>

<p>In this plot above. I mark the center of a given cluster with an X. For example, Cluster 0 and Cluster 5 are both high in outside skills. Cluster 5 is also high in rim scoring, but low in pure points.</p>

<p>Below I look at the players in each cluster. The first thing I do is identify the player closest to the cluster’s center. I call this player the prototype. It is the player that most exemplifies a cluster.</p>

<p>I then show a picture of this player because… well I wanted to see who these players were.
I print out this player’s stats and the cluster’s centroid location.
Finally, I print out the first ten players in this cluster. This is the first ten players alphabetically. Not the ten players closest to cluster center.</p>

<p>{% codeblock lang:python %}
from IPython.display import display
from IPython.display import Image</p>

<p>name = player_names[np.argmin([euclidean(x,final_fit.cluster_centers_[0]) for x in reduced_data])] #find cluster prototype
PlayerID = str(int(df[df[‘Name’]==name][‘PLAYER_ID’])) #get players ID number
#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)
player = Image(url = ‘http://4.bp.blogspot.com/_RaOrchOImw8/S3mNk3exLeI/AAAAAAAAdZk/Hs-81mnXO_E/s400/Lloyd+Daniels.jpg’,width=100)
display(player)
#display(df[df[‘Name’]==name]) #prototype’s stats
display(cluster_locs[0:1]) #cluster centroid location
df[df[‘kmeans_label’]==0][‘Name’][:10] #first ten players in the cluster (alphabetically)
{% endcodeblock %}</p>

<p><img src="http://4.bp.blogspot.com/_RaOrchOImw8/S3mNk3exLeI/AAAAAAAAdZk/Hs-81mnXO_E/s400/Lloyd+Daniels.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.830457</td>
      <td>-0.930833</td>
      <td>0.28203</td>
      <td>-0.054093</td>
      <td>0.43606</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>16       Afflalo, Arron
20         Ainge, Danny
40           Allen, Ray
46        Alston, Rafer
50     Aminu, Al-Farouq
53      Andersen, David
54       Anderson, Alan
56      Anderson, Derek
60      Anderson, James
63       Anderson, Kyle
Name: Name, dtype: object
</code></pre>

<p>First, let me mention that cluster number is a purely categorical variable. Not ordinal. If you run this analysis, you will likely create clusters with similar players, but in a different order. For example, your cluster 1 might be my cluster 0.</p>

<p>Cluster 0 has the most players (25%; about 490 of the 1965 in this cluster analysis) and is red in the scatter matrix above.</p>

<p>Cluster 0 players are second highest in outside shooting (in the table above you can see their average score on the outside skills component is 0.83). These players are lowest in rim scoring (-0.93), so they do not draw many fouls - they are basically the snipers from the outside.</p>

<p>The prototype is Lloyd Daniels who takes a fair number of 3s. I wouldn’t call 31% a dominant 3-point percentage, but its certainly not bad. Notably, Lloyd Daniels doesn’t seem to do much but shoot threes, as 55% of his shots come from the great beyond.</p>

<p>Cluster 0 notable players include Andrea Bargnani, JJ Barea, Danilo Gallinari, and Brandon Jennings. Some forwards. Some Guards. Mostly good shooters.</p>

<p>On to Cluster 1… I probably should have made a function from this code, but I enjoyed picking the players pictures too much.</p>

<p>{% codeblock lang:python %}
name = player_names[np.argmin([euclidean(x,final_fit.cluster_centers_[1]) for x in reduced_data])]
PlayerID = str(int(df[df[‘Name’]==name][‘PLAYER_ID’]))
#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)
player = Image(url = ‘https://allshookdown.files.wordpress.com/2009/06/laettner_200_921121.jpg?w=200&amp;h=300’,width=100)
display(player)
#display(df[df[‘Name’]==name])
display(cluster_locs[1:2])
df[df[‘kmeans_label’]==1][‘Name’][:10]
{% endcodeblock %}</p>

<p><img src="https://allshookdown.files.wordpress.com/2009/06/laettner_200_921121.jpg?w=200&amp;h=300" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>-0.340177</td>
      <td>1.008111</td>
      <td>1.051622</td>
      <td>-0.150204</td>
      <td>0.599516</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>1         Abdul-Jabbar, Kareem
4         Abdur-Rahim, Shareef
9                 Adams, Alvan
18               Aguirre, Mark
75      Antetokounmpo, Giannis
77            Anthony, Carmelo
85             Arenas, Gilbert
121                 Baker, Vin
133           Barkley, Charles
148            Bates, Billyray
Name: Name, dtype: object
</code></pre>

<p>Cluster 1 is green in the scatter matrix and includes about 14% of players.</p>

<p>Cluster 1 is highest on the rim scoring, pure points, and Dead Eye components. These players get the ball in the hoop.</p>

<p>Christian Laettner is the prototype. He’s a solid scoring forward.</p>

<p>Gilbert Arenas stands out in the first ten names as I was tempted to think of this cluster as big men, but it really seems to be players who shoot, score, and draw fouls.</p>

<p>Cluster 1 Notable players include James Harden,Kevin Garnet, Kevin Durant, Tim Duncan, Kobe, Lebron, Kevin Martin, Shaq, Anthony Randolph??, Kevin Love, Derrick Rose, and Michael Jordan.</p>

<p>{% codeblock lang:python %}
name = player_names[np.argmin([euclidean(x,final_fit.cluster_centers_[2]) for x in reduced_data])]
PlayerID = str(int(df[df[‘Name’]==name][‘PLAYER_ID’]))
#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)
player = Image(url = ‘http://imageocd.com/images/nba10/doug-west-wallpaper-height-weight-position-college-high-school/doug-west.jpg’,width=100)
display(player)
#display(df[df[‘Name’]==name])
display(cluster_locs[2:3])
df[df[‘kmeans_label’]==2][‘Name’][:10]
{% endcodeblock %}</p>

<p><img src="http://imageocd.com/images/nba10/doug-west-wallpaper-height-weight-position-college-high-school/doug-west.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.013618</td>
      <td>0.101054</td>
      <td>0.445377</td>
      <td>-0.347974</td>
      <td>-1.257634</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>2      Abdul-Rauf, Mahmoud
3       Abdul-Wahad, Tariq
5           Abernethy, Tom
10           Adams, Hassan
14         Addison, Rafael
24            Alarie, Mark
27      Aldridge, LaMarcus
31     Alexander, Courtney
35           Alford, Steve
37            Allen, Lavoy
Name: Name, dtype: object
</code></pre>

<p>Cluster 2 is yellow in the scatter matrix and includes about 17% of players.</p>

<p>Lots of big men who are not outside shooters and don’t draw many fouls. These players are strong 2 point shooters and free throw shooters. I think of these players as mid-range shooters. Many of the more recent Cluster 2 players are forwards since mid-range guards do not have much of a place in the current NBA.</p>

<p>Cluster 2’s prototype is Doug West. Doug West shoots well from the free throw line and on 2-point attempts, but not the 3-point line. He does not draw many fouls or collect many rebounds.</p>

<p>Cluster 2 noteable players include LaMarcus Aldridge, Tayshaun Prince, Thaddeus Young, and Shaun Livingston</p>

<p>{% codeblock lang:python %}
name = player_names[np.argmin([euclidean(x,final_fit.cluster_centers_[3]) for x in reduced_data])]
PlayerID = str(int(df[df[‘Name’]==name][‘PLAYER_ID’]))
#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)
player = Image(url = ‘http://4.bp.blogspot.com/_f5MWZq1BJXI/TCDRy3v6m9I/AAAAAAAAACc/Ux8M7uiadoc/s400/cato.jpg’,width=100)
display(player)
#display(df[df[‘Name’]==name])
display(cluster_locs[3:4])
df[df[‘kmeans_label’]==3][‘Name’][:10]
{% endcodeblock %}</p>

<p><img src="http://4.bp.blogspot.com/_f5MWZq1BJXI/TCDRy3v6m9I/AAAAAAAAACc/Ux8M7uiadoc/s400/cato.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>-1.28655</td>
      <td>-0.467105</td>
      <td>-0.133546</td>
      <td>0.905368</td>
      <td>0.000679</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>7            Acres, Mark
8            Acy, Quincy
13         Adams, Steven
15          Adrien, Jeff
21        Ajinca, Alexis
26         Aldrich, Cole
34     Alexander, Victor
45       Alston, Derrick
51         Amundson, Lou
52       Andersen, Chris
Name: Name, dtype: object
</code></pre>

<p>Cluster 3 is blue in the scatter matrix and includes about 16% of players.</p>

<p>Cluster 3 players do not have outside skills such as assists and 3-point shooting (they’re last in outside skills). They do not draw many fouls or shoot well from the free throw line. These players do not shoot often, but have a decent shooting percentage. This is likely because they only shoot when wide open next to the hoop.</p>

<p>Cluster 3 players are highest on the defensive big man component. They block lots of shots and collect lots of rebounds.</p>

<p>The Cluster 3 prototype is Kelvin Cato. Cato is not and outside shooter and he only averages 7.5 shots per 36, but he makes these shots at a decent clip. Cato averages about 10 rebounds per 36.</p>

<p>Notable Cluster 3 players include Andrew Bogut, Tyson Chandler, Andre Drummond, Kawahi Leonard??, Dikembe Mutumbo, and Hassan Whiteside.</p>

<p>{% codeblock lang:python %}
name = player_names[np.argmin([euclidean(x,final_fit.cluster_centers_[4]) for x in reduced_data])]
PlayerID = str(int(df[df[‘Name’]==name][‘PLAYER_ID’]))
#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)
player = Image(url = ‘http://www.thenolookpass.com/wp-content/uploads/2012/01/IMG-724x1024.jpg’, width=100) #a photo just for fun
display(player)
#display(df[df[‘Name’]==name])
display(cluster_locs[4:5])
df[df[‘kmeans_label’]==4][‘Name’][:10]
{% endcodeblock %}</p>

<p><img src="http://www.thenolookpass.com/wp-content/uploads/2012/01/IMG-724x1024.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>-0.668445</td>
      <td>0.035927</td>
      <td>-0.917479</td>
      <td>-1.243347</td>
      <td>0.244897</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>0         Abdelnaby, Alaa
17          Ager, Maurice
28       Aleksinas, Chuck
33         Alexander, Joe
36          Allen, Jerome
48          Amaechi, John
49          Amaya, Ashraf
74          Anstey, Chris
82         Araujo, Rafael
89     Armstrong, Brandon
Name: Name, dtype: object
</code></pre>

<p>Cluster 4 is cyan in the scatter matrix above and includes the least number of players (about 13%).</p>

<p>Cluster 4 players are not high on outsize skills. They are average on rim scoring. They do not score many points, and they don’t fill up the defensive side of the stat sheet. These players don’t seem like all stars.</p>

<p>Looking at Doug Edwards’ stats - certainly not a 3-point shooter. I guess a good description of cluster 4 players might be … NBA caliber bench warmers.</p>

<p>Cluster 4’s notable players include Yi Jianlian and Anthony Bennet….yeesh</p>

<p>{% codeblock lang:python %}
name = player_names[np.argmin([euclidean(x,final_fit.cluster_centers_[5]) for x in reduced_data])]
#PlayerID = str(int(df[df[‘Name’]==name][‘PLAYER_ID’]))
PlayerID = str(76993) #Two Gerald Hendersons!
#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”, width=100)
player = Image(url = ‘http://cdn.fansided.com/wp-content/blogs.dir/18/files/2014/04/b__gerald_henderson_82.jpg’, width=100)
display(player)
#display(df[df[‘PLAYER_ID’]==76993])
display(cluster_locs[5:])
df[df[‘kmeans_label’]==5][‘Name’][:10]
{% endcodeblock %}</p>

<p><img src="http://cdn.fansided.com/wp-content/blogs.dir/18/files/2014/04/b__gerald_henderson_82.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.890984</td>
      <td>0.846109</td>
      <td>-0.926444</td>
      <td>0.735306</td>
      <td>-0.092395</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>12          Adams, Michael
30         Alexander, Cory
41             Allen, Tony
62         Anderson, Kenny
65      Anderson, Mitchell
78           Anthony, Greg
90      Armstrong, Darrell
113           Bagley, John
126          Banks, Marcus
137         Barrett, Andre
Name: Name, dtype: object
</code></pre>

<p>Cluster 5 is magenta in the scatter matrix and includes 16% of players.</p>

<p>Cluster 5 players are highest in outside skills and second highest in rim scoring yet these players are dead last in pure points. It seems they score around the rim, but do not draw many fouls. They are second highest in defensive big man.</p>

<p>Gerald Henderson Sr is the prototype. Henderson is a good 3 point and free throw shooter but does not draw many fouls. He has lots of assists and steals.</p>

<p>Of interest mostly because it generates an error in my code, Gerald Henderson Jr is in cluster 2 - the mid range shooters.</p>

<p>Notable cluster 5 players include Mugsy Bogues, MCW, Jeff Hornacek, Magic Johnson, Jason Kidd, Steve Nash, Rajon Rando, John Stockton. Lots of guards.</p>

<p>In the cell below, I plot the percentage of players in each cluster.</p>

<p>{% codeblock lang:python %}
plt.clf()
plt.hist(df[‘kmeans_label’], normed=True,bins=[0,1,2,3,4,5,6],rwidth = 0.5)
plt.xticks([0.5,1.5,2.5,3.5,4.5,5.5],[‘Group 0’,’Group 1’,’Group 2’,’Goup 3’,’Group 4’,’Group 5’])
plt.ylabel(‘Percentage of Players in Each Cluster’);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/cluster_inc_nba.png" /></p>

<p>I began this post by asking whether player positions is the most natural way to group NBA players. The clustering analysis here suggests not.</p>

<p>Here’s my take on the clusters: Cluster 0 is pure shooters, Cluster 1 is talented scorers, Cluster 2 is mid-range shooters, Cluster 3 is defensive big-men, Cluster 4 is bench warmers, Cluster 5 is distributors. We might call the “positions” shooters, scorers, rim protectors, and distributors.</p>

<p>It’s possible that our notion of position comes more from defensive performance than offensive. On defense, a player must have a particular size and agility to guard a particular opposing player. Because of this, a team will want a range of sizes and agility - strong men to defend the rim and quick men to defend agile ball carriers. Box scores are notoriously bad at describing defensive performance. This could account for the lack of “positions” in my cluster.</p>

<p>I did not include player height and weight in this analysis. I imagine height and weight might have made clusters that resemble the traditional positions. I chose to not include height and weight because these are player attributes; not player performance.</p>

<p>After looking through all the groups one thing that stands out to me is the lack of specialization. For example we did not find a single cluster of incredible 3-point shooters. Cluster 1 includes many great shooters, but it’s not populated exclusively by great shooters. It would be interesting if adding additional clusters to the analysis could find more specific clusters such as big-men that can shoot from the outside (e.g., Dirk) or high-volume scorers (e.g., Kobe).</p>

<p>I tried to list some of the aberrant cluster choices in the notable players to give you an idea for the amount of error in the clustering. These aberrant choices are not errors, they are simply an artifact of how k-means defines clusters. Using a different clustering algorithm would produce different clusters. On that note, the silhouette score of this clustering model is not great, yet the clustering algorithm definitely found similar players, so its not worthless. Nonetheless, clusters of NBA players might not be spherical. This would prevent a high silhouette score. Trying a different algorithm without the spherical clusters assumption would definitely be worthwhile.</p>

<p>Throughout this entire analysis, I was tempted to think about group membership, as a predictor of a player’s future performance. For instance, when I saw Karl Anthony Towns in the same cluster as Kareem Abdul-Jabbar, I couldn’t help but think this meant good things for Karl Anthony Towns. Right now, this doesn’t seem justified. No group included less than 10% of players so not much of an oppotunity for a uniformly “star” group to form. Each group contained some good and some bad players. Could more clusters change this? I plan on examining whether more clusters can improve the clustering algorithm’s ability to find clusters of exclusively quality players. If it works, I’ll post it here.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating NBA Shot Charts]]></title>
    <link href="https://danvatterott.com/blog/2015/12/22/creating-nba-shot-charts/"/>
    <updated>2015-12-22T13:21:06-06:00</updated>
    <id>https://danvatterott.com/blog/2015/12/22/creating-nba-shot-charts</id>
    <content type="html"><![CDATA[<p>Here I create shot charts depicting both shooting percentage and the number of shots taken at different court locations, similar to those produced on Austin Clemens’ website (http://www.austinclemens.com/shotcharts/).</p>

<p>To create the shooting charts, I looked to a post by Savvas Tjortjoglou (http://savvastjortjoglou.com/nba-shot-sharts.html). Savvas’ post is great, but his plots only depict the number of shots taken at different locations.</p>

<p>I’m interested in both the number of shots AND the shooting percentage at different locations. This requires a little bit more work. Here’s how I did it.</p>

<p>{% codeblock lang:python %}
#import some libraries and tell ipython we want inline figures rather than interactive figures. 
%matplotlib inline
import matplotlib.pyplot as plt, pandas as pd, numpy as np, matplotlib as mpl
{% endcodeblock %}</p>

<p>First, we have to acquire shooting data about each player. I retrieved the data from NBA.com’s API using code from Savvas Tjortjoglou’s post.</p>

<p>I won’t show you the output of this function. If you’re interested in the details, I recommend Savvas Tjortjoglou’s post.</p>

<p>{% codeblock lang:python %}
def aqcuire_shootingData(PlayerID,Season):
    import requests
    shot_chart_url = ‘http://stats.nba.com/stats/shotchartdetail?CFID=33&amp;CFPARAMS=’+Season+’&amp;ContextFilter=’\
                    ‘&amp;ContextMeasure=FGA&amp;DateFrom=&amp;DateTo=&amp;GameID=&amp;GameSegment=&amp;LastNGames=0&amp;LeagueID=’\
                    ‘00&amp;Location=&amp;MeasureType=Base&amp;Month=0&amp;OpponentTeamID=0&amp;Outcome=&amp;PaceAdjust=’\
                    ‘N&amp;PerMode=PerGame&amp;Period=0&amp;PlayerID=’+PlayerID+’&amp;PlusMinus=N&amp;Position=&amp;Rank=’\
                    ‘N&amp;RookieYear=&amp;Season=’+Season+’&amp;SeasonSegment=&amp;SeasonType=Regular+Season&amp;TeamID=’\
                    ‘0&amp;VsConference=&amp;VsDivision=&amp;mode=Advanced&amp;showDetails=0&amp;showShots=1&amp;showZones=0’
    response = requests.get(shot_chart_url)
    headers = response.json()[‘resultSets’][0][‘headers’]
    shots = response.json()[‘resultSets’][0][‘rowSet’]
    shot_df = pd.DataFrame(shots, columns=headers)
    return shot_df
{% endcodeblock %}</p>

<p>Next, we need to draw a basketball court which we can draw the shot chart on. This basketball court has to use the same coordinate system as NBA.com’s API. For instance, 3pt shots have to be X units from hoop and layups have to be Y units from the hoop. Again, I recycle code from Savvas Tjortjoglou (phew! figuring out NBA.com’s coordinate system would have taken me awhile).</p>

<p>{% codeblock lang:python %}
def draw_court(ax=None, color=’black’, lw=2, outer_lines=False):
    from matplotlib.patches import Circle, Rectangle, Arc
    if ax is None:
        ax = plt.gca()
    hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False)
    backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color)
    outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color,
                          fill=False)
    inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color,
                          fill=False)
    top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180,
                         linewidth=lw, color=color, fill=False)
    bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0,
                            linewidth=lw, color=color, linestyle=’dashed’)
    restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw,
                     color=color)
    corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw,
                               color=color)
    corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color)
    three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw,
                    color=color)
    center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0,
                           linewidth=lw, color=color)
    center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0,
                           linewidth=lw, color=color)
    court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw,
                      bottom_free_throw, restricted, corner_three_a,
                      corner_three_b, three_arc, center_outer_arc,
                      center_inner_arc]
    if outer_lines:
        outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw,
                                color=color, fill=False)
        court_elements.append(outer_lines)</p>

<pre><code>for element in court_elements:
    ax.add_patch(element)

ax.set_xticklabels([])
ax.set_yticklabels([])
ax.set_xticks([])
ax.set_yticks([])
return ax {% endcodeblock %}
</code></pre>

<p>We want to create an array of shooting percentages across the different locations in our plot. I decided to group locations into evenly spaced hexagons using matplotlib’s hexbin function (http://matplotlib.org/api/pyplot_api.html). This function will count the number of times a shot is taken from a location in each of the hexagons.</p>

<p>The hexagons are evenly spaced across the xy grid. The variable “gridsize” controls the number of hexagons. The variable “extent” controls where the first hexagon and last hexagon are drawn (ordinarily the first hexagon is drawn based on the location of the first shot).</p>

<p>Computing shooting percentages requires counting the number of made and taken shots in each hexagon, so I run hexbin once using all shots taken and once using only the location of made shots. Then I simply divide the number of made shots by taken shots at each location.</p>

<p>{% codeblock lang:python %}
def find_shootingPcts(shot_df, gridNum):
    x = shot_df.LOC_X[shot_df[‘LOC_Y’]&lt;425.1] #i want to make sure to only include shots I can draw
    y = shot_df.LOC_Y[shot_df[‘LOC_Y’]&lt;425.1]</p>

<pre><code>x_made = shot_df.LOC_X[(shot_df['SHOT_MADE_FLAG']==1) &amp; (shot_df['LOC_Y']&lt;425.1)]
y_made = shot_df.LOC_Y[(shot_df['SHOT_MADE_FLAG']==1) &amp; (shot_df['LOC_Y']&lt;425.1)]

#compute number of shots made and taken from each hexbin location
hb_shot = plt.hexbin(x, y, gridsize=gridNum, extent=(-250,250,425,-50));
plt.close() #don't want to show this figure!
hb_made = plt.hexbin(x_made, y_made, gridsize=gridNum, extent=(-250,250,425,-50),cmap=plt.cm.Reds);
plt.close()

#compute shooting percentage
ShootingPctLocs = hb_made.get_array() / hb_shot.get_array()
ShootingPctLocs[np.isnan(ShootingPctLocs)] = 0 #makes 0/0s=0
return (ShootingPctLocs, hb_shot) {% endcodeblock %}
</code></pre>

<p>I really liked how Savvas Tjortjoglou included players’ pictures in his shooting charts, so I recycled this part of his code too. The picture will appear in the bottom right hand corner of the shooting chart</p>

<p>{% codeblock lang:python %}
def acquire_playerPic(PlayerID, zoom, offset=(250,400)):
    from matplotlib import  offsetbox as osb
    import urllib
    pic = urllib.urlretrieve(“http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”,PlayerID+”.png”)
    player_pic = plt.imread(pic[0])
    img = osb.OffsetImage(player_pic, zoom)
    #img.set_offset(offset)
    img = osb.AnnotationBbox(img, offset,xycoords=’data’,pad=0.0, box_alignment=(1,0), frameon=False)
    return img
{% endcodeblock %}</p>

<p>I want to depict shooting percentage using a sequential colormap - more red circles = better shooting percentage. The “reds” colormap looks great, but would depict a 0% shooting percentage as white (http://matplotlib.org/users/colormaps.html), and white circles will not appear in my plots. I want 0% shooting to be slight pink, so below I modify the reds colormap.</p>

<p>{% codeblock lang:python %}
#cmap = plt.cm.Reds
#cdict = cmap._segmentdata
cdict = { 
    ‘blue’: [(0.0, 0.6313725709915161, 0.6313725709915161), (0.25, 0.4470588266849518, 0.4470588266849518), (0.5, 0.29019609093666077, 0.29019609093666077), (0.75, 0.11372549086809158, 0.11372549086809158), (1.0, 0.05098039284348488, 0.05098039284348488)], 
    ‘green’: [(0.0, 0.7333333492279053, 0.7333333492279053), (0.25, 0.572549045085907, 0.572549045085907), (0.5, 0.4156862795352936, 0.4156862795352936), (0.75, 0.0941176488995552, 0.0941176488995552), (1.0, 0.0, 0.0)], 
    ‘red’: [(0.0, 0.9882352948188782, 0.9882352948188782), (0.25, 0.9882352948188782, 0.9882352948188782), (0.5, 0.9843137264251709, 0.9843137264251709), (0.75, 0.7960784435272217, 0.7960784435272217), (1.0, 0.40392157435417175, 0.40392157435417175)]
}</p>

<p>mymap = mpl.colors.LinearSegmentedColormap(‘my_colormap’, cdict, 1024)
{% endcodeblock %}</p>

<p>Okay, now lets put it all together. The large function below will use the functions above to create a shot chart depicting shooting percentage as the color of a circle (more red = better shooting %) and the number of shots as the size of a circle (larger circle = more shots). One note about the circle sizes, the size of a circle can increase until they start to overlap. When they start to overlap, I prevent them from growing.</p>

<p>In this function, I compute the shooting percentages and number of shots at each location. Then I draw circles depicting the number of shots taken at that location (circle size) and the shooting percentage at that location (circle color).</p>

<p>{% codeblock lang:python %}
def shooting_plot(shot_df, plot_size=(12,8),gridNum=30):
    from matplotlib.patches import Circle
    x = shot_df.LOC_X[shot_df[‘LOC_Y’]&lt;425.1]
    y = shot_df.LOC_Y[shot_df[‘LOC_Y’]&lt;425.1]</p>

<pre><code>#compute shooting percentage and # of shots
(ShootingPctLocs, shotNumber) = find_shootingPcts(shot_df, gridNum)

#draw figure and court
fig = plt.figure(figsize=plot_size)#(12,7)
cmap = mymap #my modified colormap
ax = plt.axes([0.1, 0.1, 0.8, 0.8]) #where to place the plot within the figure
draw_court(outer_lines=False)
plt.xlim(-250,250)
plt.ylim(400, -25)

#draw player image
zoom = np.float(plot_size[0])/(12.0*2) #how much to zoom the player's pic. I have this hackily dependent on figure size
img = acquire_playerPic(PlayerID, zoom)
ax.add_artist(img)
         
#draw circles
for i, shots in enumerate(ShootingPctLocs): 
    restricted = Circle(shotNumber.get_offsets()[i], radius=shotNumber.get_array()[i],
                        color=cmap(shots),alpha=0.8, fill=True)
    if restricted.radius &gt; 240/gridNum: restricted.radius=240/gridNum
    ax.add_patch(restricted)

#draw color bar
ax2 = fig.add_axes([0.92, 0.1, 0.02, 0.8])
cb = mpl.colorbar.ColorbarBase(ax2,cmap=cmap, orientation='vertical')
cb.set_label('Shooting %')
cb.set_ticks([0.0, 0.25, 0.5, 0.75, 1.0])
cb.set_ticklabels(['0%','25%', '50%','75%', '100%'])

plt.show()
return ax {% endcodeblock %}
</code></pre>

<p>Ok, thats it! Now, because I’m a t-wolves fan, I’ll output the shot charts of top 6 t-wolves in minutes this year.</p>

<p>{% codeblock lang:python %}
PlayerID = ‘203952’ #andrew wiggins
shot_df = aqcuire_shootingData(PlayerID,’2015-16’)
ax = shooting_plot(shot_df, plot_size=(12,8));
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/shotChart_wiggins.png" /></p>

<p>{% codeblock lang:python %}
PlayerID = ‘1626157’ #karl anthony towns
shot_df = aqcuire_shootingData(PlayerID,’2015-16’)
ax = shooting_plot(shot_df, plot_size=(12,8));
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/shotChart_towns.png" /></p>

<p>{% codeblock lang:python %}
PlayerID = ‘203897’ #zach lavine
shot_df = aqcuire_shootingData(PlayerID,’2015-16’)
ax = shooting_plot(shot_df, plot_size=(12,8));</p>

<p>{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/shotChart_lavine.png" /></p>

<p>{% codeblock lang:python %}
PlayerID = ‘203476’ #gorgui deing
shot_df = aqcuire_shootingData(PlayerID,’2015-16’)
ax = shooting_plot(shot_df, plot_size=(12,8));</p>

<p>{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/shotChart_dieng.png" /></p>

<p>{% codeblock lang:python %}
PlayerID = ‘2755’ #kevin martin
shot_df = aqcuire_shootingData(PlayerID,’2015-16’)
ax = shooting_plot(shot_df, plot_size=(12,8));
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/shotChart_martin.png" /></p>

<p>{% codeblock lang:python %}
PlayerID = ‘201937’ #ricky rubio
shot_df = aqcuire_shootingData(PlayerID,’2015-16’)
ax = shooting_plot(shot_df, plot_size=(12,8));
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/shotChart_rubio.png" /></p>

<p>One concern with my plots is the use of hexbin. It’s a bit hacky. In particular, it does not account for the nonlinearity produced by the 3 point line (some hexbins include both long 2-pt shots and 3-pt shots). It would be nice to limit some bins to 3-pt shots, but I can’t think of a way to do this without hardcoding the locations. One advantage with the hexbin method is I can easily change the number of bins. I’m not sure I could produce equivalent flexibility with a plot that bins 2-pt and 3-pt shots seperately.</p>

<p>Another concern is my plots treat all shots as equal, which is not fair. Shooting 40% from the restricted area and behind the 3-pt line are very different. Austin Clemens accounts for this by plotting shooting percentage relative to league average. Maybe I’ll implement something similar in the future.</p>

]]></content>
  </entry>
  
</feed>
