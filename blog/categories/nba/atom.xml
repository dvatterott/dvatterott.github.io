<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Nba | Dan Vatterott]]></title>
  <link href="http://www.danvatterott.com/blog/categories/nba/atom.xml" rel="self"/>
  <link href="http://www.danvatterott.com/"/>
  <updated>2016-04-29T23:02:08-04:00</updated>
  <id>http://www.danvatterott.com/</id>
  <author>
    <name><![CDATA[Dan Vatterott]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Revisiting NBA Career Predictions From Rookie Performance]]></title>
    <link href="http://www.danvatterott.com/blog/2016/04/08/revisiting-nba-career-predictions-from-rookie-performance/"/>
    <updated>2016-04-08T21:19:25-04:00</updated>
    <id>http://www.danvatterott.com/blog/2016/04/08/revisiting-nba-career-predictions-from-rookie-performance</id>
    <content type="html"><![CDATA[<p>In this post I wanted to do a quick follow up to a previous post about <a href="http://www.danvatterott.com/blog/2016/03/20/predicting-career-performance-from-rookie-performance/">predicting career nba performance from rookie year data</a>.</p>

<p>After my previous post, I started to get a little worried about my career prediction model. Specifically, I started to wonder about whether my model was <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">underfitting or overfitting the data</a>. Underfitting occurs when the model has too much “bias” and cannot accomodate the data’s shape. <a href="https://en.wikipedia.org/wiki/Overfitting">Overfitting</a> occurs when the model is too flexible and can account for all variance in a data set - even variance due to noise. In this post, I will quickly re-create my player prediction model, and investigate whether underfitting and overfitting are a problem.</p>

<p>Because this post largely repeats a previous one, I haven’t written quite as much about the code. If you would like to read more about the code, see my previous posts.</p>

<p>As usual, I will post all code as a jupyter notebook on my <a href="https://github.com/dvatterott/jupyter_notebooks/blob/master/nba_rookie_regression2.ipynb">github</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#import some libraries and tell ipython we want inline figures rather than interactive figures. </span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span><span class="o">,</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span><span class="o">,</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">matplotlib</span> <span class="kn">as</span> <span class="nn">mpl</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="kn">from</span> <span class="o">&lt;</span><span class="n">strong</span><span class="o">&gt;</span><span class="n">future</span><span class="o">&lt;/</span><span class="n">strong</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">print_function</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</span><span class='line'><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">mpl_style</span> <span class="o">=</span> <span class="err">‘</span><span class="n">default</span><span class="err">’</span> <span class="c">#load matplotlib for plotting</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="err">‘</span><span class="n">ggplot</span><span class="err">’</span><span class="p">)</span> <span class="c">#im addicted to ggplot. so pretty.</span>
</span><span class='line'><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="err">‘</span><span class="n">font</span><span class="o">.</span><span class="n">family</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="err">‘</span><span class="n">Bitstream</span> <span class="n">Vera</span> <span class="n">Sans</span><span class="err">’</span><span class="p">]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Load the data. Reminder - this data is still available on my <a href="https://github.com/dvatterott/nba_project">github</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">rookie_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="err">‘</span><span class="n">nba_bballref_rookie_stats_2016_Mar_15</span><span class="o">.</span><span class="n">pkl</span><span class="err">’</span><span class="p">)</span> <span class="c">#here’s the rookie year data&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">rook_games</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="p">[</span><span class="err">‘</span><span class="n">Career</span> <span class="n">Games</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">50</span>
</span><span class='line'><span class="n">rook_year</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="p">[</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span> <span class="nb">id</span><span class="o">=</span><span class="s">&quot;remove-rookies-from-before-1980-and-who-have-played-less-than-50-games-i-also-remove-some-features-that-seem-irrelevant-or-unfair&quot;</span><span class="o">&gt;</span><span class="n">remove</span> <span class="n">rookies</span> <span class="kn">from</span> <span class="nn">before</span> <span class="mi">1980</span> <span class="ow">and</span> <span class="n">who</span> <span class="n">have</span> <span class="n">played</span> <span class="n">less</span> <span class="n">than</span> <span class="mi">50</span> <span class="n">games</span><span class="o">.</span> <span class="n">I</span> <span class="n">also</span> <span class="n">remove</span> <span class="n">some</span> <span class="n">features</span> <span class="n">that</span> <span class="n">seem</span> <span class="n">irrelevant</span> <span class="ow">or</span> <span class="n">unfair</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">rookie_df_games</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="p">[</span><span class="n">rook_games</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">rook_year</span><span class="p">]</span> <span class="c">#only players with more than 50 games. </span>
</span><span class='line'><span class="n">rookie_df_drop</span> <span class="o">=</span> <span class="n">rookie_df_games</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Career</span> <span class="n">Games</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Name</span><span class="err">’</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Load more data, and normalize it data for the <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA transformation</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="err">‘</span><span class="n">nba_bballref_career_stats_2016_Mar_15</span><span class="o">.</span><span class="n">pkl</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">G</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">50</span><span class="p">]</span>
</span><span class='line'><span class="n">df_drop</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Name</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">G</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">GS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">MP</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FG</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FGA</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FG</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="mi">3</span><span class="n">P</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="mi">2</span><span class="n">P</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FT</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TRB</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">PTS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">ORtg</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DRtg</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">PER</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TS</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="mi">3</span><span class="n">PAr</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FTr</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">ORB</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DRB</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TRB</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">AST</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">STL</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">BLK</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TOV</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">USG</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">OWS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DWS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">WS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">OBPM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DBPM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">BPM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">VORP</span><span class="err">’</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">df_drop</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe</span>
</span><span class='line'><span class="n">ScaleModel</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">ScaleModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Use <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-means</a> to group players according to their performance. See my post on <a href="http://www.danvatterott.com/blog/2016/02/21/grouping-nba-players/">grouping players</a> for more info.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">reduced_model</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">reduced_data</span> <span class="o">=</span> <span class="n">reduced_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#transform data into the 5 PCA components space</span>
</span><span class='line'><span class="n">final_fit</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">)</span> <span class="c">#fit 6 clusters</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span> <span class="c">#label each data point with its clusters</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Run a separate regression on each group of players. I calculate mean absolute error (a variant of <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error</a>) for each model. I used mean absolute error because it’s on the same scale as the data, and easier to interpret. I will use this later to evaluate just how accurate these models are. Quick reminder - I am trying to predict career WS/48 with MANY predictor variables from rookie year performance such rebounding and scoring statistics.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="kn">as</span> <span class="nn">sm</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span> <span class="c">#import function for calculating mean squared error.&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">X</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span><span class="p">][</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span>
</span><span class='line'><span class="n">rookie_df_drop</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_labels</span> <span class="c">#label each data point with its clusters&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">));</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">estHold</span> <span class="o">=</span> <span class="p">[[],[],[],[],[],[]]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">score</span> <span class="o">=</span> <span class="p">[]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">)):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">Grouper</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span> <span class="c">#do one regression at a time</span>
</span><span class='line'><span class="n">Yearer</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;Year&#39;</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Grouper</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">Yearer</span><span class="p">]</span>
</span><span class='line'><span class="n">Y</span> <span class="o">=</span> <span class="n">Group1</span><span class="p">[</span><span class="s">&#39;WS/48&#39;</span><span class="p">]</span> <span class="c">#get predictor data</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">rookie_df_drop</span><span class="p">[</span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">]</span>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span> <span class="c">#get predicted data</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe    </span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c"># Adds a constant term to the predictor</span>
</span><span class='line'><span class="n">est</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="c">#fit with linear regression model</span>
</span><span class='line'><span class="n">est</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</span><span class='line'><span class="n">estHold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">est</span>
</span><span class='line'><span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span> <span class="c">#calculate the mean squared error</span>
</span><span class='line'><span class="c">#print est.summary()</span>
</span><span class='line'>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c">#plot each regression&#39;s prediction against actual data</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">Y</span><span class="p">,</span><span class="s">&#39;o&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">&#39;axes.color_cycle&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="s">&#39;-&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Group </span><span class="si">%d</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span><span class="s">&#39;$r^2$=</span><span class="si">%.2f</span><span class="s">&#39;</span><span class="o">%</span><span class="n">est</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.25</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.25</span><span class="p">]);</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p><img src="/images/regression2NBA/original_model.png" /></p>

<p>More quick reminders - predicted performances are on the Y-axis, actual performances are on the X-axis, and the red line is the <a href="https://en.wikipedia.org/wiki/Identity_line">identity line</a>. Thus far, everything has been exactly the same as my previous post (although my group labels are different).</p>

<p>I want to investigate whether the model is overfitting the data. If the data is overfitting the data, then the error should go up when training and testing with different datasets (because the model was fitting itself to noise and noise changes when the datasets change). To investigate whether the model overfits the data, I will evaluate whether the model “generalizes” via <a href="https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29">cross-validation</a>.</p>

<p>The reason I’m worried about overfitting is I used a LOT of predictors in these models and the number of predictors might have allowed the model the model to fit noise in the predictors.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span> <span class="c">#I am using sklearns linear regression because it plays well with their cross validation function</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span> <span class="c">#import the cross validation function&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">X</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span><span class="p">][</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span>
</span><span class='line'><span class="n">rookie_df_drop</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_labels</span> <span class="c">#label each data point with its clusters&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">)):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">Grouper</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span> <span class="c">#do one regression at a time</span>
</span><span class='line'><span class="n">Yearer</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;Year&#39;</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Grouper</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">Yearer</span><span class="p">]</span>
</span><span class='line'><span class="n">Y</span> <span class="o">=</span> <span class="n">Group1</span><span class="p">[</span><span class="s">&#39;WS/48&#39;</span><span class="p">]</span> <span class="c">#get predictor data</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">rookie_df_drop</span><span class="p">[</span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">]</span>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span> <span class="c">#get predicted data</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe    </span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c"># Adds a constant term to the predictor</span>
</span><span class='line'>
</span><span class='line'><span class="n">est</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span> <span class="c">#fit with linear regression model</span>
</span><span class='line'>
</span><span class='line'><span class="n">this_scores</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">&#39;mean_absolute_error&#39;</span><span class="p">)</span> <span class="c">#find mean square error across different datasets via cross validations</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Group &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Initial Mean Absolute Error: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">])</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="s">&#39;Cross Validation MAE: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">this_scores</span><span class="p">)))[</span><span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">])</span> <span class="c">#find the mean MSE across validations </span>
</span></code></pre></td></tr></table></div></figure>

Group 0
Initial Mean Absolute Error: 0.0161
Cross Validation MAE: 0.0520
Group 1
Initial Mean Absolute Error: 0.0251
Cross Validation MAE: 0.0767
Group 2
Initial Mean Absolute Error: 0.0202
Cross Validation MAE: 0.0369
Group 3
Initial Mean Absolute Error: 0.0200
Cross Validation MAE: 0.0263
Group 4
Initial Mean Absolute Error: 0.0206
Cross Validation MAE: 0.0254
Group 5
Initial Mean Absolute Error: 0.0244
Cross Validation MAE: 0.0665
</code></pre>

<p>Above I print out the model’s initial mean absolute error and median absolute error when fitting cross-validated data.</p>

<p>The models definitely have more error when cross validated. The change in error is worse in some groups than others. For instance, error dramatically increases in Group 1. Keep in mind that the scoring measure here is mean absolute error, so error is in the same scale as WS/48. An average error of 0.04 in WS/48 is sizable, leaving me worried that the models overfit the data.</p>

<p>Unfortunately, Group 1 is the “scorers” group, so the group with most the interesting players is where the model fails most…</p>

<p>Next, I will look into whether my models underfit the data. I am worried that my models underfit the data because I used linear regression, which has very little flexibility. To investigate this, I will plot the <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">residuals</a> of each model. Residuals are the error between my model’s prediction and the actual performance.</p>

<p>Linear regression assumes that residuals are uncorrelated and evenly distributed around 0. If this is not the case, then the linear regression is underfitting the data.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#plot the residuals. there’s obviously a problem with under/over prediction&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">));</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">)):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">Grouper</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span> <span class="c">#do one regression at a time</span>
</span><span class='line'><span class="n">Yearer</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;Year&#39;</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Grouper</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">Yearer</span><span class="p">]</span>
</span><span class='line'><span class="n">Y</span> <span class="o">=</span> <span class="n">Group1</span><span class="p">[</span><span class="s">&#39;WS/48&#39;</span><span class="p">]</span> <span class="c">#get predictor data</span>
</span><span class='line'><span class="n">resid</span> <span class="o">=</span> <span class="n">estHold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">resid</span> <span class="c">#extract residuals</span>
</span><span class='line'>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c">#plot each regression&#39;s prediction against actual data</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">resid</span><span class="p">,</span><span class="s">&#39;o&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">&#39;axes.color_cycle&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Group </span><span class="si">%d</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.25</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">]);</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p><img src="/images/regression2NBA/residuals.png" /></p>

<p>Residuals are on the Y-axis and career performances are on the X-axis. Negative residuals are over predictions (the player is worse than my model predicts) and postive residuals are under predictions (the player is better than my model predicts). I don’t test this, but the residuals appear VERY correlated. That is, the model tends to over estimate bad players (players with WS/48 less than 0.0) and under estimate good players. Just to clarify, non-correlated residuals would have no apparent slope.</p>

<p>This means the model is making systematic errors and not fitting the actual shape of the data. I’m not going to say the model is damned, but this is an obvious sign that the model needs more flexibility.</p>

<p>No model is perfect, but this model definitely needs more work. I’ve been playing with more flexible models and will post these models here if they do a better job predicting player performance.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Predicting Career Performance From Rookie Performance]]></title>
    <link href="http://www.danvatterott.com/blog/2016/03/20/predicting-career-performance-from-rookie-performance/"/>
    <updated>2016-03-20T15:56:18-04:00</updated>
    <id>http://www.danvatterott.com/blog/2016/03/20/predicting-career-performance-from-rookie-performance</id>
    <content type="html"><![CDATA[<p>As a huge t-wolves fan, I’ve been curious all year by what we can infer from Karl-Anthony Towns’ great rookie season. To answer this question, I’ve create a simple linear regression model that uses rookie year performance to predict career performance.</p>

<p>Many have attempted to predict NBA players’ success via regression style approaches. Notable models I know of include <a href="http://laynevashro.com/basketball/predsFAQ.html">Layne Vashro’s model</a> which uses combine and college performance to predict career performance. Layne Vashro’s model is a quasi-poisson GLM. I tried a similar approach, but had the most success when using ws/48 and OLS. I will discuss this a little more at the end of the post.</p>

<p>A jupyter notebook of this post can be found on my <a href="https://github.com/dvatterott/jupyter_notebooks/blob/master/nba_rookie_regression.ipynb">github</a>.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#import some libraries and tell ipython we want inline figures rather than interactive figures. </span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span><span class="o">,</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span><span class="o">,</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">matplotlib</span> <span class="kn">as</span> <span class="nn">mpl</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="kn">from</span> <span class="o">&lt;</span><span class="n">strong</span><span class="o">&gt;</span><span class="n">future</span><span class="o">&lt;/</span><span class="n">strong</span><span class="o">&gt;</span> <span class="kn">import</span> <span class="nn">print_function</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</span><span class='line'><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">mpl_style</span> <span class="o">=</span> <span class="err">‘</span><span class="n">default</span><span class="err">’</span> <span class="c">#load matplotlib for plotting</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="err">‘</span><span class="n">ggplot</span><span class="err">’</span><span class="p">)</span> <span class="c">#im addicted to ggplot. so pretty.</span>
</span><span class='line'><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="err">‘</span><span class="n">font</span><span class="o">.</span><span class="n">family</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="err">‘</span><span class="n">Bitstream</span> <span class="n">Vera</span> <span class="n">Sans</span><span class="err">’</span><span class="p">]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>I collected all the data for this project from basketball-reference.com. I posted the functions for collecting the data on my <a href="https://github.com/dvatterott/nba_project">github</a>. The data is also posted there. Beware, the data collection scripts take awhile to run.</p>

<p>This data includes per 36 stats and advanced statistics such as usage percentage. I simply took all the per 36 and advanced statistics from a player’s page on basketball-reference.com.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="err">‘</span><span class="n">nba_bballref_career_stats_2016_Mar_15</span><span class="o">.</span><span class="n">pkl</span><span class="err">’</span><span class="p">)</span> <span class="c">#here’s the career data. </span>
</span><span class='line'><span class="n">rookie_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="err">‘</span><span class="n">nba_bballref_rookie_stats_2016_Mar_15</span><span class="o">.</span><span class="n">pkl</span><span class="err">’</span><span class="p">)</span> <span class="c">#here’s the rookie year data</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>The variable I am trying to predict is average <a href="http://www.basketball-reference.com/about/ws.html">WS/48</a> over a player’s career. There’s no perfect box-score statistic when it comes to quantifying a player’s peformance, but ws/48 seems relatively solid.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">Games</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">G</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">50</span> <span class="c">#only using players who played in more than 50 games.</span>
</span><span class='line'><span class="n">Year</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span> <span class="c">#only using players after 1980 when they started keeping many important records such as games started&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Games</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">Year</span><span class="p">][</span><span class="err">‘</span><span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">]</span> <span class="c">#predicted variable&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">Y</span><span class="p">);</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Bin</span> <span class="n">Count</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/regressionNBA/predictor_hist.png" /></p>

<p>The predicted variable looks pretty gaussian, so I can use ordinary least squares. This will be nice because while ols is not flexible, it’s highly interpretable. At the end of the post I’ll mention some more complex models that I will try.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">rook_games</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="p">[</span><span class="err">‘</span><span class="n">Career</span> <span class="n">Games</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">50</span>
</span><span class='line'><span class="n">rook_year</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="p">[</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span> <span class="nb">id</span><span class="o">=</span><span class="s">&quot;remove-rookies-from-before-1980-and-who-have-played-less-than-50-games-i-also-remove-some-features-that-seem-irrelevant-or-unfair&quot;</span><span class="o">&gt;</span><span class="n">remove</span> <span class="n">rookies</span> <span class="kn">from</span> <span class="nn">before</span> <span class="mi">1980</span> <span class="ow">and</span> <span class="n">who</span> <span class="n">have</span> <span class="n">played</span> <span class="n">less</span> <span class="n">than</span> <span class="mi">50</span> <span class="n">games</span><span class="o">.</span> <span class="n">I</span> <span class="n">also</span> <span class="n">remove</span> <span class="n">some</span> <span class="n">features</span> <span class="n">that</span> <span class="n">seem</span> <span class="n">irrelevant</span> <span class="ow">or</span> <span class="n">unfair</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">rookie_df_games</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="p">[</span><span class="n">rook_games</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">rook_year</span><span class="p">]</span> <span class="c">#only players with more than 50 games. </span>
</span><span class='line'><span class="n">rookie_df_drop</span> <span class="o">=</span> <span class="n">rookie_df_games</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Career</span> <span class="n">Games</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Name</span><span class="err">’</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Above, I remove some predictors from the rookie data. Lets run the regression!</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="kn">as</span> <span class="nn">sm</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">X_rookie</span> <span class="o">=</span> <span class="n">rookie_df_drop</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe</span>
</span><span class='line'><span class="n">X_rookie</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X_rookie</span><span class="p">)</span>  <span class="c"># Adds a constant term to the predictor&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">estAll</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">X_rookie</span><span class="p">)</span> <span class="c">#create ordinary least squares model</span>
</span><span class='line'><span class="n">estAll</span> <span class="o">=</span> <span class="n">estAll</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c">#fit the model</span>
</span><span class='line'><span class="k">print</span><span class="p">(</span><span class="n">estAll</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</span></code></pre></td></tr></table></div></figure></p>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  WS/48   R-squared:                       0.476
Model:                            OLS   Adj. R-squared:                  0.461
Method:                 Least Squares   F-statistic:                     31.72
Date:                Sun, 20 Mar 2016   Prob (F-statistic):          2.56e-194
Time:                        15:29:43   Log-Likelihood:                 3303.9
No. Observations:                1690   AIC:                            -6512.
Df Residuals:                    1642   BIC:                            -6251.
Df Model:                          47                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          0.2509      0.078      3.223      0.001         0.098     0.404
x1            -0.0031      0.001     -6.114      0.000        -0.004    -0.002
x2            -0.0004   9.06e-05     -4.449      0.000        -0.001    -0.000
x3            -0.0003   8.12e-05     -3.525      0.000        -0.000    -0.000
x4          1.522e-05   4.73e-06      3.218      0.001      5.94e-06  2.45e-05
x5             0.0030      0.031      0.096      0.923        -0.057     0.063
x6             0.0109      0.019      0.585      0.559        -0.026     0.047
x7            -0.0312      0.094     -0.331      0.741        -0.216     0.154
x8             0.0161      0.027      0.594      0.553        -0.037     0.069
x9            -0.0054      0.018     -0.292      0.770        -0.041     0.031
x10            0.0012      0.007      0.169      0.866        -0.013     0.015
x11            0.0136      0.023      0.592      0.554        -0.031     0.059
x12           -0.0099      0.018     -0.538      0.591        -0.046     0.026
x13            0.0076      0.054      0.141      0.888        -0.098     0.113
x14            0.0094      0.012      0.783      0.433        -0.014     0.033
x15            0.0029      0.002      1.361      0.174        -0.001     0.007
x16            0.0078      0.009      0.861      0.390        -0.010     0.026
x17           -0.0107      0.019     -0.573      0.567        -0.047     0.026
x18           -0.0062      0.018     -0.342      0.732        -0.042     0.029
x19            0.0095      0.017      0.552      0.581        -0.024     0.043
x20            0.0111      0.004      2.853      0.004         0.003     0.019
x21            0.0109      0.018      0.617      0.537        -0.024     0.046
x22           -0.0139      0.006     -2.165      0.030        -0.026    -0.001
x23            0.0024      0.005      0.475      0.635        -0.008     0.012
x24            0.0022      0.001      1.644      0.100        -0.000     0.005
x25           -0.0125      0.012     -1.027      0.305        -0.036     0.011
x26           -0.0006      0.000     -1.782      0.075        -0.001  5.74e-05
x27           -0.0011      0.001     -1.749      0.080        -0.002     0.000
x28            0.0012      0.003      0.487      0.626        -0.004     0.006
x29            0.1824      0.089      2.059      0.040         0.009     0.356
x30           -0.0288      0.025     -1.153      0.249        -0.078     0.020
x31           -0.0128      0.011     -1.206      0.228        -0.034     0.008
x32           -0.0046      0.008     -0.603      0.547        -0.020     0.010
x33           -0.0071      0.005     -1.460      0.145        -0.017     0.002
x34            0.0131      0.012      1.124      0.261        -0.010     0.036
x35           -0.0023      0.001     -2.580      0.010        -0.004    -0.001
x36           -0.0077      0.013     -0.605      0.545        -0.033     0.017
x37            0.0069      0.004      1.916      0.055        -0.000     0.014
x38           -0.0015      0.001     -2.568      0.010        -0.003    -0.000
x39           -0.0002      0.002     -0.110      0.912        -0.005     0.004
x40           -0.0109      0.017     -0.632      0.528        -0.045     0.023
x41           -0.0142      0.017     -0.821      0.412        -0.048     0.020
x42            0.0217      0.017      1.257      0.209        -0.012     0.056
x43            0.0123      0.102      0.121      0.904        -0.188     0.213
x44            0.0441      0.018      2.503      0.012         0.010     0.079
x45            0.0406      0.018      2.308      0.021         0.006     0.075
x46           -0.0410      0.018     -2.338      0.020        -0.075    -0.007
x47            0.0035      0.003      1.304      0.192        -0.002     0.009
==============================================================================
Omnibus:                       42.820   Durbin-Watson:                   1.966
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               54.973
Skew:                           0.300   Prob(JB):                     1.16e-12
Kurtosis:                       3.649   Cond. No.                     1.88e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.88e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
</code></pre>

<p>There’s a lot to look at in the regression output (especially with this many features). For an explanation of all the different parts of the regression take a look at this <a href="http://connor-johnson.com/2014/02/18/linear-regression-with-python/">post</a>. Below is a quick plot of predicted ws/48 against actual ws/48.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">estAll</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_rookie</span><span class="p">),</span><span class="n">Y</span><span class="p">,</span><span class="err">’</span><span class="n">o</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="err">’</span><span class="n">b</span><span class="o">-</span><span class="err">‘</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Career</span> <span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Predicted</span> <span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/regressionNBA/regression1_predict.png" /></p>

<p>The blue line above is NOT the best-fit line. It’s the identity line. I plot it to help visualize where the model fails. The model seems to primarily fail in the extremes - it tends to overestimate the worst players.</p>

<p>All in all, This model does a remarkably good job given its simplicity (linear regression), but it also leaves a lot of variance unexplained.</p>

<p>One reason this model might miss some variance is there’s more than one way to be a productive basketball player. For instance, Dwight Howard and Steph Curry find very different ways to contribute. One linear regression model is unlikely to succesfully predict both players.</p>

<p>In a <a href="http://www.danvatterott.com/blog/2016/02/21/grouping-nba-players/">previous post</a>, I grouped players according to their on-court performance. These player groupings might help predict career performance.</p>

<p>Below, I will use the same player grouping I developed in my previous post, and examine how these groupings impact my ability to predict career performance.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="err">‘</span><span class="n">nba_bballref_career_stats_2016_Mar_15</span><span class="o">.</span><span class="n">pkl</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">G</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">50</span><span class="p">]</span>
</span><span class='line'><span class="n">df_drop</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Name</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">G</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">GS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">MP</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FG</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FGA</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FG</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="mi">3</span><span class="n">P</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="mi">2</span><span class="n">P</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FT</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TRB</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">PTS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">ORtg</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DRtg</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">PER</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TS</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="mi">3</span><span class="n">PAr</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FTr</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">ORB</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DRB</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TRB</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">AST</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">STL</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">BLK</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TOV</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">USG</span><span class="o">%</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">OWS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DWS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">WS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">OBPM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">DBPM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">BPM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">VORP</span><span class="err">’</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">df_drop</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe</span>
</span><span class='line'><span class="n">ScaleModel</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">ScaleModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">reduced_model</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">reduced_data</span> <span class="o">=</span> <span class="n">reduced_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#transform data into the 5 PCA components space</span>
</span><span class='line'><span class="n">final_fit</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">)</span> <span class="c">#fit 6 clusters</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span> <span class="c">#label each data point with its clusters</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>See my other post for more details about this clustering procedure.</p>

<p>Let’s see how WS/48 varies across the groups.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">WS_48</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span> <span class="c">#create a vector of ws/48. One for each cluster</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">WS_48</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/regressionNBA/boxwhisk_ws48.png" /></p>

<p>Some groups perform better than others, but there’s lots of overlap between the groups. Importantly, each group has a fair amount of variability. Each group spans at least 0.15 WS/48. This gives the regression enough room to successfully predict performance in each group.</p>

<p>Now, lets get a bit of a refresher on what the groups are. Again, my previous post has a good description of these groups.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">TS</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">TS</span><span class="o">%</span><span class="err">’</span><span class="p">])</span><span class="o">&lt;</span><span class="n">em</span><span class="o">&gt;</span><span class="mi">100</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span> <span class="c">#create vectors of each stat for each cluster</span>
</span><span class='line'><span class="n">ThreeAr</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="mi">3</span><span class="n">PAr</span><span class="err">’</span><span class="p">])</span><span class="o">&lt;/</span><span class="n">em</span><span class="o">&gt;</span><span class="mi">100</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span>
</span><span class='line'><span class="n">FTr</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">FTr</span><span class="err">’</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span>
</span><span class='line'><span class="n">RBD</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">TRB</span><span class="o">%</span><span class="err">’</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span>
</span><span class='line'><span class="n">AST</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">AST</span><span class="o">%</span><span class="err">’</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span>
</span><span class='line'><span class="n">STL</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">STL</span><span class="o">%</span><span class="err">’</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span>
</span><span class='line'><span class="n">TOV</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">TOV</span><span class="o">%</span><span class="err">’</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span>
</span><span class='line'><span class="n">USG</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">USG</span><span class="o">%</span><span class="err">’</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">])]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">Data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">TS</span><span class="p">,</span><span class="n">ThreeAr</span><span class="p">,</span><span class="n">FTr</span><span class="p">,</span><span class="n">RBD</span><span class="p">,</span><span class="n">AST</span><span class="p">,</span><span class="n">STL</span><span class="p">,</span><span class="n">TOV</span><span class="p">,</span><span class="n">USG</span><span class="p">])</span>
</span><span class='line'><span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">9</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ind</span><span class="p">,</span><span class="n">Data</span><span class="p">,</span><span class="err">’</span><span class="n">o</span><span class="o">-</span><span class="err">‘</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ind</span><span class="p">,(</span><span class="err">‘</span><span class="bp">True</span> <span class="n">Shooting</span><span class="err">’</span><span class="p">,</span> <span class="err">‘</span><span class="mi">3</span> <span class="n">point</span> <span class="n">Attempt</span><span class="err">’</span><span class="p">,</span> <span class="err">‘</span><span class="n">Free</span> <span class="n">Throw</span> <span class="n">Rate</span><span class="err">’</span><span class="p">,</span> <span class="err">‘</span><span class="n">Rebound</span><span class="err">’</span><span class="p">,</span> <span class="err">‘</span><span class="n">Assist</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Steal</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TOV</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Usage</span><span class="err">’</span><span class="p">),</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="err">‘</span><span class="n">Group</span> <span class="mi">1</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">2</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">3</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">4</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">5</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">6</span><span class="err">’</span><span class="p">))</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Percent</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/regressionNBA/grouping_performance.png" /></p>

<p>I’ve plotted the groups across a number of useful categories. For information about these categories see <a href="http://www.basketball-reference.com/about/glossary.html">basketball reference’s glossary</a>.</p>

<p>Here’s a quick rehash of the groupings. See my <a href="http://www.danvatterott.com/blog/2016/02/21/grouping-nba-players/">previous post</a> for more detail.</p>

<ul>
<li>**Group 1:** These are the distributors who shoot a fair number of threes, don't rebound at all, dish out assists, gather steals, and ...turn the ball over.</li> 
<li>**Group 2:** These are the scorers who get to the free throw line, dish out assists, and carry a high usage.</li> 
<li>**Group 3:** These are the bench players who don't score...or do much in general.</li>
<li>**Group 4:** These are the 3 point shooters who shoot tons of 3 pointers, almost no free throws, and don't rebound well.</li>
<li>**Group 5:** These are the mid-range shooters who shoot well, but don't shoot threes or draw free throws</li>
<li>**Group 6:** These are the defensive big men who shoot no threes, rebound lots, and carry a low usage.</li>
</ul>

<p>On to the regression.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">rookie_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="err">‘</span><span class="n">nba_bballref_rookie_stats_2016_Mar_15</span><span class="o">.</span><span class="n">pkl</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">rookie_df</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Career</span> <span class="n">Games</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Name</span><span class="err">’</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">X</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe</span>
</span><span class='line'><span class="n">ScaleRookie</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#scale data</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">ScaleRookie</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#transform data to scale&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">reduced_model_rookie</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#create pca model of first 10 components. </span>
</span></code></pre></td></tr></table></div></figure></p>

<p>You might have noticed the giant condition number in the regression above. This indicates significant <a href="https://en.wikipedia.org/wiki/Multicollinearity">multicollinearity</a> of the features, which isn’t surprising since I have many features that reflect the same abilities.</p>

<p>The multicollinearity doesn’t prevent the regression model from making accurate predictions, but does it make the beta weight estimates irratic. With irratic beta weights, it’s hard to tell whether the different clusters use different models when predicting career ws/48.</p>

<p>In the following regression, I put the predicting features through a PCA and keep only the first 10 PCA components. Using only the first 10 PCA components keeps the component score below 20, indicating that multicollinearity is not a problem. I then examine whether the different groups exhibit a different patterns of beta weights (whether different models predict success of the different groups).</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span><span class="p">][</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="c">#limit labels to players after 1980</span>
</span><span class='line'><span class="n">rookie_df_drop</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_labels</span> <span class="c">#label each data point with its clusters&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">estHold</span> <span class="o">=</span> <span class="p">[[],[],[],[],[],[]]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">)):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">Grouper</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span> <span class="c">#do regression one group at a time</span>
</span><span class='line'><span class="n">Yearer</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;Year&#39;</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Grouper</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">Yearer</span><span class="p">]</span>
</span><span class='line'><span class="n">Y</span> <span class="o">=</span> <span class="n">Group1</span><span class="p">[</span><span class="s">&#39;WS/48&#39;</span><span class="p">]</span> <span class="c">#get predicted data</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">rookie_df_drop</span><span class="p">[</span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">]</span> <span class="c">#get predictor data of group</span>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">ScaleRookie</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#scale data</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">reduced_model_rookie</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#transform data into the 10 PCA components space</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c"># Adds a constant term to the predictor</span>
</span><span class='line'><span class="n">est</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="c">#create regression model</span>
</span><span class='line'><span class="n">est</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</span><span class='line'><span class="c">#print(est.summary())</span>
</span><span class='line'><span class="n">estHold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">est</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span> <span class="c">#plot the beta weights</span>
</span><span class='line'><span class="n">width</span><span class="o">=</span><span class="mf">0.12</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">est</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">estHold</span><span class="p">):</span>
</span><span class='line'>    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span><span class="o">+</span><span class="n">width</span><span class="o">*</span><span class="n">i</span><span class="p">,</span><span class="n">est</span><span class="o">.</span><span class="n">params</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="err">‘</span><span class="n">axes</span><span class="o">.</span><span class="n">color_cycle</span><span class="err">’</span><span class="p">][</span><span class="n">i</span><span class="p">],</span><span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span><span class="n">yerr</span><span class="o">=</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">conf_int</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">est</span><span class="o">.</span><span class="n">conf_int</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">right</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Principle</span> <span class="n">Components</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="err">‘</span><span class="n">Group</span> <span class="mi">1</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">2</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">3</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">4</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">5</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">6</span><span class="err">’</span><span class="p">))</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Beta</span> <span class="n">Weights</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/regressionNBA/beta_weights.png" /></p>

<p>Above I plot the beta weights for each principle component across the groupings. This plot is a lot to look at, but I wanted to depict how the beta values changed across the groups. They are not drastically different, but they’re also not identical. Error bars depict 95% confidence intervals.</p>

<p>Below I fit a regression to each group, but with all the features. Again, multicollinearity will be a problem, but this will not decrease the regression’s accuracy, which is all I really care about.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">rookie_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">cluster_labels</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Year</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span><span class="p">][</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span>
</span><span class='line'><span class="n">rookie_df_drop</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">cluster_labels</span> <span class="c">#label each data point with its clusters&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">));</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">estHold</span> <span class="o">=</span> <span class="p">[[],[],[],[],[],[]]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">group</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">)):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">Grouper</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span> <span class="c">#do one regression at a time</span>
</span><span class='line'><span class="n">Yearer</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">&#39;Year&#39;</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1980</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">Grouper</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">Yearer</span><span class="p">]</span>
</span><span class='line'><span class="n">Y</span> <span class="o">=</span> <span class="n">Group1</span><span class="p">[</span><span class="s">&#39;WS/48&#39;</span><span class="p">]</span> <span class="c">#get predictor data</span>
</span><span class='line'>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">rookie_df_drop</span><span class="p">[</span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">]</span>
</span><span class='line'><span class="n">Group1_rookie</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span> <span class="c">#get predicted data</span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">Group1_rookie</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe    </span>
</span><span class='line'>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c"># Adds a constant term to the predictor</span>
</span><span class='line'><span class="n">est</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="c">#fit with linear regression model</span>
</span><span class='line'><span class="n">est</span> <span class="o">=</span> <span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</span><span class='line'><span class="n">estHold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">est</span>
</span><span class='line'><span class="c">#print est.summary()</span>
</span><span class='line'>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c">#plot each regression&#39;s prediction against actual data</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">Y</span><span class="p">,</span><span class="s">&#39;o&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">&#39;axes.color_cycle&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="s">&#39;-&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">&#39;Group </span><span class="si">%d</span><span class="s">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span><span class="s">&#39;$r^2$=</span><span class="si">%.2f</span><span class="s">&#39;</span><span class="o">%</span><span class="n">est</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.25</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.25</span><span class="p">]);</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p><img src="/images/regressionNBA/model2_predictions.png" /></p>

<p>The plots above depict each regression’s predictions against actual ws/48. I provide each model’s r^2 in the plot too.</p>

<p>Some regressions are better than others. For instance, the regression model does a pretty awesome job predicting the bench warmers…I wonder if this is because they have shorter careers… The regression model does not do a good job predicting the 3-point shooters.</p>

<p>Now onto the fun stuff though.</p>

<p>Below, create a function for predicting a players career WS/48. First, I write a function that finds what cluster a player would belong to, and what the regression model predicts for this players career (with 95% confidence intervals).</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">player_prediction__regressionModel</span><span class="p">(</span><span class="n">PlayerName</span><span class="p">):</span>
</span><span class='line'>    <span class="kn">from</span> <span class="nn">statsmodels.sandbox.regression.predstd</span> <span class="kn">import</span> <span class="n">wls_prediction_std</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">clust_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s">&#39;nba_bballref_career_stats_2016_Mar_05.pkl&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">clust_df</span> <span class="o">=</span> <span class="n">clust_df</span><span class="p">[</span><span class="n">clust_df</span><span class="p">[</span><span class="s">&#39;Name&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">PlayerName</span><span class="p">]</span>
</span><span class='line'><span class="n">clust_df</span> <span class="o">=</span> <span class="n">clust_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;Name&#39;</span><span class="p">,</span><span class="s">&#39;G&#39;</span><span class="p">,</span><span class="s">&#39;GS&#39;</span><span class="p">,</span><span class="s">&#39;MP&#39;</span><span class="p">,</span><span class="s">&#39;FG&#39;</span><span class="p">,</span><span class="s">&#39;FGA&#39;</span><span class="p">,</span><span class="s">&#39;FG%&#39;</span><span class="p">,</span><span class="s">&#39;3P&#39;</span><span class="p">,</span><span class="s">&#39;2P&#39;</span><span class="p">,</span><span class="s">&#39;FT&#39;</span><span class="p">,</span><span class="s">&#39;TRB&#39;</span><span class="p">,</span><span class="s">&#39;PTS&#39;</span><span class="p">,</span><span class="s">&#39;ORtg&#39;</span><span class="p">,</span><span class="s">&#39;DRtg&#39;</span><span class="p">,</span><span class="s">&#39;PER&#39;</span><span class="p">,</span><span class="s">&#39;TS%&#39;</span><span class="p">,</span><span class="s">&#39;3PAr&#39;</span><span class="p">,</span><span class="s">&#39;FTr&#39;</span><span class="p">,</span><span class="s">&#39;ORB%&#39;</span><span class="p">,</span><span class="s">&#39;DRB%&#39;</span><span class="p">,</span><span class="s">&#39;TRB%&#39;</span><span class="p">,</span><span class="s">&#39;AST%&#39;</span><span class="p">,</span><span class="s">&#39;STL%&#39;</span><span class="p">,</span><span class="s">&#39;BLK%&#39;</span><span class="p">,</span><span class="s">&#39;TOV%&#39;</span><span class="p">,</span><span class="s">&#39;USG%&#39;</span><span class="p">,</span><span class="s">&#39;OWS&#39;</span><span class="p">,</span><span class="s">&#39;DWS&#39;</span><span class="p">,</span><span class="s">&#39;WS&#39;</span><span class="p">,</span><span class="s">&#39;WS/48&#39;</span><span class="p">,</span><span class="s">&#39;OBPM&#39;</span><span class="p">,</span><span class="s">&#39;DBPM&#39;</span><span class="p">,</span><span class="s">&#39;BPM&#39;</span><span class="p">,</span><span class="s">&#39;VORP&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">new_vect</span> <span class="o">=</span> <span class="n">ScaleModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">clust_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
</span><span class='line'><span class="n">reduced_data</span> <span class="o">=</span> <span class="n">reduced_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">new_vect</span><span class="p">)</span>
</span><span class='line'><span class="n">Group</span> <span class="o">=</span> <span class="n">final_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">)</span>
</span><span class='line'><span class="n">clust_df</span><span class="p">[</span><span class="s">&#39;kmeans_label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Group</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="n">Predrookie_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s">&#39;nba_bballref_rookie_stats_2016_Mar_15.pkl&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">Predrookie_df</span> <span class="o">=</span> <span class="n">Predrookie_df</span><span class="p">[</span><span class="n">Predrookie_df</span><span class="p">[</span><span class="s">&#39;Name&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">PlayerName</span><span class="p">]</span>
</span><span class='line'><span class="n">Predrookie_df</span> <span class="o">=</span> <span class="n">Predrookie_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s">&#39;Year&#39;</span><span class="p">,</span><span class="s">&#39;Career Games&#39;</span><span class="p">,</span><span class="s">&#39;Name&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">predX</span> <span class="o">=</span> <span class="n">Predrookie_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe</span>
</span><span class='line'><span class="n">predX</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">predX</span><span class="p">,</span><span class="n">has_constant</span><span class="o">=</span><span class="s">&#39;add&#39;</span><span class="p">)</span>  <span class="c"># Adds a constant term to the predictor</span>
</span><span class='line'><span class="n">prstd_ols</span><span class="p">,</span> <span class="n">iv_l_ols</span><span class="p">,</span> <span class="n">iv_u_ols</span> <span class="o">=</span> <span class="n">wls_prediction_std</span><span class="p">(</span><span class="n">estHold</span><span class="p">[</span><span class="n">Group</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span><span class="n">predX</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
</span><span class='line'><span class="k">return</span> <span class="p">{</span><span class="s">&#39;Name&#39;</span><span class="p">:</span><span class="n">PlayerName</span><span class="p">,</span><span class="s">&#39;Group&#39;</span><span class="p">:</span><span class="n">Group</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="s">&#39;Prediction&#39;</span><span class="p">:</span><span class="n">estHold</span><span class="p">[</span><span class="n">Group</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">predX</span><span class="p">),</span><span class="s">&#39;Upper_CI&#39;</span><span class="p">:</span><span class="n">iv_u_ols</span><span class="p">,</span><span class="s">&#39;Lower_CI&#39;</span><span class="p">:</span><span class="n">iv_l_ols</span><span class="p">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Here I create a function that creates a list of all the first round draft picks from a given year.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">gather_draftData</span><span class="p">(</span><span class="n">Year</span><span class="p">):</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="kn">import</span> <span class="nn">urllib2</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class='line'>
</span><span class='line'><span class="n">draft_len</span> <span class="o">=</span> <span class="mi">30</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">convert_float</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
</span><span class='line'>    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
</span><span class='line'>        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</span><span class='line'>
</span><span class='line'><span class="n">url</span> <span class="o">=</span> <span class="s">&#39;http://www.basketball-reference.com/draft/NBA_&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">Year</span><span class="p">)</span><span class="o">+</span><span class="s">&#39;.html&#39;</span>
</span><span class='line'><span class="n">html</span> <span class="o">=</span> <span class="n">urllib2</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span><span class='line'><span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span><span class="s">&quot;lxml&quot;</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">draft_num</span> <span class="o">=</span> <span class="p">[</span><span class="n">soup</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">&#39;tbody&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">&#39;tr&#39;</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">&#39;td&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">draft_len</span><span class="p">)]</span>
</span><span class='line'><span class="n">draft_nam</span> <span class="o">=</span> <span class="p">[</span><span class="n">soup</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">&#39;tbody&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">&#39;tr&#39;</span><span class="p">)[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">&#39;td&#39;</span><span class="p">)[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">draft_len</span><span class="p">)]</span>
</span><span class='line'>
</span><span class='line'><span class="n">draft_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">draft_num</span><span class="p">,</span><span class="n">draft_nam</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</span><span class='line'><span class="n">draft_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;Number&#39;</span><span class="p">,</span><span class="s">&#39;Name&#39;</span><span class="p">]</span>
</span><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
</span><span class='line'><span class="k">return</span> <span class="n">draft_df</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p>Below I create predictions for each first-round draft pick from 2015. The spurs’ first round pick, Nikola Milutinov, has yet to play so I do not create a prediction for him.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="kn">as</span> <span class="nn">mpatches</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">draft_df</span> <span class="o">=</span> <span class="n">gather_draftData</span><span class="p">(</span><span class="mi">2015</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">draft_df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">][</span><span class="mi">14</span><span class="p">]</span> <span class="o">=</span>  <span class="err">‘</span><span class="n">Kelly</span> <span class="n">Oubre</span> <span class="n">Jr</span><span class="o">.</span><span class="err">’</span> <span class="c">#annoying name inconsistencies&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">6</span><span class="p">));</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">31</span><span class="p">),</span><span class="n">draft_df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">],</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">draft_df</span> <span class="o">=</span> <span class="n">draft_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c">#Sam Dekker has received little playing time making his prediction highly erratic</span>
</span><span class='line'><span class="n">draft_df</span> <span class="o">=</span> <span class="n">draft_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c">#spurs’ 1st round pick has not played yet&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">draft_df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">]:</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">draft_num</span> <span class="o">=</span> <span class="n">draft_df</span><span class="p">[</span><span class="n">draft_df</span><span class="p">[</span><span class="s">&#39;Name&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">name</span><span class="p">][</span><span class="s">&#39;Number&#39;</span><span class="p">]</span>
</span><span class='line'>
</span><span class='line'><span class="n">predict_dict</span> <span class="o">=</span> <span class="n">player_prediction__regressionModel</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
</span><span class='line'><span class="n">yerr</span> <span class="o">=</span> <span class="p">(</span><span class="n">predict_dict</span><span class="p">[</span><span class="s">&#39;Upper_CI&#39;</span><span class="p">]</span><span class="o">-</span><span class="n">predict_dict</span><span class="p">[</span><span class="s">&#39;Lower_CI&#39;</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
</span><span class='line'>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">draft_num</span><span class="p">,</span><span class="n">predict_dict</span><span class="p">[</span><span class="s">&#39;Prediction&#39;</span><span class="p">],</span><span class="n">fmt</span><span class="o">=</span><span class="s">&#39;o&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
</span><span class='line'>            <span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">&#39;axes.color_cycle&#39;</span><span class="p">][</span><span class="n">predict_dict</span><span class="p">[</span><span class="s">&#39;Group&#39;</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">yerr</span><span class="o">=</span><span class="n">yerr</span><span class="p">);</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">right</span><span class="o">=</span><span class="mi">31</span><span class="p">)</span>
</span><span class='line'><span class="n">patch</span> <span class="o">=</span> <span class="p">[</span><span class="n">mpatches</span><span class="o">.</span><span class="n">Patch</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="err">‘</span><span class="n">axes</span><span class="o">.</span><span class="n">color_cycle</span><span class="err">’</span><span class="p">][</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="err">’</span><span class="n">Group</span> <span class="o">%</span><span class="n">d</span><span class="err">’</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)]</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">patch</span><span class="p">,</span><span class="n">ncol</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Predicted</span> <span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Draft</span> <span class="n">Position</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/regressionNBA/draft_2015_predict.png" /></p>

<p>The plot above is ordered by draft pick. The error bars depict 95% confidence interbals…which are a little wider than I would like. It’s interesting to look at what clusters these players fit into. Lots of 3-pt shooters! It could be that rookies play a limited role in the offense - just shooting 3s.</p>

<p>As a t-wolves fan, I am relatively happy about the high prediction for Karl-Anthony Towns. His predicted ws/48 is between Marc Gasol and Elton Brand. Again, the CIs are quite wide, so the model says there’s a 95% chance he is somewhere between Lebron James ever and a player that averages less than 0.1 ws/48.</p>

<p>Karl-Anthony Towns would have the highest predicted ws/48 if it were not for Kevin Looney who the model loves. Kevin Looney has not seen much playing time though, which likely makes his prediction more erratic. Keep in mind I did not use draft position as a predictor in the model.</p>

<p>Sam Dekker has a pretty huge error bar, likely because of his limited playing time this year.</p>

<p>While I fed a ton of features into this model, it’s still just a linear regression. The simplicity of the model might prevent me from making more accurate predictions.</p>

<p>I’ve already started playing with some more complex models. If those work out well, I will post them here. I ended up sticking with a plain linear regression because my vast number of features is a little unwieldy in a more complex models. If you’re interested (and the models produce better results) check back in the future.</p>

<p>For now, these models explain between 40 and 70% of the variance in career ws/48 from only a player’s rookie year. Even predicting 30% of variance is pretty remarkable, so I don’t want to trash on this part of the model. Explaining 65% of the variance is pretty awesome. The model gives us a pretty accurate idea of how these “bench players” will perform. For instance, the future does not look bright for players like Emmanuel Mudiay and Tyus Jones. Not to say these players are doomed. The model assumes that players will retain their grouping for the entire career. Emmanuel Mudiay and Tyus Jones might start performing more like distributors as their career progresses. This could result in a better career.</p>

<p>One nice part about this model is it tells us where the predictions are less confident. For instance, it is nice to know that we’re relatively confident when predicting bench players, but not when we’re predicting 3-point shooters.</p>

<p>For those curious, I output each groups regression summary below.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="p">[</span><span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">estHold</span><span class="p">];</span>
</span></code></pre></td></tr></table></div></figure></p>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  WS/48   R-squared:                       0.648
Model:                            OLS   Adj. R-squared:                  0.575
Method:                 Least Squares   F-statistic:                     8.939
Date:                Sun, 20 Mar 2016   Prob (F-statistic):           2.33e-24
Time:                        10:40:28   Log-Likelihood:                 493.16
No. Observations:                 212   AIC:                            -912.3
Df Residuals:                     175   BIC:                            -788.1
Df Model:                          36                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const         -0.1072      0.064     -1.682      0.094        -0.233     0.019
x1             0.0012      0.001      0.925      0.356        -0.001     0.004
x2            -0.0005      0.000     -2.355      0.020        -0.001 -7.53e-05
x3            -0.0005      0.000     -1.899      0.059        -0.001  2.03e-05
x4          3.753e-05   1.27e-05      2.959      0.004      1.25e-05  6.26e-05
x5            -0.1152      0.088     -1.315      0.190        -0.288     0.058
x6             0.0240      0.053      0.456      0.649        -0.080     0.128
x7            -0.4318      0.372     -1.159      0.248        -1.167     0.303
x8             0.0089      0.085      0.105      0.917        -0.159     0.177
x9            -0.0479      0.054     -0.893      0.373        -0.154     0.058
x10           -0.0055      0.021     -0.265      0.792        -0.046     0.035
x11           -0.0011      0.076     -0.015      0.988        -0.152     0.149
x12           -0.0301      0.053     -0.569      0.570        -0.134     0.074
x13            0.7814      0.270      2.895      0.004         0.249     1.314
x14           -0.0323      0.028     -1.159      0.248        -0.087     0.023
x15           -0.0108      0.007     -1.451      0.149        -0.025     0.004
x16           -0.0202      0.030     -0.676      0.500        -0.079     0.039
x17           -0.0461      0.039     -1.172      0.243        -0.124     0.032
x18           -0.0178      0.040     -0.443      0.659        -0.097     0.062
x19            0.0450      0.038      1.178      0.240        -0.030     0.121
x20            0.0354      0.014      2.527      0.012         0.008     0.063
x21           -0.0418      0.044     -0.947      0.345        -0.129     0.045
x22           -0.0224      0.015     -1.448      0.150        -0.053     0.008
x23           -0.0158      0.008     -2.039      0.043        -0.031    -0.001
x24            0.0058      0.001      4.261      0.000         0.003     0.009
x25            0.0577      0.027      2.112      0.036         0.004     0.112
x26           -0.1913      0.267     -0.718      0.474        -0.717     0.335
x27           -0.0050      0.093     -0.054      0.957        -0.189     0.179
x28           -0.0133      0.039     -0.344      0.731        -0.090     0.063
x29           -0.0071      0.015     -0.480      0.632        -0.036     0.022
x30           -0.0190      0.010     -1.973      0.050        -0.038  5.68e-06
x31            0.0221      0.023      0.951      0.343        -0.024     0.068
x32           -0.0083      0.003     -2.490      0.014        -0.015    -0.002
x33            0.0386      0.031      1.259      0.210        -0.022     0.099
x34            0.0153      0.008      1.819      0.071        -0.001     0.032
x35        -1.734e-05      0.001     -0.014      0.989        -0.002     0.002
x36            0.0033      0.004      0.895      0.372        -0.004     0.011
==============================================================================
Omnibus:                        2.457   Durbin-Watson:                   2.144
Prob(Omnibus):                  0.293   Jarque-Bera (JB):                2.475
Skew:                           0.007   Prob(JB):                        0.290
Kurtosis:                       3.529   Cond. No.                     1.78e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.78e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  WS/48   R-squared:                       0.443
Model:                            OLS   Adj. R-squared:                  0.340
Method:                 Least Squares   F-statistic:                     4.307
Date:                Sun, 20 Mar 2016   Prob (F-statistic):           1.67e-11
Time:                        10:40:28   Log-Likelihood:                 447.99
No. Observations:                 232   AIC:                            -822.0
Df Residuals:                     195   BIC:                            -694.4
Df Model:                          36                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const         -0.0532      0.090     -0.594      0.553        -0.230     0.124
x1            -0.0020      0.002     -1.186      0.237        -0.005     0.001
x2            -0.0006      0.000     -1.957      0.052        -0.001  4.47e-06
x3            -0.0007      0.000     -2.559      0.011        -0.001    -0.000
x4          5.589e-05   1.39e-05      4.012      0.000      2.84e-05  8.34e-05
x5             0.0386      0.093      0.414      0.679        -0.145     0.222
x6            -0.0721      0.051     -1.407      0.161        -0.173     0.029
x7            -0.6259      0.571     -1.097      0.274        -1.751     0.499
x8            -0.0653      0.079     -0.822      0.412        -0.222     0.091
x9             0.0756      0.051      1.485      0.139        -0.025     0.176
x10           -0.0046      0.031     -0.149      0.881        -0.066     0.057
x11           -0.0365      0.066     -0.554      0.580        -0.166     0.093
x12            0.0679      0.051      1.332      0.185        -0.033     0.169
x13            0.0319      0.183      0.174      0.862        -0.329     0.393
x14            0.0106      0.040      0.262      0.793        -0.069     0.090
x15           -0.0232      0.017     -1.357      0.176        -0.057     0.011
x16           -0.1121      0.039     -2.869      0.005        -0.189    -0.035
x17           -0.0675      0.060     -1.134      0.258        -0.185     0.050
x18           -0.0314      0.059     -0.536      0.593        -0.147     0.084
x19            0.0266      0.055      0.487      0.627        -0.081     0.134
x20            0.0259      0.009      2.827      0.005         0.008     0.044
x21           -0.0155      0.050     -0.307      0.759        -0.115     0.084
x22            0.1170      0.051      2.281      0.024         0.016     0.218
x23           -0.0157      0.014     -1.102      0.272        -0.044     0.012
x24            0.0021      0.003      0.732      0.465        -0.003     0.008
x25           -0.0012      0.038     -0.032      0.974        -0.077     0.075
x26            0.8379      0.524      1.599      0.111        -0.196     1.871
x27           -0.0511      0.113     -0.454      0.651        -0.273     0.171
x28            0.0944      0.111      0.852      0.395        -0.124     0.313
x29           -0.0018      0.029     -0.061      0.951        -0.059     0.055
x30           -0.0167      0.017     -0.969      0.334        -0.051     0.017
x31            0.0377      0.044      0.854      0.394        -0.049     0.125
x32           -0.0052      0.002     -2.281      0.024        -0.010    -0.001
x33            0.0132      0.037      0.360      0.719        -0.059     0.086
x34           -0.0650      0.028     -2.356      0.019        -0.119    -0.011
x35           -0.0012      0.002     -0.668      0.505        -0.005     0.002
x36            0.0087      0.008      1.107      0.270        -0.007     0.024
==============================================================================
Omnibus:                        2.161   Durbin-Watson:                   2.000
Prob(Omnibus):                  0.339   Jarque-Bera (JB):                1.942
Skew:                           0.222   Prob(JB):                        0.379
Kurtosis:                       3.067   Cond. No.                     3.94e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.94e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  WS/48   R-squared:                       0.358
Model:                            OLS   Adj. R-squared:                  0.270
Method:                 Least Squares   F-statistic:                     4.050
Date:                Sun, 20 Mar 2016   Prob (F-statistic):           1.93e-11
Time:                        10:40:28   Log-Likelihood:                 645.12
No. Observations:                 298   AIC:                            -1216.
Df Residuals:                     261   BIC:                            -1079.
Df Model:                          36                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          0.0306      0.040      0.763      0.446        -0.048     0.110
x1            -0.0013      0.001     -1.278      0.202        -0.003     0.001
x2            -0.0003      0.000     -1.889      0.060        -0.001  1.39e-05
x3            -0.0002      0.000     -1.196      0.233        -0.001     0.000
x4          2.388e-05   8.83e-06      2.705      0.007       6.5e-06  4.13e-05
x5            -0.0643      0.089     -0.724      0.470        -0.239     0.111
x6             0.0131      0.046      0.286      0.775        -0.077     0.103
x7            -0.4703      0.455     -1.034      0.302        -1.366     0.426
x8             0.0194      0.089      0.219      0.827        -0.155     0.194
x9            -0.0330      0.052     -0.638      0.524        -0.135     0.069
x10           -0.0221      0.013     -1.754      0.081        -0.047     0.003
x11            0.0161      0.074      0.216      0.829        -0.130     0.162
x12           -0.0228      0.047     -0.489      0.625        -0.115     0.069
x13            0.2619      0.423      0.620      0.536        -0.570     1.094
x14           -0.0303      0.027     -1.136      0.257        -0.083     0.022
x15           -0.0023      0.003     -0.895      0.372        -0.007     0.003
x16            0.0005      0.023      0.021      0.983        -0.045     0.046
x17            0.0206      0.040      0.513      0.608        -0.059     0.100
x18            0.0507      0.040      1.271      0.205        -0.028     0.129
x19           -0.0349      0.037     -0.942      0.347        -0.108     0.038
x20            0.0210      0.017      1.252      0.212        -0.012     0.054
x21            0.0400      0.041      0.964      0.336        -0.042     0.122
x22           -0.0239      0.009     -2.530      0.012        -0.042    -0.005
x23           -0.0140      0.008     -1.683      0.094        -0.030     0.002
x24            0.0045      0.001      4.594      0.000         0.003     0.006
x25            0.0264      0.026      1.004      0.316        -0.025     0.078
x26            0.2730      0.169      1.615      0.107        -0.060     0.606
x27           -0.0208      0.187     -0.111      0.912        -0.389     0.348
x28           -0.0007      0.015     -0.051      0.959        -0.029     0.028
x29            0.0168      0.018      0.917      0.360        -0.019     0.053
x30            0.0059      0.011      0.524      0.601        -0.016     0.028
x31           -0.0196      0.028     -0.711      0.478        -0.074     0.035
x32           -0.0035      0.004     -0.899      0.370        -0.011     0.004
x33           -0.0246      0.029     -0.858      0.392        -0.081     0.032
x34            0.0145      0.005      2.903      0.004         0.005     0.024
x35           -0.0017      0.001     -1.442      0.150        -0.004     0.001
x36            0.0069      0.005      1.514      0.131        -0.002     0.016
==============================================================================
Omnibus:                        5.509   Durbin-Watson:                   1.845
Prob(Omnibus):                  0.064   Jarque-Bera (JB):                5.309
Skew:                           0.272   Prob(JB):                       0.0703
Kurtosis:                       3.362   Cond. No.                     3.70e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.7e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  WS/48   R-squared:                       0.304
Model:                            OLS   Adj. R-squared:                  0.248
Method:                 Least Squares   F-statistic:                     5.452
Date:                Sun, 20 Mar 2016   Prob (F-statistic):           4.41e-19
Time:                        10:40:28   Log-Likelihood:                 1030.4
No. Observations:                 486   AIC:                            -1987.
Df Residuals:                     449   BIC:                            -1832.
Df Model:                          36                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          0.1082      0.033      3.280      0.001         0.043     0.173
x1            -0.0018      0.001     -2.317      0.021        -0.003    -0.000
x2            -0.0005      0.000     -3.541      0.000        -0.001    -0.000
x3          4.431e-05      0.000      0.359      0.720        -0.000     0.000
x4           1.71e-05   6.08e-06      2.813      0.005      5.15e-06   2.9e-05
x5             0.0257      0.044      0.580      0.562        -0.061     0.113
x6             0.0133      0.029      0.464      0.643        -0.043     0.070
x7            -0.5271      0.357     -1.476      0.141        -1.229     0.175
x8             0.0415      0.038      1.090      0.277        -0.033     0.116
x9            -0.0117      0.029     -0.409      0.682        -0.068     0.044
x10            0.0031      0.018      0.171      0.865        -0.032     0.038
x11            0.0253      0.031      0.819      0.413        -0.035     0.086
x12           -0.0196      0.028     -0.687      0.492        -0.076     0.036
x13            0.0360      0.067      0.535      0.593        -0.096     0.168
x14            0.0096      0.021      0.461      0.645        -0.031     0.050
x15            0.0101      0.009      1.165      0.245        -0.007     0.027
x16            0.0227      0.015      1.556      0.120        -0.006     0.051
x17            0.0413      0.034      1.198      0.232        -0.026     0.109
x18            0.0195      0.031      0.623      0.533        -0.042     0.081
x19           -0.0267      0.029     -0.906      0.366        -0.085     0.031
x20            0.0199      0.008      2.652      0.008         0.005     0.035
x21           -0.0442      0.033     -1.325      0.186        -0.110     0.021
x22            0.0232      0.025      0.946      0.345        -0.025     0.072
x23            0.0085      0.009      0.976      0.330        -0.009     0.026
x24            0.0025      0.001      1.782      0.075        -0.000     0.005
x25           -0.0200      0.019     -1.042      0.298        -0.058     0.018
x26            0.4937      0.331      1.491      0.137        -0.157     1.144
x27           -0.1406      0.074     -1.907      0.057        -0.286     0.004
x28           -0.0638      0.049     -1.304      0.193        -0.160     0.032
x29           -0.0252      0.015     -1.690      0.092        -0.055     0.004
x30           -0.0217      0.008     -2.668      0.008        -0.038    -0.006
x31            0.0483      0.020      2.387      0.017         0.009     0.088
x32           -0.0036      0.002     -2.159      0.031        -0.007    -0.000
x33            0.0388      0.023      1.681      0.094        -0.007     0.084
x34           -0.0105      0.011     -0.923      0.357        -0.033     0.012
x35           -0.0028      0.001     -1.966      0.050        -0.006 -1.59e-06
x36           -0.0017      0.003     -0.513      0.608        -0.008     0.005
==============================================================================
Omnibus:                        5.317   Durbin-Watson:                   2.030
Prob(Omnibus):                  0.070   Jarque-Bera (JB):                5.115
Skew:                           0.226   Prob(JB):                       0.0775
Kurtosis:                       3.221   Cond. No.                     4.51e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.51e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  WS/48   R-squared:                       0.455
Model:                            OLS   Adj. R-squared:                  0.378
Method:                 Least Squares   F-statistic:                     5.852
Date:                Sun, 20 Mar 2016   Prob (F-statistic):           4.77e-18
Time:                        10:40:28   Log-Likelihood:                 631.81
No. Observations:                 289   AIC:                            -1190.
Df Residuals:                     252   BIC:                            -1054.
Df Model:                          36                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          0.1755      0.096      1.827      0.069        -0.014     0.365
x1            -0.0031      0.001     -2.357      0.019        -0.006    -0.001
x2            -0.0005      0.000     -2.424      0.016        -0.001 -8.68e-05
x3            -0.0003      0.000     -2.154      0.032        -0.001  -2.9e-05
x4          2.374e-05   8.35e-06      2.842      0.005      7.29e-06  4.02e-05
x5             0.0391      0.070      0.556      0.579        -0.099     0.177
x6             0.0672      0.040      1.662      0.098        -0.012     0.147
x7             0.9503      0.458      2.075      0.039         0.048     1.852
x8            -0.0013      0.061     -0.021      0.983        -0.122     0.119
x9            -0.0270      0.041     -0.659      0.510        -0.108     0.054
x10           -0.0072      0.017     -0.426      0.671        -0.041     0.026
x11            0.0604      0.056      1.083      0.280        -0.049     0.170
x12           -0.0723      0.041     -1.782      0.076        -0.152     0.008
x13           -1.2499      0.392     -3.186      0.002        -2.022    -0.477
x14            0.0502      0.028      1.776      0.077        -0.005     0.106
x15            0.0048      0.011      0.456      0.649        -0.016     0.026
x16           -0.0637      0.042     -1.530      0.127        -0.146     0.018
x17            0.0042      0.038      0.112      0.911        -0.070     0.078
x18            0.0318      0.038      0.830      0.408        -0.044     0.107
x19           -0.0220      0.037     -0.602      0.548        -0.094     0.050
x20        -4.535e-05      0.009     -0.005      0.996        -0.018     0.018
x21           -0.0176      0.040     -0.440      0.660        -0.097     0.061
x22           -0.0244      0.021     -1.182      0.238        -0.065     0.016
x23            0.0135      0.012      1.128      0.260        -0.010     0.037
x24            0.0024      0.002      1.355      0.177        -0.001     0.006
x25           -0.0418      0.026     -1.583      0.115        -0.094     0.010
x26            0.3619      0.328      1.105      0.270        -0.283     1.007
x27            0.0090      0.186      0.049      0.961        -0.358     0.376
x28           -0.0613      0.057     -1.068      0.286        -0.174     0.052
x29            0.0124      0.016      0.779      0.436        -0.019     0.044
x30            0.0042      0.011      0.379      0.705        -0.018     0.026
x31           -0.0108      0.026     -0.412      0.681        -0.062     0.041
x32            0.0014      0.002      0.588      0.557        -0.003     0.006
x33            0.0195      0.029      0.672      0.502        -0.038     0.077
x34            0.0168      0.011      1.554      0.121        -0.004     0.038
x35           -0.0026      0.002     -1.227      0.221        -0.007     0.002
x36           -0.0072      0.004     -1.958      0.051        -0.014  4.02e-05
==============================================================================
Omnibus:                        4.277   Durbin-Watson:                   1.995
Prob(Omnibus):                  0.118   Jarque-Bera (JB):                4.056
Skew:                           0.226   Prob(JB):                        0.132
Kurtosis:                       3.364   Cond. No.                     4.24e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.24e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  WS/48   R-squared:                       0.476
Model:                            OLS   Adj. R-squared:                  0.337
Method:                 Least Squares   F-statistic:                     3.431
Date:                Sun, 20 Mar 2016   Prob (F-statistic):           1.19e-07
Time:                        10:40:28   Log-Likelihood:                 330.36
No. Observations:                 173   AIC:                            -586.7
Df Residuals:                     136   BIC:                            -470.1
Df Model:                          36                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [95.0% Conf. Int.]
------------------------------------------------------------------------------
const          0.1822      0.262      0.696      0.488        -0.335     0.700
x1            -0.0011      0.002     -0.491      0.624        -0.005     0.003
x2             0.0001      0.000      0.310      0.757        -0.001     0.001
x3          6.743e-05      0.000      0.220      0.827        -0.001     0.001
x4          5.819e-06   1.63e-05      0.357      0.722     -2.65e-05  3.81e-05
x5             0.0618      0.122      0.507      0.613        -0.179     0.303
x6             0.0937      0.074      1.272      0.206        -0.052     0.240
x7             0.8422      0.919      0.917      0.361        -0.975     2.659
x8            -0.1109      0.111     -1.001      0.319        -0.330     0.108
x9            -0.1334      0.075     -1.767      0.079        -0.283     0.016
x10           -0.0357      0.024     -1.500      0.136        -0.083     0.011
x11           -0.1373      0.103     -1.335      0.184        -0.341     0.066
x12           -0.1002      0.075     -1.329      0.186        -0.249     0.049
x13           -0.2963      0.616     -0.481      0.631        -1.515     0.922
x14           -0.0278      0.047     -0.588      0.557        -0.121     0.066
x15           -0.0099      0.015     -0.661      0.510        -0.040     0.020
x16            0.1532      0.106      1.444      0.151        -0.057     0.363
x17           -0.1569      0.072     -2.168      0.032        -0.300    -0.014
x18           -0.1633      0.068     -2.385      0.018        -0.299    -0.028
x19            0.1550      0.066      2.356      0.020         0.025     0.285
x20           -0.0114      0.017     -0.688      0.492        -0.044     0.021
x21           -0.0130      0.076     -0.170      0.865        -0.164     0.138
x22           -0.0202      0.024     -0.857      0.393        -0.067     0.026
x23           -0.0203      0.028     -0.737      0.462        -0.075     0.034
x24           -0.0023      0.004     -0.608      0.544        -0.010     0.005
x25            0.0546      0.048      1.141      0.256        -0.040     0.149
x26           -1.0180      0.714     -1.426      0.156        -2.430     0.394
x27            0.3371      0.203      1.664      0.098        -0.064     0.738
x28            0.1286      0.140      0.916      0.361        -0.149     0.406
x29           -0.0561      0.035     -1.607      0.110        -0.125     0.013
x30           -0.0535      0.020     -2.645      0.009        -0.093    -0.013
x31            0.1169      0.051      2.305      0.023         0.017     0.217
x32            0.0039      0.004      1.030      0.305        -0.004     0.011
x33            0.0179      0.055      0.324      0.746        -0.091     0.127
x34            0.0081      0.013      0.632      0.529        -0.017     0.033
x35            0.0013      0.006      0.229      0.819        -0.010     0.013
x36           -0.0068      0.007     -1.045      0.298        -0.020     0.006
==============================================================================
Omnibus:                        2.969   Durbin-Watson:                   2.098
Prob(Omnibus):                  0.227   Jarque-Bera (JB):                2.526
Skew:                           0.236   Prob(JB):                        0.283
Kurtosis:                       3.357   Cond. No.                     6.96e+05
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 6.96e+05. This might indicate that there are
strong multicollinearity or other numerical problems.
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Grouping NBA Players]]></title>
    <link href="http://www.danvatterott.com/blog/2016/02/21/grouping-nba-players/"/>
    <updated>2016-02-21T15:14:23-05:00</updated>
    <id>http://www.danvatterott.com/blog/2016/02/21/grouping-nba-players</id>
    <content type="html"><![CDATA[<p>In basketball, we typically talk about 5 positions: point guard, shooting guard, small forward, power forward, and center. Based on this, one might expect NBA players to fall into 5 distinct groups- Point guards perform similar to other point guards, shooting guards perform similar to other shooting guards, etc. Is this the case? Do NBA players fall neatly into position groups?</p>

<p>To answer this question, I will look at how NBA players “group” together. For example, there might be a group of players who collect lots of rebounds, shoot poorly from behind the 3 point line, and block lots of shots. I might call these players forwards. If we allow player performance to create groups, what will these groups look like?</p>

<p>To group players, I will use k-means clustering (https://en.wikipedia.org/wiki/K-means_clustering).</p>

<p>When choosing a clustering algorithm, its important to think about how the clustering algorithm defines clusters. k-means minimizes the distance between data points (players in my case) and the center of K different points. Because distance is between the cluster center and a given point, k-means assumes clusters are spherical. When thinking about clusters of NBA players, do I think these clusters will be spherical? If not, then I might want try a different clustering algorithm.</p>

<p>For now, I will assume generally spherical clusters and use k-means. At the end of this post, I will comment on whether this assumption seems valid.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#import libraries and tell ipython we want inline figures rather than interactive figures. </span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span><span class="o">,</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span><span class="o">,</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">matplotlib</span> <span class="kn">as</span> <span class="nn">mpl</span><span class="o">,</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">time</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</span><span class='line'><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">mpl_style</span> <span class="o">=</span> <span class="err">‘</span><span class="n">default</span><span class="err">’</span> <span class="c">#load matplotlib for plotting</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="err">‘</span><span class="n">ggplot</span><span class="err">’</span><span class="p">)</span> <span class="c">#im addicted to ggplot. so pretty.</span>
</span><span class='line'><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="err">‘</span><span class="n">font</span><span class="o">.</span><span class="n">family</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="err">‘</span><span class="n">Bitstream</span> <span class="n">Vera</span> <span class="n">Sans</span><span class="err">’</span><span class="p">]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>We need data. Collecting the data will require a couple steps. First, I will create a matrix of all players who ever played in the NBA (via the NBA.com API).</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">stats</span><span class="o">.</span><span class="n">nba</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">stats</span><span class="o">/</span><span class="n">commonallplayers</span><span class="err">?</span><span class="n">IsOnlyCurrentSeason</span><span class="o">=</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">LeagueID</span><span class="o">=</span><span class="mo">00</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Season</span><span class="o">=</span><span class="mi">2015</span><span class="o">-</span><span class="mi">16</span><span class="err">’</span>
</span><span class='line'><span class="c"># the critical part of the URL is IsOnlyCurrentSeason=0. The 0 means all seasons.</span>
</span><span class='line'><span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span> <span class="c">#get data</span>
</span><span class='line'><span class="n">headers</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="err">‘</span><span class="n">resultSets</span><span class="err">’</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span class='line'><span class="n">players</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="err">‘</span><span class="n">resultSets</span><span class="err">’</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="err">‘</span><span class="n">rowSet</span><span class="err">’</span><span class="p">]</span>
</span><span class='line'><span class="n">players_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">players</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">headers</span><span class="p">[</span><span class="err">‘</span><span class="n">headers</span><span class="err">’</span><span class="p">])</span> <span class="c">#turn data into dataframe</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>In the 1979-1980 season, the NBA started using the 3-point line. The 3-point has dramatically changed basketball, so players performed different before it. While this change in play was not instantaneous, it does not make sense to include players before the 3-point line.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">players_df</span><span class="p">[</span><span class="err">‘</span><span class="n">TO_YEAR</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">players_df</span><span class="p">[</span><span class="err">‘</span><span class="n">TO_YEAR</span><span class="err">’</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c">#change data in the TO_YEAR column from strings to numbers</span>
</span><span class='line'><span class="n">players_df</span> <span class="o">=</span> <span class="n">players_df</span><span class="p">[</span><span class="n">players_df</span><span class="p">[</span><span class="err">‘</span><span class="n">TO_YEAR</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">1979</span><span class="p">]</span> <span class="c">#only use players after 3 pt line</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>I have a list of all the players after 1979, but I want data about all these players. When grouping the players, I am not interested in how much a player played. Instead, I want to know HOW a player played. To remove variability associated with playing time, I will gather data that is standardized for 36 minutes of play. For example, if a player averages 4 points and 12 minutes a game, this player averages 12 points per 36 minutes.</p>

<p>Below, I have written a function that will collect every player’s performance per 36 minutes. The function collects data one player at a time, so its VERY slow. If you want the data, it can be found on my github (https://github.com/dvatterott/nba_project).</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">careerPer36</span><span class="p">(</span><span class="n">playerID</span><span class="p">):</span>
</span><span class='line'>    <span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">stats</span><span class="o">.</span><span class="n">nba</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">stats</span><span class="o">/</span><span class="n">playercareerstats</span><span class="err">?</span><span class="n">LeagueID</span><span class="o">=</span><span class="mo">00</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">PerMode</span><span class="o">=</span><span class="n">Per36</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">PlayerID</span><span class="o">=</span><span class="err">’</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">playerID</span><span class="p">)</span>
</span><span class='line'>    <span class="n">header_data</span> <span class="o">=</span> <span class="p">{</span> <span class="c">#I pulled this header from the py goldsberry library</span>
</span><span class='line'>            <span class="err">‘</span><span class="n">Accept</span><span class="o">-</span><span class="n">Encoding</span><span class="err">’</span><span class="p">:</span> <span class="err">‘</span><span class="n">gzip</span><span class="p">,</span> <span class="n">deflate</span><span class="p">,</span> <span class="n">sdch</span><span class="err">’</span><span class="p">,</span>
</span><span class='line'>            <span class="err">‘</span><span class="n">Accept</span><span class="o">-</span><span class="n">Language</span><span class="err">’</span><span class="p">:</span> <span class="err">‘</span><span class="n">en</span><span class="o">-</span><span class="n">US</span><span class="p">,</span><span class="n">en</span><span class="p">;</span><span class="n">q</span><span class="o">=</span><span class="mf">0.8</span><span class="err">’</span><span class="p">,</span>
</span><span class='line'>            <span class="err">‘</span><span class="n">Upgrade</span><span class="o">-</span><span class="n">Insecure</span><span class="o">-</span><span class="n">Requests</span><span class="err">’</span><span class="p">:</span> <span class="err">‘</span><span class="mi">1</span><span class="err">’</span><span class="p">,</span>
</span><span class='line'>            <span class="err">‘</span><span class="n">User</span><span class="o">-</span><span class="n">Agent</span><span class="err">’</span><span class="p">:</span> <span class="err">‘</span><span class="n">Mozilla</span><span class="o">/</span><span class="mf">5.0</span> <span class="p">(</span><span class="n">Windows</span> <span class="n">NT</span> <span class="mf">10.0</span><span class="p">;</span> <span class="n">WOW64</span><span class="p">)</span><span class="err">’</span>\
</span><span class='line'>            <span class="err">‘</span> <span class="n">AppleWebKit</span><span class="o">/</span><span class="mf">537.36</span> <span class="p">(</span><span class="n">KHTML</span><span class="p">,</span> <span class="n">like</span> <span class="n">Gecko</span><span class="p">)</span> <span class="n">Chrome</span><span class="o">/</span><span class="mf">48.0</span><span class="o">.</span><span class="mf">2564.82</span> <span class="err">‘</span>\
</span><span class='line'>            <span class="err">‘</span><span class="n">Safari</span><span class="o">/</span><span class="mf">537.36</span><span class="err">’</span><span class="p">,</span>
</span><span class='line'>            <span class="err">‘</span><span class="n">Accept</span><span class="err">’</span><span class="p">:</span> <span class="err">‘</span><span class="n">text</span><span class="o">/</span><span class="n">html</span><span class="p">,</span><span class="n">application</span><span class="o">/</span><span class="n">xhtml</span><span class="o">+</span><span class="n">xml</span><span class="p">,</span><span class="n">application</span><span class="o">/</span><span class="n">xml</span><span class="p">;</span><span class="n">q</span><span class="o">=</span><span class="mf">0.9</span><span class="err">’</span>\
</span><span class='line'>            <span class="err">‘</span><span class="p">,</span><span class="n">image</span><span class="o">/</span><span class="n">webp</span><span class="p">,</span><span class="o">&lt;</span><span class="n">em</span><span class="o">&gt;/&lt;/</span><span class="n">em</span><span class="o">&gt;</span><span class="p">;</span><span class="n">q</span><span class="o">=</span><span class="mf">0.8</span><span class="err">’</span><span class="p">,</span>
</span><span class='line'>            <span class="err">‘</span><span class="n">Cache</span><span class="o">-</span><span class="n">Control</span><span class="err">’</span><span class="p">:</span> <span class="err">‘</span><span class="nb">max</span><span class="o">-</span><span class="n">age</span><span class="o">=</span><span class="mi">0</span><span class="err">’</span><span class="p">,</span>
</span><span class='line'>            <span class="err">‘</span><span class="n">Connection</span><span class="err">’</span><span class="p">:</span> <span class="err">‘</span><span class="n">keep</span><span class="o">-</span><span class="n">alive</span><span class="err">’</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="k">try</span><span class="p">:</span>
</span><span class='line'>        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">headers</span> <span class="o">=</span> <span class="n">header_data</span><span class="p">)</span> <span class="c">#get the data</span>
</span><span class='line'>        <span class="c">#print playerID #testing purposes</span>
</span><span class='line'>    <span class="k">except</span><span class="p">:</span>
</span><span class='line'>        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c">#sometime the nba api gets mad about all the requests, so i take a quick break</span>
</span><span class='line'>        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">headers</span> <span class="o">=</span> <span class="n">header_data</span><span class="p">)</span>
</span><span class='line'>    <span class="n">headers</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="err">‘</span><span class="n">resultSets</span><span class="err">’</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="c">#find headers</span>
</span><span class='line'>    <span class="n">players</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="err">‘</span><span class="n">resultSets</span><span class="err">’</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="err">‘</span><span class="n">rowSet</span><span class="err">’</span><span class="p">]</span> <span class="c">#actual data</span>
</span><span class='line'>    <span class="n">players_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">players</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">headers</span><span class="p">[</span><span class="err">‘</span><span class="n">headers</span><span class="err">’</span><span class="p">])</span> <span class="c">#create dataframe</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">players_df</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span> <span class="nb">id</span><span class="o">=</span><span class="s">&quot;df--pddataframe&quot;</span><span class="o">&gt;</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="c">#player_list = players_df[‘PERSON_ID’] </span>
</span><span class='line'><span class="c">#df = df.append([careerPer36(x) for x in player_list]) #BEWARE. this takes forever.</span>
</span><span class='line'><span class="c">#df.index = range(np.size(df,0))</span>
</span><span class='line'><span class="c">#df.to_pickle(‘nba_career_stats_‘+time.strftime(“%Y_%b_%d”, time.gmtime())+’.pkl’)</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="err">‘</span><span class="n">nba_career_stats_2016_Feb_14</span><span class="o">.</span><span class="n">pkl</span><span class="err">’</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">df</span><span class="o">.</span><span class="n">columns</span>
</span></code></pre></td></tr></table></div></figure></p>

<pre><code>Index([u'PLAYER_ID', u'LEAGUE_ID',   u'TEAM_ID',        u'GP',        u'GS',
             u'MIN',       u'FGM',       u'FGA',    u'FG_PCT',      u'FG3M',
            u'FG3A',   u'FG3_PCT',       u'FTM',       u'FTA',    u'FT_PCT',
            u'OREB',      u'DREB',       u'REB',       u'AST',       u'STL',
             u'BLK',       u'TOV',        u'PF',       u'PTS'],
      dtype='object')
</code></pre>

<p>Great! Now we have data that is scaled for 36 minutes of play (per36 data) from every player between 1979 and 2016. Above, I printed out the columns. I don’t want all this data. For instance, I do not care about how many minutes a player played. Also, some of the data is redundant. For instance, if I know a player’s field goal attempts (FGA) and field goal percentage (FG_PCT), I can calculate the number of made field goals (FGM). I removed the data columns that seem redundant. I do this because I do not want redundant data exercising too much influence on the grouping process.</p>

<p>Below, I create new data columns for 2 point field goal attempts and 2 point field goal percentage. I also remove all players who played less than 50 games. I do this because these players have not had the opportunity to establish consistent performance.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">GP</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">50</span><span class="p">]</span> <span class="c">#only players with more than 50 games. </span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c">#some players have “None” in some cells. Turn these into 0s</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FG2M</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FGM</span><span class="err">’</span><span class="p">]</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FG3M</span><span class="err">’</span><span class="p">]</span> <span class="c">#find number of 2pt field goals</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FG2A</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FGA</span><span class="err">’</span><span class="p">]</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FG3A</span><span class="err">’</span><span class="p">]</span> <span class="c">#2 point field goal attempts</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FG2_PCT</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FG2M</span><span class="err">’</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">FG2A</span><span class="err">’</span><span class="p">]</span> <span class="c">#2 point field goal percentage</span>
</span><span class='line'><span class="n">saveIDs</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]</span> <span class="c">#save player IDs for later</span>
</span><span class='line'><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">LEAGUE_ID</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">TEAM_ID</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">GP</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">GS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">MIN</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FGM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FGA</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FG_PCT</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FG3M</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FTM</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">REB</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">PTS</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">FG2M</span><span class="err">’</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span> <span class="c">#pull out unncessary columns</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>It’s always important to visualize the data, so lets get an idea what we’re working with!</p>

<p>The plot below is called a scatter matrix. This type of plot will appear again, so lets go through it carefully. Each subplot has the feature (stat) labeled on its row which serves as its y-axis. The column feature serves as the x-axis. For example the subplot in the second column of the first row plots 3-point field goal attempts by 3-point field goal percentage. As you can see, players that have higher 3-point percentages tend to take more 3-pointers… makes sense.</p>

<p>On the diagonals, I plot the Kernel Density Estimation for the sample histogram. More players fall into areas where where the line is higher on the y-axis. For instance, no players shoot better than ~45% from behind the 3 point line.</p>

<p>One interesting part about scatter matrices is the plots below the diagonal are a reflection of the plots above the diagonal. For example, the data in the second column of the first row and the first column of the second row are the same. The only difference is the axes have switched.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">axs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">scatter_matrix</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="err">’</span><span class="n">kde</span><span class="err">’</span><span class="p">);</span> <span class="c">#the diagonal will show kernel density</span>
</span><span class='line'><span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]]</span> <span class="c">#turn off the ticks that take up way too much space in such a crammed figure</span>
</span><span class='line'><span class="p">[</span><span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]];</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/scatter_mat1_nba.png" /></p>

<p>There are a couple things to note in the graph above. First, there’s a TON of information there. Second, it looks like there are some strong correlations. For example, look at the subplots depicting offensive rebounds by defensive rebounds.</p>

<p>While I tried to throw out redundant data, I clearly did not throw out all redundant data. For example, players that are good 3-point shooters are probably also good free throw shooters. These players are simply good shooters, and being a good shooter contributes to multiple data columns above.</p>

<p>When I group the data, I do not want an ability such as shooting to contribute too much. I want to group players equally according to all their abilities. Below I use a PCA to seperate variance associated with the different “components” (e.g., shooting ability) of basketball performance.</p>

<p>For an explanation of PCA I recommend this link - https://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span> <span class="c">#take data out of dataframe</span>
</span><span class='line'><span class="n">X</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#standardize the data before giving it to the PCA. </span>
</span><span class='line'><span class="c">#I standardize the data because some features such as PF or steals have lower magnitudes than other features such as FG2A</span>
</span><span class='line'><span class="c">#I want both to contribute equally to the PCA, so I make sure they’re on the same scale.&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span> <span class="c">#great PCA object</span>
</span><span class='line'><span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#pull out principle components</span>
</span><span class='line'><span class="n">var_expl</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span> <span class="c">#find amount of variance explained by each component</span>
</span><span class='line'><span class="n">tot_var_expl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">sum</span><span class="p">(</span><span class="n">var_expl</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">var_expl</span><span class="p">)])</span> <span class="c">#create vector with cumulative variance&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span> <span class="c">#create cumulative proportion of variance plot</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">tot_var_expl</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">tot_var_expl</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="err">’</span><span class="n">o</span><span class="o">-</span><span class="err">‘</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tot_var_expl</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Number</span> <span class="n">of</span> <span class="n">PCA</span> <span class="n">Components</span> <span class="n">Included</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Percentage</span> <span class="n">of</span> <span class="n">variance</span> <span class="n">explained</span> <span class="p">(</span><span class="o">%</span><span class="p">)</span><span class="err">’</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c">#create scree plot</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">var_expl</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">var_expl</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="err">’</span><span class="n">o</span><span class="o">-</span><span class="err">‘</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">var_expl</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">PCA</span> <span class="n">Component</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/PCA_nba.png" /></p>

<p>On the left, I plot the amount of variance explained after including each additional PCA component. Using all the components explains all the variability, but notice how little the last few components contribute. It doesn’t make sense to include a component that only explains 1% of the variability…but how many components to include!?</p>

<p>I chose to include the first 5 components because no component after the 5th explained more than 5% of the data. This part of the analysis is admittedly arbitrary, but 5% is a relatively conservative cut-off.</p>

<p>Below is the fun part of the data. We get to look at what features contribute to the different principle components.</p>

<ul>
  <li>Assists and 3-point shooting contribute to the first component. I will call this the <strong>Outside Skills</strong> component.</li>
  <li>Free throw attempts, assists, turnovers and 2-point field goals contribute to the second component. I will call this the <strong>Rim Scoring</strong> component.</li>
  <li>Free throw percentage and 2-point field goal percentage  contribute to the third component. I will call this the <strong>Pure Points</strong> component.</li>
  <li>2-point field goal percentage and steals contribute to the fourth component. I will call this the <strong>Defensive Big Man</strong> component.</li>
  <li>3-point shooting and free throws contribute to the fifth component. I will call this the <strong>Dead Eye</strong> component.</li>
</ul>

<p>One thing to keep in mind here is that each component explains less variance than the last. So while 3 point shooting contributes to both the 1st and 5th component, more 3 point shooting variability is probably explained by the 1st component.</p>

<p>It would be great if we had a PCA component that was only shooting and another that was only rebounding since we typically conceive these to be different skills. Yet, there are multiple aspects of each skill. For example, a 3-point shooter not only has to be a dead-eye shooter, but also has to find ways to get open. Additionally, being good at “getting open” might be something akin to basketball IQ which would also contribute to assists and steals!</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">factor_names</span> <span class="o">=</span> <span class="p">[</span><span class="err">‘</span><span class="n">Outside</span> <span class="n">Skills</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Rim</span> <span class="n">Scoring</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Pure</span> <span class="n">Points</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Defensive</span> <span class="n">Big</span> <span class="n">Man</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Dead</span> <span class="n">Eye</span><span class="err">’</span><span class="p">]</span> <span class="c">#my component names</span>
</span><span class='line'><span class="n">loadings_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</span><span class='line'><span class="c">#loadings_df[0:5] #all the factor loadings appear below.</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Cool, we have our 5 PCA components. Now lets transform the data into our 5 component PCA space (from our 13 feature space - e.g., FG3A, FG3_PCT, ect.). To do this, we give each player a score on each of the 5 PCA components.</p>

<p>Next, I want to see how players cluster together based on their scores on these components. First, let’s investigate how using more or less clusters (i.e., groups) explains different amounts of variance.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span><span class="p">,</span> <span class="n">pdist</span><span class="p">,</span> <span class="n">euclidean</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span> <span class="nb">id</span><span class="o">=</span><span class="s">&quot;httpstackoverflowcomquestions6645895calculating-the-percentage-of-variance-measure-for-k-means&quot;</span><span class="o">&gt;</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">stackoverflow</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">questions</span><span class="o">/</span><span class="mi">6645895</span><span class="o">/</span><span class="n">calculating</span><span class="o">-</span><span class="n">the</span><span class="o">-</span><span class="n">percentage</span><span class="o">-</span><span class="n">of</span><span class="o">-</span><span class="n">variance</span><span class="o">-</span><span class="n">measure</span><span class="o">-</span><span class="k">for</span><span class="o">-</span><span class="n">k</span><span class="o">-</span><span class="n">means</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="c">#The above link was helpful when writing this code.&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">reduced_data</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">whiten</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c">#transform data into the 5 PCA components space</span>
</span><span class='line'><span class="c">#kmeans assumes clusters have equal variance, and whitening helps keep this assumption.&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">31</span><span class="p">)</span> <span class="c">#looking amount of variance explained by 1 through 30 cluster</span>
</span><span class='line'><span class="n">k_means_var</span> <span class="o">=</span> <span class="p">[</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">]</span> <span class="c">#fit kmeans with 1 cluster to 30 clusters&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span> <span class="nb">id</span><span class="o">=</span><span class="s">&quot;get-labels-and-calculate-silhouette-score&quot;</span><span class="o">&gt;</span><span class="n">get</span> <span class="n">labels</span> <span class="ow">and</span> <span class="n">calculate</span> <span class="n">silhouette</span> <span class="n">score</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">labels_</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">k_means_var</span><span class="p">]</span>
</span><span class='line'><span class="n">sil_score</span> <span class="o">=</span> <span class="p">[</span><span class="n">metrics</span><span class="o">.</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">metric</span><span class="o">=</span><span class="err">’</span><span class="n">euclidean</span><span class="err">’</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">centroids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">k_means_var</span><span class="p">]</span> <span class="c">#get the center of each cluster</span>
</span><span class='line'><span class="n">k_euclid</span> <span class="o">=</span> <span class="p">[</span><span class="n">cdist</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">,</span><span class="n">cent</span><span class="p">,</span><span class="err">’</span><span class="n">euclidean</span><span class="err">’</span><span class="p">)</span> <span class="k">for</span> <span class="n">cent</span> <span class="ow">in</span> <span class="n">centroids</span><span class="p">]</span> <span class="c">#calculate distance between each item and each cluster center</span>
</span><span class='line'><span class="n">dist</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">ke</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">ke</span> <span class="ow">in</span> <span class="n">k_euclid</span><span class="p">]</span> <span class="c">#get the distance between each item and its cluster&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">wcss</span> <span class="o">=</span> <span class="p">[</span><span class="nb">sum</span><span class="p">(</span><span class="n">d</span><span class="o">&lt;</span><span class="n">strong</span><span class="o">&gt;</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dist</span><span class="p">]</span> <span class="c">#within cluster sum of squares</span>
</span><span class='line'><span class="n">tss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">pdist</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">strong</span><span class="o">&gt;</span><span class="mi">2</span><span class="o">/</span><span class="n">reduced_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c">#total sum of squares</span>
</span><span class='line'><span class="n">bss</span> <span class="o">=</span> <span class="n">tss</span><span class="o">-</span><span class="n">wcss</span> <span class="c">#between cluster sum of squares&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span> <span class="c">#create cumulative proportion of variance plot</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">bss</span><span class="o">/</span><span class="n">tss</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="err">’</span><span class="n">o</span><span class="o">-</span><span class="err">‘</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">k_range</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Number</span> <span class="n">of</span> <span class="n">Clusters</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Percentage</span> <span class="n">of</span> <span class="n">variance</span> <span class="n">explained</span> <span class="p">(</span><span class="o">%</span><span class="p">)</span><span class="err">’</span><span class="p">);</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c">#create scree plot</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">sil_score</span><span class="p">)</span><span class="o">&lt;</span><span class="n">em</span><span class="o">&gt;</span><span class="mi">100</span><span class="p">,</span><span class="err">’</span><span class="n">o</span><span class="o">-</span><span class="err">‘</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">k_range</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">40</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Number</span> <span class="n">of</span> <span class="n">Clusters</span><span class="err">’</span><span class="p">);</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Average</span> <span class="n">Silhouette</span> <span class="n">Score</span><span class="o">&lt;/</span><span class="n">em</span><span class="o">&gt;</span><span class="mi">100</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/cluster_eval_nba.png" /></p>

<p>As you can in the left hand plot, adding more clusters explains more of the variance, but there are diminishing returns. Each additional cluster explains a little less data than the last (much like each PCA component explained less variance than the previous component).</p>

<p>The particularly intersting point here is the point where the second derivative is greatest, when the amount of change changes the most (the elbow). The elbow occurs at the 6th cluster.</p>

<p>Perhaps not coincidently, 6 clusters also has the highest silhouette score (right hand plot). The silhouette score computes the average distance between a player and all other players in this player’s cluster. It then divides this distance by the distance between this player and all players in the next nearest cluster. Silhouette scores range between -1 and 1 (where negative one means the player is in the wrong cluster, 0 means the clusters completely overlap, and 1 means the clusters are extermely well separated).</p>

<p>Six clusters has the highest silhouette score at 0.19. 0.19 is not great, and suggests a different clustering algorithm might be better. More on this later.</p>

<p>Because 6 clusters is the elbow and has the highest silhouette score, I will use 6 clusters in my grouping analysis. Okay, now that I decided on 6 clusters lets see what players fall into what clusters!</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">final_fit</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">)</span> <span class="c">#fit 6 clusters</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span> <span class="c">#label each data point with its clusters</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">saveIDs</span> <span class="c">#of course we want to know what players are in what cluster</span>
</span><span class='line'><span class="n">player_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">players_df</span><span class="p">[</span><span class="n">players_df</span><span class="p">[</span><span class="err">‘</span><span class="n">PERSON_ID</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">x</span><span class="p">][</span><span class="err">‘</span><span class="n">DISPLAY_LAST_COMMA_FIRST</span><span class="err">’</span><span class="p">])</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">header</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]]</span>
</span><span class='line'><span class="c"># because playerID #s mean nothing to me, lets get the names too</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">]</span> <span class="o">=</span> <span class="n">player_names</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span> <span class="nb">id</span><span class="o">=</span><span class="s">&quot;lets-also-create-a-dataframe-with-data-about-where-the-clusters-occur-in-the-5-component-pca-space&quot;</span><span class="o">&gt;</span><span class="n">lets</span> <span class="n">also</span> <span class="n">create</span> <span class="n">a</span> <span class="n">dataframe</span> <span class="k">with</span> <span class="n">data</span> <span class="n">about</span> <span class="n">where</span> <span class="n">the</span> <span class="n">clusters</span> <span class="n">occur</span> <span class="ow">in</span> <span class="n">the</span> <span class="mi">5</span> <span class="n">component</span> <span class="n">PCA</span> <span class="n">space</span><span class="o">.&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">cluster_locs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="err">‘</span><span class="n">component</span> <span class="o">%</span><span class="n">s</span><span class="err">’</span><span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span><span class="mi">1</span><span class="p">))])</span>
</span><span class='line'><span class="n">cluster_locs</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">factor_names</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Awesome. Now lets see how all the clusters look. These clusters were created in 5 dimensional space, which is not easy to visualize. Below I plot another scatter matrix. The scatter matrix allows us to visualize the clusters in different 2D combinations of the 5D space.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gaussian_kde</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">centroids</span> <span class="o">=</span> <span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="c">#find centroids so we can plot them</span>
</span><span class='line'><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="err">‘</span><span class="n">r</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">g</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">y</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">b</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">c</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">m</span><span class="err">’</span><span class="p">]</span> <span class="c">#cluster colors</span>
</span><span class='line'><span class="n">Clusters</span> <span class="o">=</span> <span class="p">[</span><span class="err">‘</span><span class="n">Cluster</span> <span class="mi">0</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Cluster</span> <span class="mi">1</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Cluster</span> <span class="mi">2</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Cluster</span> <span class="mi">3</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Cluster</span> <span class="mi">4</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Cluster</span> <span class="mi">5</span><span class="err">’</span><span class="p">]</span> <span class="c">#cluster…names&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">numdata</span><span class="p">,</span> <span class="n">numvars</span> <span class="o">=</span> <span class="n">reduced_data</span><span class="o">.</span><span class="n">shape</span> <span class="c">#players by PCA components</span>
</span><span class='line'><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="n">numvars</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="n">numvars</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span> <span class="c">#create a scatter matrix with 5**2 cells</span>
</span><span class='line'><span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">recs</span><span class="o">=</span><span class="p">[]</span>
</span><span class='line'><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">colors</span><span class="p">:</span> <span class="c">#make some patches for the legend</span>
</span><span class='line'>    <span class="n">recs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">fc</span><span class="o">=</span><span class="n">col</span><span class="p">))</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">fig</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">recs</span><span class="p">,</span><span class="n">Clusters</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="n">ncol</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span> <span class="c">#create legend with patches above&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
</span><span class='line'>    <span class="c"># Hide all ticks and labels</span>
</span><span class='line'>    <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_yticklabels</span><span class="p">(),</span> <span class="n">visible</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c">#tick labels are too much with this many subplots</span>
</span><span class='line'>    <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">get_xticklabels</span><span class="p">(),</span> <span class="n">visible</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> <span class="c">#again, too much</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">5</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">factor_names</span><span class="p">[</span><span class="n">i</span><span class="o">/</span><span class="mi">5</span><span class="p">])</span> <span class="c">#label outer y axes</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">i</span><span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span><span class="mi">19</span><span class="p">:</span><span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">factor_names</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">20</span><span class="p">])</span> <span class="c">#label outer x axes&lt;/p&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)):</span>
</span><span class='line'>    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">),</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">)]:</span>
</span><span class='line'>        <span class="c">#plot individual data points and cluster centers</span>
</span><span class='line'>        <span class="n">axes</span><span class="p">[</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">[:,</span> <span class="n">x</span><span class="p">],</span> <span class="n">reduced_data</span><span class="p">[:,</span> <span class="n">y</span><span class="p">],</span> <span class="err">‘</span><span class="n">k</span><span class="o">.</span><span class="err">’</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span class='line'>        <span class="n">axes</span><span class="p">[</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">[:,</span><span class="n">x</span><span class="p">],</span> <span class="n">centroids</span><span class="p">[:,</span><span class="n">y</span><span class="p">],</span><span class="n">marker</span><span class="o">=</span><span class="err">’</span><span class="n">x</span><span class="err">’</span><span class="p">,</span><span class="n">s</span><span class="o">=</span><span class="mi">169</span><span class="p">,</span><span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">h1</span> <span class="nb">id</span><span class="o">=</span><span class="s">&quot;create-kernel-density-estimation-for-each-pca-factor-on-the-diagonals&quot;</span><span class="o">&gt;</span><span class="n">create</span> <span class="n">kernel</span> <span class="n">density</span> <span class="n">estimation</span> <span class="k">for</span> <span class="n">each</span> <span class="n">PCA</span> <span class="n">factor</span> <span class="n">on</span> <span class="n">the</span> <span class="n">diagonals</span><span class="o">&lt;/</span><span class="n">h1</span><span class="o">&gt;</span>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">factor_names</span><span class="p">):</span>
</span><span class='line'>    <span class="n">density</span> <span class="o">=</span> <span class="n">gaussian_kde</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">[:,</span><span class="n">i</span><span class="p">])</span>
</span><span class='line'>    <span class="n">density</span><span class="o">.</span><span class="n">covariance_factor</span> <span class="o">=</span> <span class="k">lambda</span> <span class="p">:</span> <span class="o">.</span><span class="mi">25</span>
</span><span class='line'>    <span class="n">density</span><span class="o">.</span><span class="n">_compute_covariance</span><span class="p">()</span>
</span><span class='line'>    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">[:,</span><span class="n">i</span><span class="p">]),</span><span class="nb">max</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]))</span>
</span><span class='line'>    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">density</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/scatter_mat2_nba.png" /></p>

<p>In this plot above. I mark the center of a given cluster with an X. For example, Cluster 0 and Cluster 5 are both high in outside skills. Cluster 5 is also high in rim scoring, but low in pure points.</p>

<p>Below I look at the players in each cluster. The first thing I do is identify the player closest to the cluster’s center. I call this player the prototype. It is the player that most exemplifies a cluster.</p>

<p>I then show a picture of this player because… well I wanted to see who these players were. 
I print out this player’s stats and the cluster’s centroid location. 
Finally, I print out the first ten players in this cluster. This is the first ten players alphabetically. Not the ten players closest to cluster center.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
</span><span class='line'><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">name</span> <span class="o">=</span> <span class="n">player_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">euclidean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reduced_data</span><span class="p">])]</span> <span class="c">#find cluster prototype</span>
</span><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">name</span><span class="p">][</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]))</span> <span class="c">#get players ID number</span>
</span><span class='line'><span class="c">#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)</span>
</span><span class='line'><span class="n">player</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="mf">4.</span><span class="n">bp</span><span class="o">.</span><span class="n">blogspot</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">_RaOrchOImw8</span><span class="o">/</span><span class="n">S3mNk3exLeI</span><span class="o">/</span><span class="n">AAAAAAAAdZk</span><span class="o">/</span><span class="n">Hs</span><span class="o">-</span><span class="mi">81</span><span class="n">mnXO_E</span><span class="o">/</span><span class="n">s400</span><span class="o">/</span><span class="n">Lloyd</span><span class="o">+</span><span class="n">Daniels</span><span class="o">.</span><span class="n">jpg</span><span class="err">’</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
</span><span class='line'><span class="c">#display(df[df[‘Name’]==name]) #prototype’s stats</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">cluster_locs</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">])</span> <span class="c">#cluster centroid location</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">][</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span> <span class="c">#first ten players in the cluster (alphabetically)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="http://4.bp.blogspot.com/_RaOrchOImw8/S3mNk3exLeI/AAAAAAAAdZk/Hs-81mnXO_E/s400/Lloyd+Daniels.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.830457</td>
      <td>-0.930833</td>
      <td>0.28203</td>
      <td>-0.054093</td>
      <td>0.43606</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>16       Afflalo, Arron
20         Ainge, Danny
40           Allen, Ray
46        Alston, Rafer
50     Aminu, Al-Farouq
53      Andersen, David
54       Anderson, Alan
56      Anderson, Derek
60      Anderson, James
63       Anderson, Kyle
Name: Name, dtype: object
</code></pre>

<p>First, let me mention that cluster number is a purely categorical variable. Not ordinal. If you run this analysis, you will likely create clusters with similar players, but in a different order. For example, your cluster 1 might be my cluster 0.</p>

<p>Cluster 0 has the most players (25%; about 490 of the 1965 in this cluster analysis) and is red in the scatter matrix above.</p>

<p>Cluster 0 players are second highest in outside shooting (in the table above you can see their average score on the outside skills component is 0.83). These players are lowest in rim scoring (-0.93), so they do not draw many fouls - they are basically the snipers from the outside.</p>

<p>The prototype is Lloyd Daniels who takes a fair number of 3s. I wouldn’t call 31% a dominant 3-point percentage, but its certainly not bad. Notably, Lloyd Daniels doesn’t seem to do much but shoot threes, as 55% of his shots come from the great beyond.</p>

<p>Cluster 0 notable players include Andrea Bargnani, JJ Barea, Danilo Gallinari, and Brandon Jennings. Some forwards. Some Guards. Mostly good shooters.</p>

<p>On to Cluster 1… I probably should have made a function from this code, but I enjoyed picking the players pictures too much.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">name</span> <span class="o">=</span> <span class="n">player_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">euclidean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reduced_data</span><span class="p">])]</span>
</span><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">name</span><span class="p">][</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]))</span>
</span><span class='line'><span class="c">#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)</span>
</span><span class='line'><span class="n">player</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">allshookdown</span><span class="o">.</span><span class="n">files</span><span class="o">.</span><span class="n">wordpress</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="mi">2009</span><span class="o">/</span><span class="mo">06</span><span class="o">/</span><span class="n">laettner_200_921121</span><span class="o">.</span><span class="n">jpg</span><span class="err">?</span><span class="n">w</span><span class="o">=</span><span class="mi">200</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">h</span><span class="o">=</span><span class="mi">300</span><span class="err">’</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
</span><span class='line'><span class="c">#display(df[df[‘Name’]==name])</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">cluster_locs</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">][</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="https://allshookdown.files.wordpress.com/2009/06/laettner_200_921121.jpg?w=200&amp;h=300" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>-0.340177</td>
      <td>1.008111</td>
      <td>1.051622</td>
      <td>-0.150204</td>
      <td>0.599516</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>1         Abdul-Jabbar, Kareem
4         Abdur-Rahim, Shareef
9                 Adams, Alvan
18               Aguirre, Mark
75      Antetokounmpo, Giannis
77            Anthony, Carmelo
85             Arenas, Gilbert
121                 Baker, Vin
133           Barkley, Charles
148            Bates, Billyray
Name: Name, dtype: object
</code></pre>

<p>Cluster 1 is green in the scatter matrix and includes about 14% of players.</p>

<p>Cluster 1 is highest on the rim scoring, pure points, and Dead Eye components. These players get the ball in the hoop.</p>

<p>Christian Laettner is the prototype. He’s a solid scoring forward.</p>

<p>Gilbert Arenas stands out in the first ten names as I was tempted to think of this cluster as big men, but it really seems to be players who shoot, score, and draw fouls.</p>

<p>Cluster 1 Notable players include James Harden,Kevin Garnet, Kevin Durant, Tim Duncan, Kobe, Lebron, Kevin Martin, Shaq, Anthony Randolph??, Kevin Love, Derrick Rose, and Michael Jordan.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">name</span> <span class="o">=</span> <span class="n">player_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">euclidean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reduced_data</span><span class="p">])]</span>
</span><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">name</span><span class="p">][</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]))</span>
</span><span class='line'><span class="c">#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)</span>
</span><span class='line'><span class="n">player</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">imageocd</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">images</span><span class="o">/</span><span class="n">nba10</span><span class="o">/</span><span class="n">doug</span><span class="o">-</span><span class="n">west</span><span class="o">-</span><span class="n">wallpaper</span><span class="o">-</span><span class="n">height</span><span class="o">-</span><span class="n">weight</span><span class="o">-</span><span class="n">position</span><span class="o">-</span><span class="n">college</span><span class="o">-</span><span class="n">high</span><span class="o">-</span><span class="n">school</span><span class="o">/</span><span class="n">doug</span><span class="o">-</span><span class="n">west</span><span class="o">.</span><span class="n">jpg</span><span class="err">’</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
</span><span class='line'><span class="c">#display(df[df[‘Name’]==name])</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">cluster_locs</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="mi">2</span><span class="p">][</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="http://imageocd.com/images/nba10/doug-west-wallpaper-height-weight-position-college-high-school/doug-west.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.013618</td>
      <td>0.101054</td>
      <td>0.445377</td>
      <td>-0.347974</td>
      <td>-1.257634</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>2      Abdul-Rauf, Mahmoud
3       Abdul-Wahad, Tariq
5           Abernethy, Tom
10           Adams, Hassan
14         Addison, Rafael
24            Alarie, Mark
27      Aldridge, LaMarcus
31     Alexander, Courtney
35           Alford, Steve
37            Allen, Lavoy
Name: Name, dtype: object
</code></pre>

<p>Cluster 2 is yellow in the scatter matrix and includes about 17% of players.</p>

<p>Lots of big men who are not outside shooters and don’t draw many fouls. These players are strong 2 point shooters and free throw shooters. I think of these players as mid-range shooters. Many of the more recent Cluster 2 players are forwards since mid-range guards do not have much of a place in the current NBA.</p>

<p>Cluster 2’s prototype is Doug West. Doug West shoots well from the free throw line and on 2-point attempts, but not the 3-point line. He does not draw many fouls or collect many rebounds.</p>

<p>Cluster 2 noteable players include LaMarcus Aldridge, Tayshaun Prince, Thaddeus Young, and Shaun Livingston</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">name</span> <span class="o">=</span> <span class="n">player_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">euclidean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reduced_data</span><span class="p">])]</span>
</span><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">name</span><span class="p">][</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]))</span>
</span><span class='line'><span class="c">#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)</span>
</span><span class='line'><span class="n">player</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="mf">4.</span><span class="n">bp</span><span class="o">.</span><span class="n">blogspot</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">_f5MWZq1BJXI</span><span class="o">/</span><span class="n">TCDRy3v6m9I</span><span class="o">/</span><span class="n">AAAAAAAAACc</span><span class="o">/</span><span class="n">Ux8M7uiadoc</span><span class="o">/</span><span class="n">s400</span><span class="o">/</span><span class="n">cato</span><span class="o">.</span><span class="n">jpg</span><span class="err">’</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
</span><span class='line'><span class="c">#display(df[df[‘Name’]==name])</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">cluster_locs</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="mi">3</span><span class="p">][</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="http://4.bp.blogspot.com/_f5MWZq1BJXI/TCDRy3v6m9I/AAAAAAAAACc/Ux8M7uiadoc/s400/cato.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>-1.28655</td>
      <td>-0.467105</td>
      <td>-0.133546</td>
      <td>0.905368</td>
      <td>0.000679</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>7            Acres, Mark
8            Acy, Quincy
13         Adams, Steven
15          Adrien, Jeff
21        Ajinca, Alexis
26         Aldrich, Cole
34     Alexander, Victor
45       Alston, Derrick
51         Amundson, Lou
52       Andersen, Chris
Name: Name, dtype: object
</code></pre>

<p>Cluster 3 is blue in the scatter matrix and includes about 16% of players.</p>

<p>Cluster 3 players do not have outside skills such as assists and 3-point shooting (they’re last in outside skills). They do not draw many fouls or shoot well from the free throw line. These players do not shoot often, but have a decent shooting percentage. This is likely because they only shoot when wide open next to the hoop.</p>

<p>Cluster 3 players are highest on the defensive big man component. They block lots of shots and collect lots of rebounds.</p>

<p>The Cluster 3 prototype is Kelvin Cato. Cato is not and outside shooter and he only averages 7.5 shots per 36, but he makes these shots at a decent clip. Cato averages about 10 rebounds per 36.</p>

<p>Notable Cluster 3 players include Andrew Bogut, Tyson Chandler, Andre Drummond, Kawahi Leonard??, Dikembe Mutumbo, and Hassan Whiteside.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">name</span> <span class="o">=</span> <span class="n">player_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">euclidean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reduced_data</span><span class="p">])]</span>
</span><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="n">name</span><span class="p">][</span><span class="err">‘</span><span class="n">PLAYER_ID</span><span class="err">’</span><span class="p">]))</span>
</span><span class='line'><span class="c">#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”)</span>
</span><span class='line'><span class="n">player</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">thenolookpass</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">wp</span><span class="o">-</span><span class="n">content</span><span class="o">/</span><span class="n">uploads</span><span class="o">/</span><span class="mi">2012</span><span class="o">/</span><span class="mo">01</span><span class="o">/</span><span class="n">IMG</span><span class="o">-</span><span class="mi">724</span><span class="n">x1024</span><span class="o">.</span><span class="n">jpg</span><span class="err">’</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span> <span class="c">#a photo just for fun</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
</span><span class='line'><span class="c">#display(df[df[‘Name’]==name])</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">cluster_locs</span><span class="p">[</span><span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="mi">4</span><span class="p">][</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="http://www.thenolookpass.com/wp-content/uploads/2012/01/IMG-724x1024.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>-0.668445</td>
      <td>0.035927</td>
      <td>-0.917479</td>
      <td>-1.243347</td>
      <td>0.244897</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>0         Abdelnaby, Alaa
17          Ager, Maurice
28       Aleksinas, Chuck
33         Alexander, Joe
36          Allen, Jerome
48          Amaechi, John
49          Amaya, Ashraf
74          Anstey, Chris
82         Araujo, Rafael
89     Armstrong, Brandon
Name: Name, dtype: object
</code></pre>

<p>Cluster 4 is cyan in the scatter matrix above and includes the least number of players (about 13%).</p>

<p>Cluster 4 players are not high on outsize skills. They are average on rim scoring. They do not score many points, and they don’t fill up the defensive side of the stat sheet. These players don’t seem like all stars.</p>

<p>Looking at Doug Edwards’ stats - certainly not a 3-point shooter. I guess a good description of cluster 4 players might be … NBA caliber bench warmers.</p>

<p>Cluster 4’s notable players include Yi Jianlian and Anthony Bennet….yeesh</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">name</span> <span class="o">=</span> <span class="n">player_names</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">euclidean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">final_fit</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reduced_data</span><span class="p">])]</span>
</span><span class='line'><span class="c">#PlayerID = str(int(df[df[‘Name’]==name][‘PLAYER_ID’]))</span>
</span><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="mi">76993</span><span class="p">)</span> <span class="c">#Two Gerald Hendersons!</span>
</span><span class='line'><span class="c">#player = Image(url = “http://stats.nba.com/media/players/230x185/”+PlayerID+”.png”, width=100)</span>
</span><span class='line'><span class="n">player</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">cdn</span><span class="o">.</span><span class="n">fansided</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">wp</span><span class="o">-</span><span class="n">content</span><span class="o">/</span><span class="n">blogs</span><span class="o">.</span><span class="n">dir</span><span class="o">/</span><span class="mi">18</span><span class="o">/</span><span class="n">files</span><span class="o">/</span><span class="mi">2014</span><span class="o">/</span><span class="mo">04</span><span class="o">/</span><span class="n">b__gerald_henderson_82</span><span class="o">.</span><span class="n">jpg</span><span class="err">’</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">player</span><span class="p">)</span>
</span><span class='line'><span class="c">#display(df[df[‘PLAYER_ID’]==76993])</span>
</span><span class='line'><span class="n">display</span><span class="p">(</span><span class="n">cluster_locs</span><span class="p">[</span><span class="mi">5</span><span class="p">:])</span>
</span><span class='line'><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">]</span><span class="o">==</span><span class="mi">5</span><span class="p">][</span><span class="err">‘</span><span class="n">Name</span><span class="err">’</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="http://cdn.fansided.com/wp-content/blogs.dir/18/files/2014/04/b__gerald_henderson_82.jpg" width="100" /></p>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Outside Skills</th>
      <th>Rim Scoring</th>
      <th>Pure Points</th>
      <th>Defensive Big Man</th>
      <th>Dead Eye</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.890984</td>
      <td>0.846109</td>
      <td>-0.926444</td>
      <td>0.735306</td>
      <td>-0.092395</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code>12          Adams, Michael
30         Alexander, Cory
41             Allen, Tony
62         Anderson, Kenny
65      Anderson, Mitchell
78           Anthony, Greg
90      Armstrong, Darrell
113           Bagley, John
126          Banks, Marcus
137         Barrett, Andre
Name: Name, dtype: object
</code></pre>

<p>Cluster 5 is magenta in the scatter matrix and includes 16% of players.</p>

<p>Cluster 5 players are highest in outside skills and second highest in rim scoring yet these players are dead last in pure points. It seems they score around the rim, but do not draw many fouls. They are second highest in defensive big man.</p>

<p>Gerald Henderson Sr is the prototype. Henderson is a good 3 point and free throw shooter but does not draw many fouls. He has lots of assists and steals.</p>

<p>Of interest mostly because it generates an error in my code, Gerald Henderson Jr is in cluster 2 - the mid range shooters.</p>

<p>Notable cluster 5 players include Mugsy Bogues, MCW, Jeff Hornacek, Magic Johnson, Jason Kidd, Steve Nash, Rajon Rando, John Stockton. Lots of guards.</p>

<p>In the cell below, I plot the percentage of players in each cluster.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="err">‘</span><span class="n">kmeans_label</span><span class="err">’</span><span class="p">],</span> <span class="n">normed</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span><span class="n">rwidth</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">,</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">5.5</span><span class="p">],[</span><span class="err">‘</span><span class="n">Group</span> <span class="mi">0</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">1</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">2</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Goup</span> <span class="mi">3</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">4</span><span class="err">’</span><span class="p">,</span><span class="err">’</span><span class="n">Group</span> <span class="mi">5</span><span class="err">’</span><span class="p">])</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="err">‘</span><span class="n">Percentage</span> <span class="n">of</span> <span class="n">Players</span> <span class="ow">in</span> <span class="n">Each</span> <span class="n">Cluster</span><span class="err">’</span><span class="p">);</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/cluster_inc_nba.png" /></p>

<p>I began this post by asking whether player positions is the most natural way to group NBA players. The clustering analysis here suggests not.</p>

<p>Here’s my take on the clusters: Cluster 0 is pure shooters, Cluster 1 is talented scorers, Cluster 2 is mid-range shooters, Cluster 3 is defensive big-men, Cluster 4 is bench warmers, Cluster 5 is distributors. We might call the “positions” shooters, scorers, rim protectors, and distributors.</p>

<p>It’s possible that our notion of position comes more from defensive performance than offensive. On defense, a player must have a particular size and agility to guard a particular opposing player. Because of this, a team will want a range of sizes and agility - strong men to defend the rim and quick men to defend agile ball carriers. Box scores are notoriously bad at describing defensive performance. This could account for the lack of “positions” in my cluster.</p>

<p>I did not include player height and weight in this analysis. I imagine height and weight might have made clusters that resemble the traditional positions. I chose to not include height and weight because these are player attributes; not player performance.</p>

<p>After looking through all the groups one thing that stands out to me is the lack of specialization. For example we did not find a single cluster of incredible 3-point shooters. Cluster 1 includes many great shooters, but it’s not populated exclusively by great shooters. It would be interesting if adding additional clusters to the analysis could find more specific clusters such as big-men that can shoot from the outside (e.g., Dirk) or high-volume scorers (e.g., Kobe).</p>

<p>I tried to list some of the aberrant cluster choices in the notable players to give you an idea for the amount of error in the clustering. These aberrant choices are not errors, they are simply an artifact of how k-means defines clusters. Using a different clustering algorithm would produce different clusters. On that note, the silhouette score of this clustering model is not great, yet the clustering algorithm definitely found similar players, so its not worthless. Nonetheless, clusters of NBA players might not be spherical. This would prevent a high silhouette score. Trying a different algorithm without the spherical clusters assumption would definitely be worthwhile.</p>

<p>Throughout this entire analysis, I was tempted to think about group membership, as a predictor of a player’s future performance. For instance, when I saw Karl Anthony Towns in the same cluster as Kareem Abdul-Jabbar, I couldn’t help but think this meant good things for Karl Anthony Towns. Right now, this doesn’t seem justified. No group included less than 10% of players so not much of an oppotunity for a uniformly “star” group to form. Each group contained some good and some bad players. Could more clusters change this? I plan on examining whether more clusters can improve the clustering algorithm’s ability to find clusters of exclusively quality players. If it works, I’ll post it here.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Creating NBA Shot Charts]]></title>
    <link href="http://www.danvatterott.com/blog/2015/12/22/creating-nba-shot-charts/"/>
    <updated>2015-12-22T14:21:06-05:00</updated>
    <id>http://www.danvatterott.com/blog/2015/12/22/creating-nba-shot-charts</id>
    <content type="html"><![CDATA[<p>Here I create shot charts depicting both shooting percentage and the number of shots taken at different court locations, similar to those produced on Austin Clemens’ website (http://www.austinclemens.com/shotcharts/).</p>

<p>To create the shooting charts, I looked to a post by Savvas Tjortjoglou (http://savvastjortjoglou.com/nba-shot-sharts.html). Savvas’ post is great, but his plots only depict the number of shots taken at different locations.</p>

<p>I’m interested in both the number of shots AND the shooting percentage at different locations. This requires a little bit more work. Here’s how I did it.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#import some libraries and tell ipython we want inline figures rather than interactive figures. </span>
</span><span class='line'><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span><span class="o">,</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span><span class="o">,</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span><span class="o">,</span> <span class="nn">matplotlib</span> <span class="kn">as</span> <span class="nn">mpl</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>First, we have to acquire shooting data about each player. I retrieved the data from NBA.com’s API using code from Savvas Tjortjoglou’s post.</p>

<p>I won’t show you the output of this function. If you’re interested in the details, I recommend Savvas Tjortjoglou’s post.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">aqcuire_shootingData</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span><span class="n">Season</span><span class="p">):</span>
</span><span class='line'>    <span class="kn">import</span> <span class="nn">requests</span>
</span><span class='line'>    <span class="n">shot_chart_url</span> <span class="o">=</span> <span class="err">‘</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">stats</span><span class="o">.</span><span class="n">nba</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">stats</span><span class="o">/</span><span class="n">shotchartdetail</span><span class="err">?</span><span class="n">CFID</span><span class="o">=</span><span class="mi">33</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">CFPARAMS</span><span class="o">=</span><span class="err">’</span><span class="o">+</span><span class="n">Season</span><span class="o">+</span><span class="err">’</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">ContextFilter</span><span class="o">=</span><span class="err">’</span>\
</span><span class='line'>                    <span class="err">‘</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">ContextMeasure</span><span class="o">=</span><span class="n">FGA</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">DateFrom</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">DateTo</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">GameID</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">GameSegment</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">LastNGames</span><span class="o">=</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">LeagueID</span><span class="o">=</span><span class="err">’</span>\
</span><span class='line'>                    <span class="err">‘</span><span class="mo">00</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Location</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">MeasureType</span><span class="o">=</span><span class="n">Base</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Month</span><span class="o">=</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">OpponentTeamID</span><span class="o">=</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Outcome</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">PaceAdjust</span><span class="o">=</span><span class="err">’</span>\
</span><span class='line'>                    <span class="err">‘</span><span class="n">N</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">PerMode</span><span class="o">=</span><span class="n">PerGame</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Period</span><span class="o">=</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">PlayerID</span><span class="o">=</span><span class="err">’</span><span class="o">+</span><span class="n">PlayerID</span><span class="o">+</span><span class="err">’</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">PlusMinus</span><span class="o">=</span><span class="n">N</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Position</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Rank</span><span class="o">=</span><span class="err">’</span>\
</span><span class='line'>                    <span class="err">‘</span><span class="n">N</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">RookieYear</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">Season</span><span class="o">=</span><span class="err">’</span><span class="o">+</span><span class="n">Season</span><span class="o">+</span><span class="err">’</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">SeasonSegment</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">SeasonType</span><span class="o">=</span><span class="n">Regular</span><span class="o">+</span><span class="n">Season</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">TeamID</span><span class="o">=</span><span class="err">’</span>\
</span><span class='line'>                    <span class="err">‘</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">VsConference</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">VsDivision</span><span class="o">=&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">mode</span><span class="o">=</span><span class="n">Advanced</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">showDetails</span><span class="o">=</span><span class="mi">0</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">showShots</span><span class="o">=</span><span class="mi">1</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="n">showZones</span><span class="o">=</span><span class="mi">0</span><span class="err">’</span>
</span><span class='line'>    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">shot_chart_url</span><span class="p">)</span>
</span><span class='line'>    <span class="n">headers</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="err">‘</span><span class="n">resultSets</span><span class="err">’</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="err">‘</span><span class="n">headers</span><span class="err">’</span><span class="p">]</span>
</span><span class='line'>    <span class="n">shots</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()[</span><span class="err">‘</span><span class="n">resultSets</span><span class="err">’</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="err">‘</span><span class="n">rowSet</span><span class="err">’</span><span class="p">]</span>
</span><span class='line'>    <span class="n">shot_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">shots</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">shot_df</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Next, we need to draw a basketball court which we can draw the shot chart on. This basketball court has to use the same coordinate system as NBA.com’s API. For instance, 3pt shots have to be X units from hoop and layups have to be Y units from the hoop. Again, I recycle code from Savvas Tjortjoglou (phew! figuring out NBA.com’s coordinate system would have taken me awhile).</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">draw_court</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="err">’</span><span class="n">black</span><span class="err">’</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">outer_lines</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
</span><span class='line'>    <span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Circle</span><span class="p">,</span> <span class="n">Rectangle</span><span class="p">,</span> <span class="n">Arc</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
</span><span class='line'>        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
</span><span class='line'>    <span class="n">hoop</span> <span class="o">=</span> <span class="n">Circle</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">radius</span><span class="o">=</span><span class="mf">7.5</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>    <span class="n">backboard</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.5</span><span class="p">),</span> <span class="mi">60</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'>    <span class="n">outer_box</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="o">-</span><span class="mi">80</span><span class="p">,</span> <span class="o">-</span><span class="mf">47.5</span><span class="p">),</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
</span><span class='line'>                          <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>    <span class="n">inner_box</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="o">-</span><span class="mi">60</span><span class="p">,</span> <span class="o">-</span><span class="mf">47.5</span><span class="p">),</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
</span><span class='line'>                          <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>    <span class="n">top_free_throw</span> <span class="o">=</span> <span class="n">Arc</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mf">142.5</span><span class="p">),</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">theta1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">theta2</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span>
</span><span class='line'>                         <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>    <span class="n">bottom_free_throw</span> <span class="o">=</span> <span class="n">Arc</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mf">142.5</span><span class="p">),</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">theta1</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">theta2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span class='line'>                            <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="err">’</span><span class="n">dashed</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'>    <span class="n">restricted</span> <span class="o">=</span> <span class="n">Arc</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="n">theta1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">theta2</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span>
</span><span class='line'>                     <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'>    <span class="n">corner_three_a</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="o">-</span><span class="mi">220</span><span class="p">,</span> <span class="o">-</span><span class="mf">47.5</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">140</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span>
</span><span class='line'>                               <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'>    <span class="n">corner_three_b</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="mi">220</span><span class="p">,</span> <span class="o">-</span><span class="mf">47.5</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">140</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'>    <span class="n">three_arc</span> <span class="o">=</span> <span class="n">Arc</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">475</span><span class="p">,</span> <span class="mi">475</span><span class="p">,</span> <span class="n">theta1</span><span class="o">=</span><span class="mi">22</span><span class="p">,</span> <span class="n">theta2</span><span class="o">=</span><span class="mi">158</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span>
</span><span class='line'>                    <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'>    <span class="n">center_outer_arc</span> <span class="o">=</span> <span class="n">Arc</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mf">422.5</span><span class="p">),</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="n">theta1</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">theta2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span class='line'>                           <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'>    <span class="n">center_inner_arc</span> <span class="o">=</span> <span class="n">Arc</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mf">422.5</span><span class="p">),</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="n">theta1</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">theta2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span><span class='line'>                           <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
</span><span class='line'>    <span class="n">court_elements</span> <span class="o">=</span> <span class="p">[</span><span class="n">hoop</span><span class="p">,</span> <span class="n">backboard</span><span class="p">,</span> <span class="n">outer_box</span><span class="p">,</span> <span class="n">inner_box</span><span class="p">,</span> <span class="n">top_free_throw</span><span class="p">,</span>
</span><span class='line'>                      <span class="n">bottom_free_throw</span><span class="p">,</span> <span class="n">restricted</span><span class="p">,</span> <span class="n">corner_three_a</span><span class="p">,</span>
</span><span class='line'>                      <span class="n">corner_three_b</span><span class="p">,</span> <span class="n">three_arc</span><span class="p">,</span> <span class="n">center_outer_arc</span><span class="p">,</span>
</span><span class='line'>                      <span class="n">center_inner_arc</span><span class="p">]</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">outer_lines</span><span class="p">:</span>
</span><span class='line'>        <span class="n">outer_lines</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="o">-</span><span class="mi">250</span><span class="p">,</span> <span class="o">-</span><span class="mf">47.5</span><span class="p">),</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">470</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">,</span>
</span><span class='line'>                                <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>        <span class="n">court_elements</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">outer_lines</span><span class="p">)</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">court_elements</span><span class="p">:</span>
</span><span class='line'>    <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">element</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
</span><span class='line'><span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([])</span>
</span><span class='line'><span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
</span><span class='line'><span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
</span><span class='line'><span class="k">return</span> <span class="n">ax</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p>We want to create an array of shooting percentages across the different locations in our plot. I decided to group locations into evenly spaced hexagons using matplotlib’s hexbin function (http://matplotlib.org/api/pyplot_api.html). This function will count the number of times a shot is taken from a location in each of the hexagons.</p>

<p>The hexagons are evenly spaced across the xy grid. The variable “gridsize” controls the number of hexagons. The variable “extent” controls where the first hexagon and last hexagon are drawn (ordinarily the first hexagon is drawn based on the location of the first shot).</p>

<p>Computing shooting percentages requires counting the number of made and taken shots in each hexagon, so I run hexbin once using all shots taken and once using only the location of made shots. Then I simply divide the number of made shots by taken shots at each location.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">find_shootingPcts</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">gridNum</span><span class="p">):</span>
</span><span class='line'>    <span class="n">x</span> <span class="o">=</span> <span class="n">shot_df</span><span class="o">.</span><span class="n">LOC_X</span><span class="p">[</span><span class="n">shot_df</span><span class="p">[</span><span class="err">‘</span><span class="n">LOC_Y</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="mf">425.1</span><span class="p">]</span> <span class="c">#i want to make sure to only include shots I can draw</span>
</span><span class='line'>    <span class="n">y</span> <span class="o">=</span> <span class="n">shot_df</span><span class="o">.</span><span class="n">LOC_Y</span><span class="p">[</span><span class="n">shot_df</span><span class="p">[</span><span class="err">‘</span><span class="n">LOC_Y</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="mf">425.1</span><span class="p">]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">x_made</span> <span class="o">=</span> <span class="n">shot_df</span><span class="o">.</span><span class="n">LOC_X</span><span class="p">[(</span><span class="n">shot_df</span><span class="p">[</span><span class="s">&#39;SHOT_MADE_FLAG&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="p">(</span><span class="n">shot_df</span><span class="p">[</span><span class="s">&#39;LOC_Y&#39;</span><span class="p">]</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="mf">425.1</span><span class="p">)]</span>
</span><span class='line'><span class="n">y_made</span> <span class="o">=</span> <span class="n">shot_df</span><span class="o">.</span><span class="n">LOC_Y</span><span class="p">[(</span><span class="n">shot_df</span><span class="p">[</span><span class="s">&#39;SHOT_MADE_FLAG&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="p">(</span><span class="n">shot_df</span><span class="p">[</span><span class="s">&#39;LOC_Y&#39;</span><span class="p">]</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="mf">425.1</span><span class="p">)]</span>
</span><span class='line'>
</span><span class='line'><span class="c">#compute number of shots made and taken from each hexbin location</span>
</span><span class='line'><span class="n">hb_shot</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">gridsize</span><span class="o">=</span><span class="n">gridNum</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">250</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">425</span><span class="p">,</span><span class="o">-</span><span class="mi">50</span><span class="p">));</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c">#don&#39;t want to show this figure!</span>
</span><span class='line'><span class="n">hb_made</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hexbin</span><span class="p">(</span><span class="n">x_made</span><span class="p">,</span> <span class="n">y_made</span><span class="p">,</span> <span class="n">gridsize</span><span class="o">=</span><span class="n">gridNum</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">250</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">425</span><span class="p">,</span><span class="o">-</span><span class="mi">50</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Reds</span><span class="p">);</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="c">#compute shooting percentage</span>
</span><span class='line'><span class="n">ShootingPctLocs</span> <span class="o">=</span> <span class="n">hb_made</span><span class="o">.</span><span class="n">get_array</span><span class="p">()</span> <span class="o">/</span> <span class="n">hb_shot</span><span class="o">.</span><span class="n">get_array</span><span class="p">()</span>
</span><span class='line'><span class="n">ShootingPctLocs</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">ShootingPctLocs</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c">#makes 0/0s=0</span>
</span><span class='line'><span class="k">return</span> <span class="p">(</span><span class="n">ShootingPctLocs</span><span class="p">,</span> <span class="n">hb_shot</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p>I really liked how Savvas Tjortjoglou included players’ pictures in his shooting charts, so I recycled this part of his code too. The picture will appear in the bottom right hand corner of the shooting chart</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">acquire_playerPic</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span> <span class="n">zoom</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="p">(</span><span class="mi">250</span><span class="p">,</span><span class="mi">400</span><span class="p">)):</span>
</span><span class='line'>    <span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span>  <span class="n">offsetbox</span> <span class="k">as</span> <span class="n">osb</span>
</span><span class='line'>    <span class="kn">import</span> <span class="nn">urllib</span>
</span><span class='line'>    <span class="n">pic</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="err">“</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">stats</span><span class="o">.</span><span class="n">nba</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">media</span><span class="o">/</span><span class="n">players</span><span class="o">/</span><span class="mi">230</span><span class="n">x185</span><span class="o">/</span><span class="err">”</span><span class="o">+</span><span class="n">PlayerID</span><span class="o">+</span><span class="err">”</span><span class="o">.</span><span class="n">png</span><span class="err">”</span><span class="p">,</span><span class="n">PlayerID</span><span class="o">+</span><span class="err">”</span><span class="o">.</span><span class="n">png</span><span class="err">”</span><span class="p">)</span>
</span><span class='line'>    <span class="n">player_pic</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">pic</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span class='line'>    <span class="n">img</span> <span class="o">=</span> <span class="n">osb</span><span class="o">.</span><span class="n">OffsetImage</span><span class="p">(</span><span class="n">player_pic</span><span class="p">,</span> <span class="n">zoom</span><span class="p">)</span>
</span><span class='line'>    <span class="c">#img.set_offset(offset)</span>
</span><span class='line'>    <span class="n">img</span> <span class="o">=</span> <span class="n">osb</span><span class="o">.</span><span class="n">AnnotationBbox</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span><span class="n">xycoords</span><span class="o">=</span><span class="err">’</span><span class="n">data</span><span class="err">’</span><span class="p">,</span><span class="n">pad</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">box_alignment</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">frameon</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'>    <span class="k">return</span> <span class="n">img</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>I want to depict shooting percentage using a sequential colormap - more red circles = better shooting percentage. The “reds” colormap looks great, but would depict a 0% shooting percentage as white (http://matplotlib.org/users/colormaps.html), and white circles will not appear in my plots. I want 0% shooting to be slight pink, so below I modify the reds colormap.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="c">#cmap = plt.cm.Reds</span>
</span><span class='line'><span class="c">#cdict = cmap._segmentdata</span>
</span><span class='line'><span class="n">cdict</span> <span class="o">=</span> <span class="p">{</span>
</span><span class='line'>    <span class="err">‘</span><span class="n">blue</span><span class="err">’</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6313725709915161</span><span class="p">,</span> <span class="mf">0.6313725709915161</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.4470588266849518</span><span class="p">,</span> <span class="mf">0.4470588266849518</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.29019609093666077</span><span class="p">,</span> <span class="mf">0.29019609093666077</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.11372549086809158</span><span class="p">,</span> <span class="mf">0.11372549086809158</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.05098039284348488</span><span class="p">,</span> <span class="mf">0.05098039284348488</span><span class="p">)],</span>
</span><span class='line'>    <span class="err">‘</span><span class="n">green</span><span class="err">’</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.7333333492279053</span><span class="p">,</span> <span class="mf">0.7333333492279053</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.572549045085907</span><span class="p">,</span> <span class="mf">0.572549045085907</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4156862795352936</span><span class="p">,</span> <span class="mf">0.4156862795352936</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.0941176488995552</span><span class="p">,</span> <span class="mf">0.0941176488995552</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)],</span>
</span><span class='line'>    <span class="err">‘</span><span class="n">red</span><span class="err">’</span><span class="p">:</span> <span class="p">[(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9882352948188782</span><span class="p">,</span> <span class="mf">0.9882352948188782</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.9882352948188782</span><span class="p">,</span> <span class="mf">0.9882352948188782</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9843137264251709</span><span class="p">,</span> <span class="mf">0.9843137264251709</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.7960784435272217</span><span class="p">,</span> <span class="mf">0.7960784435272217</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.40392157435417175</span><span class="p">,</span> <span class="mf">0.40392157435417175</span><span class="p">)]</span>
</span><span class='line'><span class="p">}</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="n">mymap</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">LinearSegmentedColormap</span><span class="p">(</span><span class="err">‘</span><span class="n">my_colormap</span><span class="err">’</span><span class="p">,</span> <span class="n">cdict</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Okay, now lets put it all together. The large function below will use the functions above to create a shot chart depicting shooting percentage as the color of a circle (more red = better shooting %) and the number of shots as the size of a circle (larger circle = more shots). One note about the circle sizes, the size of a circle can increase until they start to overlap. When they start to overlap, I prevent them from growing.</p>

<p>In this function, I compute the shooting percentages and number of shots at each location. Then I draw circles depicting the number of shots taken at that location (circle size) and the shooting percentage at that location (circle color).</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">shooting_plot</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">plot_size</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span><span class="n">gridNum</span><span class="o">=</span><span class="mi">30</span><span class="p">):</span>
</span><span class='line'>    <span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Circle</span>
</span><span class='line'>    <span class="n">x</span> <span class="o">=</span> <span class="n">shot_df</span><span class="o">.</span><span class="n">LOC_X</span><span class="p">[</span><span class="n">shot_df</span><span class="p">[</span><span class="err">‘</span><span class="n">LOC_Y</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="mf">425.1</span><span class="p">]</span>
</span><span class='line'>    <span class="n">y</span> <span class="o">=</span> <span class="n">shot_df</span><span class="o">.</span><span class="n">LOC_Y</span><span class="p">[</span><span class="n">shot_df</span><span class="p">[</span><span class="err">‘</span><span class="n">LOC_Y</span><span class="err">’</span><span class="p">]</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="mf">425.1</span><span class="p">]</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="c">#compute shooting percentage and # of shots</span>
</span><span class='line'><span class="p">(</span><span class="n">ShootingPctLocs</span><span class="p">,</span> <span class="n">shotNumber</span><span class="p">)</span> <span class="o">=</span> <span class="n">find_shootingPcts</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">gridNum</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#draw figure and court</span>
</span><span class='line'><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">plot_size</span><span class="p">)</span><span class="c">#(12,7)</span>
</span><span class='line'><span class="n">cmap</span> <span class="o">=</span> <span class="n">mymap</span> <span class="c">#my modified colormap</span>
</span><span class='line'><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">axes</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span> <span class="c">#where to place the plot within the figure</span>
</span><span class='line'><span class="n">draw_court</span><span class="p">(</span><span class="n">outer_lines</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">250</span><span class="p">,</span><span class="mi">250</span><span class="p">)</span>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">400</span><span class="p">,</span> <span class="o">-</span><span class="mi">25</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#draw player image</span>
</span><span class='line'><span class="n">zoom</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="n">plot_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="mf">12.0</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span> <span class="c">#how much to zoom the player&#39;s pic. I have this hackily dependent on figure size</span>
</span><span class='line'><span class="n">img</span> <span class="o">=</span> <span class="n">acquire_playerPic</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span> <span class="n">zoom</span><span class="p">)</span>
</span><span class='line'><span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#draw circles</span>
</span><span class='line'><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">shots</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ShootingPctLocs</span><span class="p">):</span>
</span><span class='line'>    <span class="n">restricted</span> <span class="o">=</span> <span class="n">Circle</span><span class="p">(</span><span class="n">shotNumber</span><span class="o">.</span><span class="n">get_offsets</span><span class="p">()[</span><span class="n">i</span><span class="p">],</span> <span class="n">radius</span><span class="o">=</span><span class="n">shotNumber</span><span class="o">.</span><span class="n">get_array</span><span class="p">()[</span><span class="n">i</span><span class="p">],</span>
</span><span class='line'>                        <span class="n">color</span><span class="o">=</span><span class="n">cmap</span><span class="p">(</span><span class="n">shots</span><span class="p">),</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</span><span class='line'>    <span class="k">if</span> <span class="n">restricted</span><span class="o">.</span><span class="n">radius</span> <span class="o">&amp;</span><span class="n">gt</span><span class="p">;</span> <span class="mi">240</span><span class="o">/</span><span class="n">gridNum</span><span class="p">:</span> <span class="n">restricted</span><span class="o">.</span><span class="n">radius</span><span class="o">=</span><span class="mi">240</span><span class="o">/</span><span class="n">gridNum</span>
</span><span class='line'>    <span class="n">ax</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">restricted</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'><span class="c">#draw color bar</span>
</span><span class='line'><span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="mf">0.92</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>
</span><span class='line'><span class="n">cb</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">colorbar</span><span class="o">.</span><span class="n">ColorbarBase</span><span class="p">(</span><span class="n">ax2</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">orientation</span><span class="o">=</span><span class="s">&#39;vertical&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">cb</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s">&#39;Shooting %&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">cb</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
</span><span class='line'><span class="n">cb</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">([</span><span class="s">&#39;0%&#39;</span><span class="p">,</span><span class="s">&#39;25%&#39;</span><span class="p">,</span> <span class="s">&#39;50%&#39;</span><span class="p">,</span><span class="s">&#39;75%&#39;</span><span class="p">,</span> <span class="s">&#39;100%&#39;</span><span class="p">])</span>
</span><span class='line'>
</span><span class='line'><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span class='line'><span class="k">return</span> <span class="n">ax</span>
</span></code></pre></td></tr></table></div></figure>
</code></pre>

<p>Ok, thats it! Now, because I’m a t-wolves fan, I’ll output the shot charts of top 6 t-wolves in minutes this year.</p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="err">‘</span><span class="mi">203952</span><span class="err">’</span> <span class="c">#andrew wiggins</span>
</span><span class='line'><span class="n">shot_df</span> <span class="o">=</span> <span class="n">aqcuire_shootingData</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span><span class="err">’</span><span class="mi">2015</span><span class="o">-</span><span class="mi">16</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">ax</span> <span class="o">=</span> <span class="n">shooting_plot</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">plot_size</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/shotChart_wiggins.png" /></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="err">‘</span><span class="mi">1626157</span><span class="err">’</span> <span class="c">#karl anthony towns</span>
</span><span class='line'><span class="n">shot_df</span> <span class="o">=</span> <span class="n">aqcuire_shootingData</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span><span class="err">’</span><span class="mi">2015</span><span class="o">-</span><span class="mi">16</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">ax</span> <span class="o">=</span> <span class="n">shooting_plot</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">plot_size</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/shotChart_towns.png" /></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="err">‘</span><span class="mi">203897</span><span class="err">’</span> <span class="c">#zach lavine</span>
</span><span class='line'><span class="n">shot_df</span> <span class="o">=</span> <span class="n">aqcuire_shootingData</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span><span class="err">’</span><span class="mi">2015</span><span class="o">-</span><span class="mi">16</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">ax</span> <span class="o">=</span> <span class="n">shooting_plot</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">plot_size</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">));</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/shotChart_lavine.png" /></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="err">‘</span><span class="mi">203476</span><span class="err">’</span> <span class="c">#gorgui deing</span>
</span><span class='line'><span class="n">shot_df</span> <span class="o">=</span> <span class="n">aqcuire_shootingData</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span><span class="err">’</span><span class="mi">2015</span><span class="o">-</span><span class="mi">16</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">ax</span> <span class="o">=</span> <span class="n">shooting_plot</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">plot_size</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">));</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/shotChart_dieng.png" /></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="err">‘</span><span class="mi">2755</span><span class="err">’</span> <span class="c">#kevin martin</span>
</span><span class='line'><span class="n">shot_df</span> <span class="o">=</span> <span class="n">aqcuire_shootingData</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span><span class="err">’</span><span class="mi">2015</span><span class="o">-</span><span class="mi">16</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">ax</span> <span class="o">=</span> <span class="n">shooting_plot</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">plot_size</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/shotChart_martin.png" /></p>

<p><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="n">PlayerID</span> <span class="o">=</span> <span class="err">‘</span><span class="mi">201937</span><span class="err">’</span> <span class="c">#ricky rubio</span>
</span><span class='line'><span class="n">shot_df</span> <span class="o">=</span> <span class="n">aqcuire_shootingData</span><span class="p">(</span><span class="n">PlayerID</span><span class="p">,</span><span class="err">’</span><span class="mi">2015</span><span class="o">-</span><span class="mi">16</span><span class="err">’</span><span class="p">)</span>
</span><span class='line'><span class="n">ax</span> <span class="o">=</span> <span class="n">shooting_plot</span><span class="p">(</span><span class="n">shot_df</span><span class="p">,</span> <span class="n">plot_size</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">));</span>
</span></code></pre></td></tr></table></div></figure></p>

<p><img src="/images/shotChart_rubio.png" /></p>

<p>One concern with my plots is the use of hexbin. It’s a bit hacky. In particular, it does not account for the nonlinearity produced by the 3 point line (some hexbins include both long 2-pt shots and 3-pt shots). It would be nice to limit some bins to 3-pt shots, but I can’t think of a way to do this without hardcoding the locations. One advantage with the hexbin method is I can easily change the number of bins. I’m not sure I could produce equivalent flexibility with a plot that bins 2-pt and 3-pt shots seperately.</p>

<p>Another concern is my plots treat all shots as equal, which is not fair. Shooting 40% from the restricted area and behind the 3-pt line are very different. Austin Clemens accounts for this by plotting shooting percentage relative to league average. Maybe I’ll implement something similar in the future.</p>

]]></content>
  </entry>
  
</feed>
