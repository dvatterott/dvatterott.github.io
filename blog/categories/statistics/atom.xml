<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Statistics | Dan Vatterott]]></title>
  <link href="https://danvatterott.com/blog/categories/statistics/atom.xml" rel="self"/>
  <link href="https://danvatterott.com/"/>
  <updated>2022-02-25T14:33:11-06:00</updated>
  <id>https://danvatterott.com/</id>
  <author>
    <name><![CDATA[Dan Vatterott]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Are Some MLB Players More Likely to Hit Into Errors: Statistics]]></title>
    <link href="https://danvatterott.com/blog/2019/06/04/are-some-mlb-players-more-likely-to-hit-into-errors-statistics/"/>
    <updated>2019-06-04T20:04:31-05:00</updated>
    <id>https://danvatterott.com/blog/2019/06/04/are-some-mlb-players-more-likely-to-hit-into-errors-statistics</id>
    <content type="html"><![CDATA[<p>In a <a href="https://danvatterott.com/blog/2019/04/19/are-some-mlb-players-more-likely-to-hit-into-errors-munging/">previous post</a>, I described how to download and clean data for understanding how likely a baseball player is to hit into an error given that they hit the ball into play.</p>

<p>This analysis will statistically demonstrate that some players are more likely to hit into errors than others.</p>

<p>Errors are uncommon, so players hit into errors very infrequently. Estimating the likelihood of an infrequent event is hard and requires lots of data. To acquire as much data as possible, I wrote a bash script that will download data for all players between 1970 and 2018.</p>

<p>This data enables me to use data from multiple years for each player, giving me more data when estimating how likely a particular player is to hit into an error.</p>

<p>{% codeblock lang:bash %}
%%bash</p>

<p>for i in {1970..2018}; do
    echo “YEAR: $i”
    ../scripts/get_data.sh ${i};
done</p>

<p>find processed_data/* -type f -name ‘errors_bip.out’ | \
    xargs awk ‘{print $0”, “FILENAME}’ | \
    sed s1processed_data/11g1 | \
    sed s1/errors_bip.out11g1 &gt; \
        processed_data/all_errors_bip.out
{% endcodeblock %}</p>

<p>The data has 5 columns: playerid, playername, errors hit into, balls hit into play (BIP), and year. The file does not have a header.</p>

<p>{% codeblock lang:bash %}
%%bash
head ../processed_data/all_errors_bip.out
{% endcodeblock %}</p>

<pre><code>aaroh101, Hank Aaron, 8, 453, 1970
aarot101, Tommie Aaron, 0, 53, 1970
abert101, Ted Abernathy, 0, 10, 1970
adaij101, Jerry Adair, 0, 24, 1970
ageet101, Tommie Agee, 12, 480, 1970
akerj102, Jack Aker, 0, 10, 1970
alcal101, Luis Alcaraz, 1, 107, 1970
alleb105, Bernie Allen, 1, 240, 1970
alled101, Dick Allen, 4, 341, 1970
alleg101, Gene Alley, 6, 356, 1970
</code></pre>

<p>I can load the data into pandas using the following command.</p>

<p>{% codeblock lang:python %}
import pandas as pd</p>

<p>DF = pd.read_csv(‘../processed_data/all_errors_bip.out’,
                 header=None,
                 names=[‘playerid’, ‘player_name’, ‘errors’, ‘bip’, ‘year’])
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
DF.head()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aaroh101</td>
      <td>Hank Aaron</td>
      <td>8</td>
      <td>453</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>1</th>
      <td>aarot101</td>
      <td>Tommie Aaron</td>
      <td>0</td>
      <td>53</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>2</th>
      <td>abert101</td>
      <td>Ted Abernathy</td>
      <td>0</td>
      <td>10</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>3</th>
      <td>adaij101</td>
      <td>Jerry Adair</td>
      <td>0</td>
      <td>24</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ageet101</td>
      <td>Tommie Agee</td>
      <td>12</td>
      <td>480</td>
      <td>1970</td>
    </tr>
  </tbody>
</table>
</div>

<p>{% codeblock lang:python %}
len(DF)
{% endcodeblock %}</p>

<pre><code>38870
</code></pre>

<p>I have almost 39,000 year, player combinations…. a good amount of data to play with.</p>

<p>While exploring the data, I noticed that players hit into errors less frequently now than they used to. Let’s see how the probability that a player hits into an error has changed across the years.</p>

<p>{% codeblock lang:python %}
%matplotlib inline</p>

<p>YEAR_DF = (DF
           .groupby(“year”)
           .agg({
               “errors”: “sum”,
               “bip”: “sum”
           })
           .assign(prop_error=lambda x: x[“errors”] / x[“bip”])
          )</p>

<p>YEAR_DF[“prop_error”].plot(style=”o-“);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/error_year.png" /></p>

<p>Interestingly, the proportion of errors per BIP <a href="https://www.pinstripealley.com/2013/8/16/4623050/mlb-errors-trends-statistics">has been dropping over time</a>. I am not sure if this is a conscious effort by MLB score keepers, a change in how hitters hit, or improved fielding (but I suspect it’s the score keepers). It looks like this drop in errors per BIP leveled off around 2015. Zooming in.</p>

<p>{% codeblock lang:python %}
YEAR_DF[YEAR_DF.index &gt; 2010][“prop_error”].plot(style=”o-“);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/zoom_error_year.png" /></p>

<p>I explore this statistically in <a href="https://github.com/dvatterott/mlb_errors/blob/master/notebook/PYMC%20-%20Hierarchical%20Beta%20Binomial%20YEAR.ipynb">a jupyter notebook on my github</a>.</p>

<p>Because I don’t want year to confound the analysis, I remove all data before 2015.</p>

<p>{% codeblock lang:python %}
DF = DF[DF[“year”] &gt;= 2015]
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
len(DF)
{% endcodeblock %}</p>

<pre><code>3591
</code></pre>

<p>This leaves me with 3500 year, player combinations.</p>

<p>Next I combine players’ data across years.</p>

<p>{% codeblock lang:python %}
GROUPED_DF = DF.groupby([“playerid”, “player_name”]).agg({“errors”: “sum”, “bip”: “sum”}).reset_index()
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
GROUPED_DF.describe()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>errors</th>
      <th>bip</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1552.000000</td>
      <td>1552.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.835052</td>
      <td>324.950387</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.073256</td>
      <td>494.688755</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>7.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>69.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>5.000000</td>
      <td>437.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>37.000000</td>
      <td>2102.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>I want an idea for how likely players are to hit into errors.</p>

<p>{% codeblock lang:python %}
TOTALS = GROUPED_DF.agg({“errors”: “sum”, “bip”: “sum”})
ERROR_RATE = TOTALS[“errors”] / TOTALS[“bip”]
ERROR_RATE
{% endcodeblock %}</p>

<pre><code>0.011801960251664112
</code></pre>

<p>Again, errors are very rare, so I want know how many “trials” (BIP) I need for a reasonable estimate of how likely each player is to hit into an error.</p>

<p>I’d like the majority of players to have at least 5 errors. I can estimate how many BIP that would require.</p>

<p>{% codeblock lang:python %}
5. /ERROR_RATE
{% endcodeblock %}</p>

<pre><code>423.65843413978496
</code></pre>

<p>Looks like I should require at least 425 BIP for each player. I round this to 500.</p>

<p>{% codeblock lang:python %}
GROUPED_DF = GROUPED_DF[GROUPED_DF[“bip”] &gt; 500]
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
GROUPED_DF = GROUPED_DF.reset_index(drop=True)
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
GROUPED_DF.head()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>abrej003</td>
      <td>Jose Abreu</td>
      <td>20</td>
      <td>1864</td>
    </tr>
    <tr>
      <th>1</th>
      <td>adamm002</td>
      <td>Matt Adams</td>
      <td>6</td>
      <td>834</td>
    </tr>
    <tr>
      <th>2</th>
      <td>adrie001</td>
      <td>Ehire Adrianza</td>
      <td>2</td>
      <td>533</td>
    </tr>
    <tr>
      <th>3</th>
      <td>aguij001</td>
      <td>Jesus Aguilar</td>
      <td>2</td>
      <td>551</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ahmen001</td>
      <td>Nick Ahmed</td>
      <td>12</td>
      <td>1101</td>
    </tr>
  </tbody>
</table>
</div>

<p>{% codeblock lang:python %}
GROUPED_DF.describe()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>errors</th>
      <th>bip</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>354.000000</td>
      <td>354.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>12.991525</td>
      <td>1129.059322</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.447648</td>
      <td>428.485467</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>503.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>8.000000</td>
      <td>747.250000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>12.000000</td>
      <td>1112.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>17.000000</td>
      <td>1475.750000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>37.000000</td>
      <td>2102.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>I’ve identified 354 players who have enough BIP for me to estimate how frequently they hit into errors.</p>

<p>Below, I plot how the likelihood of hitting into errors is distributed.</p>

<p>{% codeblock lang:python %}
%matplotlib inline</p>

<p>GROUPED_DF[“prop_error”] = GROUPED_DF[“errors”] / GROUPED_DF[“bip”]
GROUPED_DF[“prop_error”].hist();
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/error_dist.png" /></p>

<p>The question is whether someone who has hit into errors in 2% of their BIP is more likely to hit into an error than someone who has hit into errors in 0.5% of their BIP (or is this all just random variation).</p>

<p>To try and estimate this, I treat each BIP as a Bernoulli trial. Hitting into an error is a “success”. I use a Binomial distribution to model the number of “successes”. I would like to know if different players are more or less likely to hit into errors. To do this, I model each player as having their own Binomial distribution and ask whether <em>p</em> (the probability of success) differs across players.</p>

<p>To answer this question, I could use a <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html#scipy.stats.chi2_contingency">chi square contingency test</a> but this would only tell me whether players differ at all and not which players differ.</p>

<p>The traditional way to identify which players differ is to do pairwise comparisons, but this would result in TONS of comparisons making <a href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem">false positives all but certain</a>.</p>

<p>Another option is to harness Bayesian statistics and build a <a href="http://sl8r000.github.io/ab_testing_statistics/use_a_hierarchical_model/">Hierarchical Beta-Binomial model</a>. The intuition is that each player’s probability of hitting into an error is drawn from a <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a>. I want to know whether these Beta distributions are different. I then assume I can best estimate a player’s Beta distribution by using that particular player’s data AND data from all players together.</p>

<p>The model is built so that as I accrue data about a particular player, I will trust that data more and more, relying less and less on data from all players. This is called partial pooling. <a href="https://dsaber.com/2016/08/27/analyze-your-experiment-with-a-multilevel-logistic-regression-using-pymc3%E2%80%8B/">Here’s</a> a useful explanation.</p>

<p>I largely based my analysis on <a href="https://docs.pymc.io/notebooks/hierarchical_partial_pooling.html">this</a> tutorial. Reference the tutorial for an explanation of how I choose my priors. I ended up using a greater lambda value (because the model sampled better) in the Exponential prior, and while this did lead to more extreme estimates of error likelihood, it didn’t change the basic story.</p>

<p>{% codeblock lang:python %}
import pymc3 as pm
import numpy as np
import theano.tensor as tt</p>

<p>with pm.Model() as model:</p>

<pre><code>phi = pm.Uniform('phi', lower=0.0, upper=1.0)

kappa_log = pm.Exponential('kappa_log', lam=25.)
kappa = pm.Deterministic('kappa', tt.exp(kappa_log))

rates = pm.Beta('rates', alpha=phi*kappa, beta=(1.0-phi)*kappa, shape=len(GROUPED_DF))

trials = np.array(GROUPED_DF["bip"])
successes = np.array(GROUPED_DF["errors"])
 
obs = pm.Binomial('observed_values', trials, rates, observed=successes)
trace = pm.sample(2000, tune=1000, chains=2, cores=2, nuts_kwargs={'target_accept': .95}) {% endcodeblock %}

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [rates, kappa_log, phi]
Sampling 2 chains: 100%|██████████| 6000/6000 [01:47&lt;00:00, 28.06draws/s] 
</code></pre>

<p>Check whether the model converged.</p>

<p>{% codeblock lang:python %}
max(np.max(score) for score in pm.gelman_rubin(trace).values())
{% endcodeblock %}</p>

<pre><code>1.0022635936332533
</code></pre>

<p>{% codeblock lang:python %}
bfmi = pm.bfmi(trace)
max_gr = max(np.max(gr_stats) for gr_stats in pm.gelman_rubin(trace).values())
(pm.energyplot(trace, figsize=(6, 4)).set_title(“BFMI = {}\nGelman-Rubin = {}”.format(bfmi, max_gr)));
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/energy.png" /></p>

<p>The most challenging parameter to fit is <em>kappa</em> which modulates for the variance in the likelihood to hit into an error. I take a look at it to make sure things look as expected.</p>

<p>{% codeblock lang:python %}
pm.summary(trace, varnames=[“kappa”])
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>mc_error</th>
      <th>hpd_2.5</th>
      <th>hpd_97.5</th>
      <th>n_eff</th>
      <th>Rhat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kappa</th>
      <td>927.587178</td>
      <td>141.027597</td>
      <td>4.373954</td>
      <td>657.066554</td>
      <td>1201.922608</td>
      <td>980.288914</td>
      <td>1.000013</td>
    </tr>
  </tbody>
</table>
</div>

<p>{% codeblock lang:python %}
pm.traceplot(trace, varnames=[‘kappa’]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/kappa.png" /></p>

<p>I can also look at <em>phi</em>, the estimated global likelihood to hit into an error.</p>

<p>{% codeblock lang:python %}
pm.traceplot(trace, varnames=[‘phi’]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/phi.png" /></p>

<p>Finally, I can look at how all players vary in their likelihood to hit into an error.</p>

<p>{% codeblock lang:python %}
pm.traceplot(trace, varnames=[‘rates’]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/rate_trace.png" /></p>

<p>Obviously, the above plot is a lot to look at it, so let’s order players by how likely the model believes they are to hit in an error.</p>

<p>{% codeblock lang:python %}
from matplotlib import pyplot as plt</p>

<p>rate_means = trace[‘rates’, 1000:].mean(axis=0)
rate_se = trace[‘rates’, 1000:].std(axis=0)</p>

<p>mean_se = [(x, y, i) for i, x, y in zip(GROUPED_DF.index, rate_means, rate_se)]
sorted_means_se = sorted(mean_se, key=lambda x: x[0])
sorted_means = [x[0] for x in sorted_means_se]
sorted_se = [x[1] for x in sorted_means_se]</p>

<p>x = np.arange(len(sorted_means))</p>

<p>plt.plot(x, sorted_means, ‘o’, alpha=0.25);</p>

<p>for x_val, m, se in zip(x, sorted_means, sorted_se):
    plt.plot([x_val, x_val], [m-se, m+se], ‘b-‘, alpha=0.5)
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/players_ranked.png" /></p>

<p>Now, the ten players who are most likely to hit into an error.</p>

<p>{% codeblock lang:python %}
estimated_mean = pm.summary(trace, varnames=[“rates”]).iloc[[x[2] for x in sorted_means_se[-10:]]][“mean”]</p>

<p>GROUPED_DF.loc[[x[2] for x in sorted_means_se[-10:]], :].assign(estimated_mean=estimated_mean.values).iloc[::-1]
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
      <th>prop_error</th>
      <th>estimated_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>71</th>
      <td>corrc001</td>
      <td>Carlos Correa</td>
      <td>30</td>
      <td>1368</td>
      <td>0.021930</td>
      <td>0.017838</td>
    </tr>
    <tr>
      <th>227</th>
      <td>myerw001</td>
      <td>Wil Myers</td>
      <td>27</td>
      <td>1214</td>
      <td>0.022241</td>
      <td>0.017724</td>
    </tr>
    <tr>
      <th>15</th>
      <td>andre001</td>
      <td>Elvis Andrus</td>
      <td>37</td>
      <td>1825</td>
      <td>0.020274</td>
      <td>0.017420</td>
    </tr>
    <tr>
      <th>258</th>
      <td>plawk001</td>
      <td>Kevin Plawecki</td>
      <td>14</td>
      <td>528</td>
      <td>0.026515</td>
      <td>0.017200</td>
    </tr>
    <tr>
      <th>285</th>
      <td>rojam002</td>
      <td>Miguel Rojas</td>
      <td>21</td>
      <td>952</td>
      <td>0.022059</td>
      <td>0.017001</td>
    </tr>
    <tr>
      <th>118</th>
      <td>garca003</td>
      <td>Avisail Garcia</td>
      <td>28</td>
      <td>1371</td>
      <td>0.020423</td>
      <td>0.016920</td>
    </tr>
    <tr>
      <th>244</th>
      <td>pench001</td>
      <td>Hunter Pence</td>
      <td>22</td>
      <td>1026</td>
      <td>0.021442</td>
      <td>0.016875</td>
    </tr>
    <tr>
      <th>20</th>
      <td>baezj001</td>
      <td>Javier Baez</td>
      <td>23</td>
      <td>1129</td>
      <td>0.020372</td>
      <td>0.016443</td>
    </tr>
    <tr>
      <th>335</th>
      <td>turnt001</td>
      <td>Trea Turner</td>
      <td>23</td>
      <td>1140</td>
      <td>0.020175</td>
      <td>0.016372</td>
    </tr>
    <tr>
      <th>50</th>
      <td>cainl001</td>
      <td>Lorenzo Cain</td>
      <td>32</td>
      <td>1695</td>
      <td>0.018879</td>
      <td>0.016332</td>
    </tr>
  </tbody>
</table>
</div>

<p>And the 10 players who are least likely to hit in an error.</p>

<p>{% codeblock lang:python %}
estimated_mean = pm.summary(trace, varnames=[“rates”]).iloc[[x[2] for x in sorted_means_se[:10]]][“mean”]</p>

<p>GROUPED_DF.loc[[x[2] for x in sorted_means_se[:10]], :].assign(estimated_mean=estimated_mean.values)
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
      <th>prop_error</th>
      <th>estimated_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>226</th>
      <td>murpd006</td>
      <td>Daniel Murphy</td>
      <td>4</td>
      <td>1680</td>
      <td>0.002381</td>
      <td>0.005670</td>
    </tr>
    <tr>
      <th>223</th>
      <td>morrl001</td>
      <td>Logan Morrison</td>
      <td>4</td>
      <td>1241</td>
      <td>0.003223</td>
      <td>0.006832</td>
    </tr>
    <tr>
      <th>343</th>
      <td>vottj001</td>
      <td>Joey Votto</td>
      <td>8</td>
      <td>1724</td>
      <td>0.004640</td>
      <td>0.007112</td>
    </tr>
    <tr>
      <th>239</th>
      <td>panij002</td>
      <td>Joe Panik</td>
      <td>7</td>
      <td>1542</td>
      <td>0.004540</td>
      <td>0.007245</td>
    </tr>
    <tr>
      <th>51</th>
      <td>calhk001</td>
      <td>Kole Calhoun</td>
      <td>9</td>
      <td>1735</td>
      <td>0.005187</td>
      <td>0.007413</td>
    </tr>
    <tr>
      <th>55</th>
      <td>carpm002</td>
      <td>Matt Carpenter</td>
      <td>8</td>
      <td>1566</td>
      <td>0.005109</td>
      <td>0.007534</td>
    </tr>
    <tr>
      <th>142</th>
      <td>hamib001</td>
      <td>Billy Hamilton</td>
      <td>8</td>
      <td>1476</td>
      <td>0.005420</td>
      <td>0.007822</td>
    </tr>
    <tr>
      <th>289</th>
      <td>rosae001</td>
      <td>Eddie Rosario</td>
      <td>8</td>
      <td>1470</td>
      <td>0.005442</td>
      <td>0.007855</td>
    </tr>
    <tr>
      <th>275</th>
      <td>renda001</td>
      <td>Anthony Rendon</td>
      <td>9</td>
      <td>1564</td>
      <td>0.005754</td>
      <td>0.007966</td>
    </tr>
    <tr>
      <th>8</th>
      <td>alony001</td>
      <td>Yonder Alonso</td>
      <td>8</td>
      <td>1440</td>
      <td>0.005556</td>
      <td>0.008011</td>
    </tr>
  </tbody>
</table>
</div>

<p>It looks to me like players who hit more ground balls are more likely to hit into an error than players who predominately hits fly balls and line-drives. This makes sense since infielders make more errors than outfielders.</p>

<p>Using the posterior distribution of estimated likelihoods to hit into an error, I can assign a probability to whether Carlos Correa is more likely to hit into an error than Daniel Murphy.</p>

<p>{% codeblock lang:python %}
np.mean(trace[‘rates’, 1000:][:, 71] &lt;= trace[‘rates’, 1000:][:, 226])
{% endcodeblock %}</p>

<pre><code>0.0
</code></pre>

<p>The model believes Correa is much more likely to hit into an error than Murphy!</p>

<p>I can also plot these players’ posterior distributions.</p>

<p>{% codeblock lang:python %}
import seaborn as sns</p>

<p>sns.kdeplot(trace[‘rates’, 1000:][:, 226], shade=True, label=”Daniel Murphy”);
sns.kdeplot(trace[‘rates’, 1000:][:, 71], shade=True, label=”Carlos Correa”);
sns.kdeplot(trace[‘rates’, 1000:].flatten(), shade=True, label=”Overall”);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/play_comparison.png" /></p>

<p>Finally, I can look exclusively at how the posterior distributions of the ten most likely and 10 least likely players to hit into an error compare.</p>

<p>{% codeblock lang:python %}
sns.kdeplot(trace[‘rates’, 1000:][:, [x[2] for x in sorted_means_se[-10:]]].flatten(), shade=True, label=”10 Least Likely”);
sns.kdeplot(trace[‘rates’, 1000:][:, [x[2] for x in sorted_means_se[:10]]].flatten(), shade=True, label=”10 Most Likely”);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/top10.png" /></p>

<p>All in all, this analysis makes it obvious that some players are more likely to hit into errors than other players. This is probably driven by how often players hit ground balls.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Regression of a Proportion in Python]]></title>
    <link href="https://danvatterott.com/blog/2018/05/03/regression-of-a-proportion-in-python/"/>
    <updated>2018-05-03T21:20:09-05:00</updated>
    <id>https://danvatterott.com/blog/2018/05/03/regression-of-a-proportion-in-python</id>
    <content type="html"><![CDATA[<p>I frequently predict proportions (e.g., proportion of year during which a customer is active). This is a regression task because the dependent variables is a float, but the dependent variable is bound between the 0 and 1. Googling around, I had a hard time finding the a good way to model this situation, so I’ve written here what I think is the most straight forward solution.</p>

<p>I am guessing there’s a better way to do this with MCMC, so please comment below if you know a better way.</p>

<p>Let’s get started by importing some libraries for making random data.</p>

<p>{% codeblock lang:python %}
from sklearn.datasets import make_regression
import numpy as np
{% endcodeblock %}</p>

<p>Create random regression data.</p>

<p>{% codeblock lang:python %}
rng = np.random.RandomState(0)  # fix random state
X, y, coef = make_regression(n_samples=10000,
                             n_features=100,
                             n_informative=40,
                             effective_rank= 15,
                             random_state=0,
                             noise=4.0,
                             bias=100.0,
                             coef=True)
{% endcodeblock %}</p>

<p>Shrink down the dependent variable so it’s bound between 0 and 1.</p>

<p>{% codeblock lang:python %}
y_min = min(y)
y = [i-y_min for i in y]  # min value will be 0
y_max = max(y)
y = [i/y_max for i in y]  # max value will be 1
{% endcodeblock %}</p>

<p>Make a quick plot to confirm that the data is bound between 0 and 1.</p>

<p>{% codeblock lang:python %}
from matplotlib import pyplot as plt
import seaborn as sns
%matplotlib inline</p>

<p>sns.set_style(‘whitegrid’)</p>

<p>plt.hist(y);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/prop_regression/hist.png" /></p>

<p>All the data here is fake which worries me, but beggars can’t be choosers and this is just a quick example.</p>

<p>Below, I apply a plain GLM to the data. This is what you would expect if you treated this as a plain regression problem</p>

<p>{% codeblock lang:python %}
import statsmodels.api as sm</p>

<p>linear_glm = sm.GLM(y, X)
linear_result = linear_glm.fit()
# print(linear_result.summary2())  # too much output for a blog post
{% endcodeblock %}</p>

<p>Here’s the actual values plotted (x-axis) against the predicted values (y-axis). The model does a decent job, but check out the values on the y-axis - the linear model predicts negative values!</p>

<p>{% codeblock lang:python %}
plt.plot(y, linear_result.predict(X), ‘o’, alpha=0.2);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/prop_regression/linear.png" /></p>

<p>Obviously the linear model above isn’t correctly modeling this data since it’s guessing values that are impossible.</p>

<p>I followed <a href="https://stats.idre.ucla.edu/stata/faq/how-does-one-do-regression-when-the-dependent-variable-is-a-proportion/">this tutorial</a> which recommends using a GLM with a logit link and the binomial family. Checking out the <a href="http://www.statsmodels.org/stable/generated/statsmodels.genmod.families.family.Binomial.html#statsmodels.genmod.families.family.Binomial">statsmodels module reference</a>, we can see the default link for the binomial family is logit.</p>

<p>Below I apply a GLM with a logit link and the binomial family to the data.</p>

<p>{% codeblock lang:python %}
binom_glm = sm.GLM(y, X, family=sm.families.Binomial())
binom_results = binom_glm.fit()
#print(binom_results.summary2())  # too much output for a blog post
{% endcodeblock %}</p>

<p>Here’s the actual data (x-axis) plotted against teh predicted data. You can see the fit is much better!</p>

<p>{% codeblock lang:python %}
plt.plot(y, binom_results.predict(X), ‘o’, alpha=0.2);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/prop_regression/binomial.png" /></p>

<p>{% codeblock lang:python %}
%load_ext watermark
%watermark -v -m -p numpy,matplotlib,sklearn,seaborn,statsmodels
{% endcodeblock %}</p>

<pre><code>CPython 3.6.3
IPython 6.1.0

numpy 1.13.3
matplotlib 2.0.2
sklearn 0.19.1
seaborn 0.8.0
statsmodels 0.8.0

compiler   : GCC 7.2.0
system     : Linux
release    : 4.13.0-38-generic
machine    : x86_64
processor  : x86_64
CPU cores  : 4
interpreter: 64bit
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Repeated Measures ANOVA in Python (Kinda)]]></title>
    <link href="https://danvatterott.com/blog/2016/02/28/repeated-measures-anova-in-python-kinda/"/>
    <updated>2016-02-28T20:52:03-06:00</updated>
    <id>https://danvatterott.com/blog/2016/02/28/repeated-measures-anova-in-python-kinda</id>
    <content type="html"><![CDATA[<p><em>If you’re just finding this post, please check out Erik Marsja’s <a href="https://www.marsja.se/repeated-measures-anova-in-python-using-statsmodels/">post</a> describing the same functionality in well-maintained python software that wasn’t available when I originally wrote this post.</em></p>

<p>I love doing data analyses with pandas, numpy, sci-py etc., but I often need to run <a href="https://en.wikipedia.org/wiki/Repeated_measures_design">repeated measures ANOVAs</a>, which are not implemented in any major python libraries. <a href="http://pythonpsychologist.tumblr.com/post/139246503057/repeated-measures-anova-using-python">Python Psychologist</a> shows how to do repeated measures ANOVAs yourself in python, but I find using a widley distributed implementation comforting…</p>

<p>In this post I show how to execute a repeated measures ANOVAs using the <a href="http://rpy2.bitbucket.org/">rpy2</a> library, which allows us to move data between python and R, and execute R commands from python. I use rpy2 to load the <a href="http://www.inside-r.org/packages/cran/car/docs/Anova">car</a> library and run the ANOVA.</p>

<p>I will show how to run a one-way repeated measures ANOVA and a two-way repeated measures ANOVA.</p>

<p>{% codeblock lang:python %}
#first import the libraries I always use.
import numpy as np, scipy.stats, pandas as pd</p>

<p>import matplotlib as mpl
import matplotlib.pyplot as plt
import pylab as pl
%matplotlib inline
pd.options.display.mpl_style = ‘default’
plt.style.use(‘ggplot’)
mpl.rcParams[‘font.family’] = [‘Bitstream Vera Sans’]</p>

<p>{% endcodeblock %}</p>

<p>Below I use the random library to generate some fake data. I seed the random number generator with a one so that this analysis can be replicated.</p>

<p>I will generated 3 conditions which represent 3 levels of a single variable.</p>

<p>The data are generated from a gaussian distribution. The second condition has a higher mean than the other two conditions.</p>

<p>{% codeblock lang:python %}
import random</p>

<p>random.seed(1) #seed random number generator
cond_1 = [random.gauss(600,30) for x in range(30)] #condition 1 has a mean of 600 and standard deviation of 30
cond_2 = [random.gauss(650,30) for x in range(30)] #u=650 and sd=30
cond_3 = [random.gauss(600,30) for x in range(30)] #u=600 and sd=30</p>

<p>plt.bar(np.arange(1,4),[np.mean(cond_1),np.mean(cond_2),np.mean(cond_3)],align=’center’) #plot data
plt.xticks([1,2,3]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/rmANOVA_1.png" /></p>

<p>Next, I load rpy2 for ipython. I am doing these analyses with ipython in a <a href="http://jupyter.org/">jupyter notebook</a> (highly recommended).</p>

<p>{% codeblock lang:python %}
%load_ext rpy2.ipython
{% endcodeblock %}</p>

<p>Here’s how to run the ANOVA. Note that this is a one-way anova with 3 levels of the factor.</p>

<p>{% codeblock lang:python %}
#pop the data into R
%Rpush cond_1 cond_2 cond_3</p>

<h1 id="label-the-conditions">label the conditions</h1>
<p>%R Factor &lt;- c(‘Cond1’,’Cond2’,’Cond3’)
#create a vector of conditions
%R idata &lt;- data.frame(Factor)</p>

<h1 id="combine-data-into-single-matrix">combine data into single matrix</h1>
<p>%R Bind &lt;- cbind(cond_1,cond_2,cond_3)
#generate linear model
%R model &lt;- lm(Bind~1)</p>

<h1 id="load-the-car-library-note-this-library-must-be-installed">load the car library. note this library must be installed.</h1>
<p>%R library(car)
#run anova
%R analysis &lt;- Anova(model,idata=idata,idesign=~Factor,type=”III”)
#create anova summary table
%R anova_sum = summary(analysis)</p>

<h1 id="move-the-data-from-r-to-python">move the data from R to python</h1>
<p>%Rpull anova_sum
print anova_sum
{% endcodeblock %}</p>

<pre><code>Type III Repeated Measures MANOVA Tests:

------------------------------------------

Term: (Intercept)

 Response transformation matrix:
       (Intercept)
cond_1           1
cond_2           1
cond_3           1

Sum of squares and products for the hypothesis:
            (Intercept)
(Intercept)   102473990

Sum of squares and products for error:
            (Intercept)
(Intercept)     78712.7

Multivariate Tests: (Intercept)
                 Df test stat approx F num Df den Df     Pr(&gt;F)    
Pillai            1    0.9992 37754.33      1     29 &lt; 2.22e-16 ***
Wilks             1    0.0008 37754.33      1     29 &lt; 2.22e-16 ***
Hotelling-Lawley  1 1301.8736 37754.33      1     29 &lt; 2.22e-16 ***
Roy               1 1301.8736 37754.33      1     29 &lt; 2.22e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

------------------------------------------

Term: Factor

 Response transformation matrix:
       Factor1 Factor2
cond_1       1       0
cond_2       0       1
cond_3      -1      -1

Sum of squares and products for the hypothesis:
          Factor1   Factor2
Factor1  3679.584  19750.87
Factor2 19750.870 106016.58

Sum of squares and products for error:
         Factor1  Factor2
Factor1 40463.19 27139.59
Factor2 27139.59 51733.12

Multivariate Tests: Factor
                 Df test stat approx F num Df den Df    Pr(&gt;F)    
Pillai            1 0.7152596 35.16759      2     28 2.303e-08 ***
Wilks             1 0.2847404 35.16759      2     28 2.303e-08 ***
Hotelling-Lawley  1 2.5119704 35.16759      2     28 2.303e-08 ***
Roy               1 2.5119704 35.16759      2     28 2.303e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Univariate Type III Repeated-Measures ANOVA Assuming Sphericity

                  SS num Df Error SS den Df         F    Pr(&gt;F)    
(Intercept) 34157997      1    26238     29 37754.334 &lt; 2.2e-16 ***
Factor         59964      2    43371     58    40.094 1.163e-11 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


Mauchly Tests for Sphericity

       Test statistic p-value
Factor        0.96168 0.57866


Greenhouse-Geisser and Huynh-Feldt Corrections
 for Departure from Sphericity

        GG eps Pr(&gt;F[GG])    
Factor 0.96309  2.595e-11 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

        HF eps   Pr(&gt;F[HF])
Factor 1.03025 1.163294e-11
</code></pre>

<p>The ANOVA table isn’t pretty, but it works. As you can see, the ANOVA was wildly significant.</p>

<p>Next, I generate data for a two-way (2x3) repeated measures ANOVA. Condition A is the same data as above. Condition B has a different pattern (2 is lower than 1 and 3), which should produce an interaction.</p>

<p>{% codeblock lang:python %}
random.seed(1)</p>

<p>cond_1a = [random.gauss(600,30) for x in range(30)] #u=600,sd=30
cond_2a = [random.gauss(650,30) for x in range(30)] #u=650,sd=30
cond_3a = [random.gauss(600,30) for x in range(30)] #u=600,sd=30</p>

<p>cond_1b = [random.gauss(600,30) for x in range(30)] #u=600,sd=30
cond_2b = [random.gauss(550,30) for x in range(30)] #u=550,sd=30
cond_3b = [random.gauss(650,30) for x in range(30)] #u=650,sd=30</p>

<p>width = 0.25
plt.bar(np.arange(1,4)-width,[np.mean(cond_1a),np.mean(cond_2a),np.mean(cond_3a)],width)
plt.bar(np.arange(1,4),[np.mean(cond_1b),np.mean(cond_2b),np.mean(cond_3b)],width,color=plt.rcParams[‘axes.color_cycle’][0])
plt.legend([‘A’,’B’],loc=4)
plt.xticks([1,2,3]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/rmANOVA_2.png" /></p>

<p>{% codeblock lang:python %}
%Rpush cond_1a cond_1b cond_2a cond_2b cond_3a cond_3b</p>

<p>%R Factor1 &lt;- c(‘A’,’A’,’A’,’B’,’B’,’B’)
%R Factor2 &lt;- c(‘Cond1’,’Cond2’,’Cond3’,’Cond1’,’Cond2’,’Cond3’)
%R idata &lt;- data.frame(Factor1, Factor2)</p>

<h1 id="make-sure-the-vectors-appear-in-the-same-order-as-they-appear-in-the-dataframe">make sure the vectors appear in the same order as they appear in the dataframe</h1>
<p>%R Bind &lt;- cbind(cond_1a, cond_2a, cond_3a, cond_1b, cond_2b, cond_3b)
%R model &lt;- lm(Bind~1)</p>

<p>%R library(car)
%R analysis &lt;- Anova(model, idata=idata, idesign=~Factor1*Factor2, type=”III”)
%R anova_sum = summary(analysis)
%Rpull anova_sum</p>

<p>print anova_sum
{% endcodeblock %}</p>

<pre><code>Type III Repeated Measures MANOVA Tests:

------------------------------------------

Term: (Intercept)

 Response transformation matrix:
        (Intercept)
cond_1a           1
cond_2a           1
cond_3a           1
cond_1b           1
cond_2b           1
cond_3b           1

Sum of squares and products for the hypothesis:
            (Intercept)
(Intercept)   401981075

Sum of squares and products for error:
            (Intercept)
(Intercept)    185650.5

Multivariate Tests: (Intercept)
                 Df test stat approx F num Df den Df     Pr(&gt;F)    
Pillai            1    0.9995 62792.47      1     29 &lt; 2.22e-16 ***
Wilks             1    0.0005 62792.47      1     29 &lt; 2.22e-16 ***
Hotelling-Lawley  1 2165.2575 62792.47      1     29 &lt; 2.22e-16 ***
Roy               1 2165.2575 62792.47      1     29 &lt; 2.22e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

------------------------------------------

Term: Factor1

 Response transformation matrix:
        Factor11
cond_1a        1
cond_2a        1
cond_3a        1
cond_1b       -1
cond_2b       -1
cond_3b       -1

Sum of squares and products for the hypothesis:
         Factor11
Factor11 38581.51

Sum of squares and products for error:
         Factor11
Factor11 142762.3

Multivariate Tests: Factor1
                 Df test stat approx F num Df den Df    Pr(&gt;F)   
Pillai            1 0.2127533 7.837247      1     29 0.0090091 **
Wilks             1 0.7872467 7.837247      1     29 0.0090091 **
Hotelling-Lawley  1 0.2702499 7.837247      1     29 0.0090091 **
Roy               1 0.2702499 7.837247      1     29 0.0090091 **
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

------------------------------------------

Term: Factor2

 Response transformation matrix:
        Factor21 Factor22
cond_1a        1        0
cond_2a        0        1
cond_3a       -1       -1
cond_1b        1        0
cond_2b        0        1
cond_3b       -1       -1

Sum of squares and products for the hypothesis:
         Factor21 Factor22
Factor21 91480.01 77568.78
Factor22 77568.78 65773.02

Sum of squares and products for error:
         Factor21 Factor22
Factor21 90374.60 56539.06
Factor22 56539.06 87589.85

Multivariate Tests: Factor2
                 Df test stat approx F num Df den Df    Pr(&gt;F)    
Pillai            1 0.5235423 15.38351      2     28 3.107e-05 ***
Wilks             1 0.4764577 15.38351      2     28 3.107e-05 ***
Hotelling-Lawley  1 1.0988223 15.38351      2     28 3.107e-05 ***
Roy               1 1.0988223 15.38351      2     28 3.107e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

------------------------------------------

Term: Factor1:Factor2

 Response transformation matrix:
        Factor11:Factor21 Factor11:Factor22
cond_1a                 1                 0
cond_2a                 0                 1
cond_3a                -1                -1
cond_1b                -1                 0
cond_2b                 0                -1
cond_3b                 1                 1

Sum of squares and products for the hypothesis:
                  Factor11:Factor21 Factor11:Factor22
Factor11:Factor21          179585.9            384647
Factor11:Factor22          384647.0            823858

Sum of squares and products for error:
                  Factor11:Factor21 Factor11:Factor22
Factor11:Factor21          92445.33          45639.49
Factor11:Factor22          45639.49          89940.37

Multivariate Tests: Factor1:Factor2
                 Df test stat approx F num Df den Df     Pr(&gt;F)    
Pillai            1  0.901764 128.5145      2     28 7.7941e-15 ***
Wilks             1  0.098236 128.5145      2     28 7.7941e-15 ***
Hotelling-Lawley  1  9.179605 128.5145      2     28 7.7941e-15 ***
Roy               1  9.179605 128.5145      2     28 7.7941e-15 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Univariate Type III Repeated-Measures ANOVA Assuming Sphericity

                      SS num Df Error SS den Df          F    Pr(&gt;F)    
(Intercept)     66996846      1    30942     29 62792.4662 &lt; 2.2e-16 ***
Factor1             6430      1    23794     29     7.8372  0.009009 **
Factor2            26561      2    40475     58    19.0310  4.42e-07 ***
Factor1:Factor2   206266      2    45582     58   131.2293 &lt; 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1


Mauchly Tests for Sphericity

                Test statistic p-value
Factor2                0.96023 0.56654
Factor1:Factor2        0.99975 0.99648


Greenhouse-Geisser and Huynh-Feldt Corrections
 for Departure from Sphericity

                 GG eps Pr(&gt;F[GG])    
Factor2         0.96175  6.876e-07 ***
Factor1:Factor2 0.99975  &lt; 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

                  HF eps   Pr(&gt;F[HF])
Factor2         1.028657 4.420005e-07
Factor1:Factor2 1.073774 2.965002e-22
</code></pre>

<p>Again, the anova table isn’t too pretty.</p>

<p>This obviously isn’t the most exciting post in the world, but its a nice bit of code to have in your back pocket if you’re doing experimental analyses in python.</p>
]]></content>
  </entry>
  
</feed>
