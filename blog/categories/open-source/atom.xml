<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Open Source | Dan Vatterott]]></title>
  <link href="https://danvatterott.com/blog/categories/open-source/atom.xml" rel="self"/>
  <link href="https://danvatterott.com/"/>
  <updated>2022-02-25T14:33:11-06:00</updated>
  <id>https://danvatterott.com/</id>
  <author>
    <name><![CDATA[Dan Vatterott]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Are Some MLB Players More Likely to Hit Into Errors: Statistics]]></title>
    <link href="https://danvatterott.com/blog/2019/06/04/are-some-mlb-players-more-likely-to-hit-into-errors-statistics/"/>
    <updated>2019-06-04T20:04:31-05:00</updated>
    <id>https://danvatterott.com/blog/2019/06/04/are-some-mlb-players-more-likely-to-hit-into-errors-statistics</id>
    <content type="html"><![CDATA[<p>In a <a href="https://danvatterott.com/blog/2019/04/19/are-some-mlb-players-more-likely-to-hit-into-errors-munging/">previous post</a>, I described how to download and clean data for understanding how likely a baseball player is to hit into an error given that they hit the ball into play.</p>

<p>This analysis will statistically demonstrate that some players are more likely to hit into errors than others.</p>

<p>Errors are uncommon, so players hit into errors very infrequently. Estimating the likelihood of an infrequent event is hard and requires lots of data. To acquire as much data as possible, I wrote a bash script that will download data for all players between 1970 and 2018.</p>

<p>This data enables me to use data from multiple years for each player, giving me more data when estimating how likely a particular player is to hit into an error.</p>

<p>{% codeblock lang:bash %}
%%bash</p>

<p>for i in {1970..2018}; do
    echo “YEAR: $i”
    ../scripts/get_data.sh ${i};
done</p>

<p>find processed_data/* -type f -name ‘errors_bip.out’ | \
    xargs awk ‘{print $0”, “FILENAME}’ | \
    sed s1processed_data/11g1 | \
    sed s1/errors_bip.out11g1 &gt; \
        processed_data/all_errors_bip.out
{% endcodeblock %}</p>

<p>The data has 5 columns: playerid, playername, errors hit into, balls hit into play (BIP), and year. The file does not have a header.</p>

<p>{% codeblock lang:bash %}
%%bash
head ../processed_data/all_errors_bip.out
{% endcodeblock %}</p>

<pre><code>aaroh101, Hank Aaron, 8, 453, 1970
aarot101, Tommie Aaron, 0, 53, 1970
abert101, Ted Abernathy, 0, 10, 1970
adaij101, Jerry Adair, 0, 24, 1970
ageet101, Tommie Agee, 12, 480, 1970
akerj102, Jack Aker, 0, 10, 1970
alcal101, Luis Alcaraz, 1, 107, 1970
alleb105, Bernie Allen, 1, 240, 1970
alled101, Dick Allen, 4, 341, 1970
alleg101, Gene Alley, 6, 356, 1970
</code></pre>

<p>I can load the data into pandas using the following command.</p>

<p>{% codeblock lang:python %}
import pandas as pd</p>

<p>DF = pd.read_csv(‘../processed_data/all_errors_bip.out’,
                 header=None,
                 names=[‘playerid’, ‘player_name’, ‘errors’, ‘bip’, ‘year’])
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
DF.head()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aaroh101</td>
      <td>Hank Aaron</td>
      <td>8</td>
      <td>453</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>1</th>
      <td>aarot101</td>
      <td>Tommie Aaron</td>
      <td>0</td>
      <td>53</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>2</th>
      <td>abert101</td>
      <td>Ted Abernathy</td>
      <td>0</td>
      <td>10</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>3</th>
      <td>adaij101</td>
      <td>Jerry Adair</td>
      <td>0</td>
      <td>24</td>
      <td>1970</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ageet101</td>
      <td>Tommie Agee</td>
      <td>12</td>
      <td>480</td>
      <td>1970</td>
    </tr>
  </tbody>
</table>
</div>

<p>{% codeblock lang:python %}
len(DF)
{% endcodeblock %}</p>

<pre><code>38870
</code></pre>

<p>I have almost 39,000 year, player combinations…. a good amount of data to play with.</p>

<p>While exploring the data, I noticed that players hit into errors less frequently now than they used to. Let’s see how the probability that a player hits into an error has changed across the years.</p>

<p>{% codeblock lang:python %}
%matplotlib inline</p>

<p>YEAR_DF = (DF
           .groupby(“year”)
           .agg({
               “errors”: “sum”,
               “bip”: “sum”
           })
           .assign(prop_error=lambda x: x[“errors”] / x[“bip”])
          )</p>

<p>YEAR_DF[“prop_error”].plot(style=”o-“);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/error_year.png" /></p>

<p>Interestingly, the proportion of errors per BIP <a href="https://www.pinstripealley.com/2013/8/16/4623050/mlb-errors-trends-statistics">has been dropping over time</a>. I am not sure if this is a conscious effort by MLB score keepers, a change in how hitters hit, or improved fielding (but I suspect it’s the score keepers). It looks like this drop in errors per BIP leveled off around 2015. Zooming in.</p>

<p>{% codeblock lang:python %}
YEAR_DF[YEAR_DF.index &gt; 2010][“prop_error”].plot(style=”o-“);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/zoom_error_year.png" /></p>

<p>I explore this statistically in <a href="https://github.com/dvatterott/mlb_errors/blob/master/notebook/PYMC%20-%20Hierarchical%20Beta%20Binomial%20YEAR.ipynb">a jupyter notebook on my github</a>.</p>

<p>Because I don’t want year to confound the analysis, I remove all data before 2015.</p>

<p>{% codeblock lang:python %}
DF = DF[DF[“year”] &gt;= 2015]
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
len(DF)
{% endcodeblock %}</p>

<pre><code>3591
</code></pre>

<p>This leaves me with 3500 year, player combinations.</p>

<p>Next I combine players’ data across years.</p>

<p>{% codeblock lang:python %}
GROUPED_DF = DF.groupby([“playerid”, “player_name”]).agg({“errors”: “sum”, “bip”: “sum”}).reset_index()
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
GROUPED_DF.describe()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>errors</th>
      <th>bip</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1552.000000</td>
      <td>1552.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.835052</td>
      <td>324.950387</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.073256</td>
      <td>494.688755</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>7.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>69.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>5.000000</td>
      <td>437.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>37.000000</td>
      <td>2102.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>I want an idea for how likely players are to hit into errors.</p>

<p>{% codeblock lang:python %}
TOTALS = GROUPED_DF.agg({“errors”: “sum”, “bip”: “sum”})
ERROR_RATE = TOTALS[“errors”] / TOTALS[“bip”]
ERROR_RATE
{% endcodeblock %}</p>

<pre><code>0.011801960251664112
</code></pre>

<p>Again, errors are very rare, so I want know how many “trials” (BIP) I need for a reasonable estimate of how likely each player is to hit into an error.</p>

<p>I’d like the majority of players to have at least 5 errors. I can estimate how many BIP that would require.</p>

<p>{% codeblock lang:python %}
5. /ERROR_RATE
{% endcodeblock %}</p>

<pre><code>423.65843413978496
</code></pre>

<p>Looks like I should require at least 425 BIP for each player. I round this to 500.</p>

<p>{% codeblock lang:python %}
GROUPED_DF = GROUPED_DF[GROUPED_DF[“bip”] &gt; 500]
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
GROUPED_DF = GROUPED_DF.reset_index(drop=True)
{% endcodeblock %}</p>

<p>{% codeblock lang:python %}
GROUPED_DF.head()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>abrej003</td>
      <td>Jose Abreu</td>
      <td>20</td>
      <td>1864</td>
    </tr>
    <tr>
      <th>1</th>
      <td>adamm002</td>
      <td>Matt Adams</td>
      <td>6</td>
      <td>834</td>
    </tr>
    <tr>
      <th>2</th>
      <td>adrie001</td>
      <td>Ehire Adrianza</td>
      <td>2</td>
      <td>533</td>
    </tr>
    <tr>
      <th>3</th>
      <td>aguij001</td>
      <td>Jesus Aguilar</td>
      <td>2</td>
      <td>551</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ahmen001</td>
      <td>Nick Ahmed</td>
      <td>12</td>
      <td>1101</td>
    </tr>
  </tbody>
</table>
</div>

<p>{% codeblock lang:python %}
GROUPED_DF.describe()
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>errors</th>
      <th>bip</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>354.000000</td>
      <td>354.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>12.991525</td>
      <td>1129.059322</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.447648</td>
      <td>428.485467</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>503.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>8.000000</td>
      <td>747.250000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>12.000000</td>
      <td>1112.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>17.000000</td>
      <td>1475.750000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>37.000000</td>
      <td>2102.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>I’ve identified 354 players who have enough BIP for me to estimate how frequently they hit into errors.</p>

<p>Below, I plot how the likelihood of hitting into errors is distributed.</p>

<p>{% codeblock lang:python %}
%matplotlib inline</p>

<p>GROUPED_DF[“prop_error”] = GROUPED_DF[“errors”] / GROUPED_DF[“bip”]
GROUPED_DF[“prop_error”].hist();
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/error_dist.png" /></p>

<p>The question is whether someone who has hit into errors in 2% of their BIP is more likely to hit into an error than someone who has hit into errors in 0.5% of their BIP (or is this all just random variation).</p>

<p>To try and estimate this, I treat each BIP as a Bernoulli trial. Hitting into an error is a “success”. I use a Binomial distribution to model the number of “successes”. I would like to know if different players are more or less likely to hit into errors. To do this, I model each player as having their own Binomial distribution and ask whether <em>p</em> (the probability of success) differs across players.</p>

<p>To answer this question, I could use a <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html#scipy.stats.chi2_contingency">chi square contingency test</a> but this would only tell me whether players differ at all and not which players differ.</p>

<p>The traditional way to identify which players differ is to do pairwise comparisons, but this would result in TONS of comparisons making <a href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem">false positives all but certain</a>.</p>

<p>Another option is to harness Bayesian statistics and build a <a href="http://sl8r000.github.io/ab_testing_statistics/use_a_hierarchical_model/">Hierarchical Beta-Binomial model</a>. The intuition is that each player’s probability of hitting into an error is drawn from a <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a>. I want to know whether these Beta distributions are different. I then assume I can best estimate a player’s Beta distribution by using that particular player’s data AND data from all players together.</p>

<p>The model is built so that as I accrue data about a particular player, I will trust that data more and more, relying less and less on data from all players. This is called partial pooling. <a href="https://dsaber.com/2016/08/27/analyze-your-experiment-with-a-multilevel-logistic-regression-using-pymc3%E2%80%8B/">Here’s</a> a useful explanation.</p>

<p>I largely based my analysis on <a href="https://docs.pymc.io/notebooks/hierarchical_partial_pooling.html">this</a> tutorial. Reference the tutorial for an explanation of how I choose my priors. I ended up using a greater lambda value (because the model sampled better) in the Exponential prior, and while this did lead to more extreme estimates of error likelihood, it didn’t change the basic story.</p>

<p>{% codeblock lang:python %}
import pymc3 as pm
import numpy as np
import theano.tensor as tt</p>

<p>with pm.Model() as model:</p>

<pre><code>phi = pm.Uniform('phi', lower=0.0, upper=1.0)

kappa_log = pm.Exponential('kappa_log', lam=25.)
kappa = pm.Deterministic('kappa', tt.exp(kappa_log))

rates = pm.Beta('rates', alpha=phi*kappa, beta=(1.0-phi)*kappa, shape=len(GROUPED_DF))

trials = np.array(GROUPED_DF["bip"])
successes = np.array(GROUPED_DF["errors"])
 
obs = pm.Binomial('observed_values', trials, rates, observed=successes)
trace = pm.sample(2000, tune=1000, chains=2, cores=2, nuts_kwargs={'target_accept': .95}) {% endcodeblock %}

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [rates, kappa_log, phi]
Sampling 2 chains: 100%|██████████| 6000/6000 [01:47&lt;00:00, 28.06draws/s] 
</code></pre>

<p>Check whether the model converged.</p>

<p>{% codeblock lang:python %}
max(np.max(score) for score in pm.gelman_rubin(trace).values())
{% endcodeblock %}</p>

<pre><code>1.0022635936332533
</code></pre>

<p>{% codeblock lang:python %}
bfmi = pm.bfmi(trace)
max_gr = max(np.max(gr_stats) for gr_stats in pm.gelman_rubin(trace).values())
(pm.energyplot(trace, figsize=(6, 4)).set_title(“BFMI = {}\nGelman-Rubin = {}”.format(bfmi, max_gr)));
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/energy.png" /></p>

<p>The most challenging parameter to fit is <em>kappa</em> which modulates for the variance in the likelihood to hit into an error. I take a look at it to make sure things look as expected.</p>

<p>{% codeblock lang:python %}
pm.summary(trace, varnames=[“kappa”])
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>mc_error</th>
      <th>hpd_2.5</th>
      <th>hpd_97.5</th>
      <th>n_eff</th>
      <th>Rhat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>kappa</th>
      <td>927.587178</td>
      <td>141.027597</td>
      <td>4.373954</td>
      <td>657.066554</td>
      <td>1201.922608</td>
      <td>980.288914</td>
      <td>1.000013</td>
    </tr>
  </tbody>
</table>
</div>

<p>{% codeblock lang:python %}
pm.traceplot(trace, varnames=[‘kappa’]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/kappa.png" /></p>

<p>I can also look at <em>phi</em>, the estimated global likelihood to hit into an error.</p>

<p>{% codeblock lang:python %}
pm.traceplot(trace, varnames=[‘phi’]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/phi.png" /></p>

<p>Finally, I can look at how all players vary in their likelihood to hit into an error.</p>

<p>{% codeblock lang:python %}
pm.traceplot(trace, varnames=[‘rates’]);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/rate_trace.png" /></p>

<p>Obviously, the above plot is a lot to look at it, so let’s order players by how likely the model believes they are to hit in an error.</p>

<p>{% codeblock lang:python %}
from matplotlib import pyplot as plt</p>

<p>rate_means = trace[‘rates’, 1000:].mean(axis=0)
rate_se = trace[‘rates’, 1000:].std(axis=0)</p>

<p>mean_se = [(x, y, i) for i, x, y in zip(GROUPED_DF.index, rate_means, rate_se)]
sorted_means_se = sorted(mean_se, key=lambda x: x[0])
sorted_means = [x[0] for x in sorted_means_se]
sorted_se = [x[1] for x in sorted_means_se]</p>

<p>x = np.arange(len(sorted_means))</p>

<p>plt.plot(x, sorted_means, ‘o’, alpha=0.25);</p>

<p>for x_val, m, se in zip(x, sorted_means, sorted_se):
    plt.plot([x_val, x_val], [m-se, m+se], ‘b-‘, alpha=0.5)
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/players_ranked.png" /></p>

<p>Now, the ten players who are most likely to hit into an error.</p>

<p>{% codeblock lang:python %}
estimated_mean = pm.summary(trace, varnames=[“rates”]).iloc[[x[2] for x in sorted_means_se[-10:]]][“mean”]</p>

<p>GROUPED_DF.loc[[x[2] for x in sorted_means_se[-10:]], :].assign(estimated_mean=estimated_mean.values).iloc[::-1]
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
      <th>prop_error</th>
      <th>estimated_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>71</th>
      <td>corrc001</td>
      <td>Carlos Correa</td>
      <td>30</td>
      <td>1368</td>
      <td>0.021930</td>
      <td>0.017838</td>
    </tr>
    <tr>
      <th>227</th>
      <td>myerw001</td>
      <td>Wil Myers</td>
      <td>27</td>
      <td>1214</td>
      <td>0.022241</td>
      <td>0.017724</td>
    </tr>
    <tr>
      <th>15</th>
      <td>andre001</td>
      <td>Elvis Andrus</td>
      <td>37</td>
      <td>1825</td>
      <td>0.020274</td>
      <td>0.017420</td>
    </tr>
    <tr>
      <th>258</th>
      <td>plawk001</td>
      <td>Kevin Plawecki</td>
      <td>14</td>
      <td>528</td>
      <td>0.026515</td>
      <td>0.017200</td>
    </tr>
    <tr>
      <th>285</th>
      <td>rojam002</td>
      <td>Miguel Rojas</td>
      <td>21</td>
      <td>952</td>
      <td>0.022059</td>
      <td>0.017001</td>
    </tr>
    <tr>
      <th>118</th>
      <td>garca003</td>
      <td>Avisail Garcia</td>
      <td>28</td>
      <td>1371</td>
      <td>0.020423</td>
      <td>0.016920</td>
    </tr>
    <tr>
      <th>244</th>
      <td>pench001</td>
      <td>Hunter Pence</td>
      <td>22</td>
      <td>1026</td>
      <td>0.021442</td>
      <td>0.016875</td>
    </tr>
    <tr>
      <th>20</th>
      <td>baezj001</td>
      <td>Javier Baez</td>
      <td>23</td>
      <td>1129</td>
      <td>0.020372</td>
      <td>0.016443</td>
    </tr>
    <tr>
      <th>335</th>
      <td>turnt001</td>
      <td>Trea Turner</td>
      <td>23</td>
      <td>1140</td>
      <td>0.020175</td>
      <td>0.016372</td>
    </tr>
    <tr>
      <th>50</th>
      <td>cainl001</td>
      <td>Lorenzo Cain</td>
      <td>32</td>
      <td>1695</td>
      <td>0.018879</td>
      <td>0.016332</td>
    </tr>
  </tbody>
</table>
</div>

<p>And the 10 players who are least likely to hit in an error.</p>

<p>{% codeblock lang:python %}
estimated_mean = pm.summary(trace, varnames=[“rates”]).iloc[[x[2] for x in sorted_means_se[:10]]][“mean”]</p>

<p>GROUPED_DF.loc[[x[2] for x in sorted_means_se[:10]], :].assign(estimated_mean=estimated_mean.values)
{% endcodeblock %}</p>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>playerid</th>
      <th>player_name</th>
      <th>errors</th>
      <th>bip</th>
      <th>prop_error</th>
      <th>estimated_mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>226</th>
      <td>murpd006</td>
      <td>Daniel Murphy</td>
      <td>4</td>
      <td>1680</td>
      <td>0.002381</td>
      <td>0.005670</td>
    </tr>
    <tr>
      <th>223</th>
      <td>morrl001</td>
      <td>Logan Morrison</td>
      <td>4</td>
      <td>1241</td>
      <td>0.003223</td>
      <td>0.006832</td>
    </tr>
    <tr>
      <th>343</th>
      <td>vottj001</td>
      <td>Joey Votto</td>
      <td>8</td>
      <td>1724</td>
      <td>0.004640</td>
      <td>0.007112</td>
    </tr>
    <tr>
      <th>239</th>
      <td>panij002</td>
      <td>Joe Panik</td>
      <td>7</td>
      <td>1542</td>
      <td>0.004540</td>
      <td>0.007245</td>
    </tr>
    <tr>
      <th>51</th>
      <td>calhk001</td>
      <td>Kole Calhoun</td>
      <td>9</td>
      <td>1735</td>
      <td>0.005187</td>
      <td>0.007413</td>
    </tr>
    <tr>
      <th>55</th>
      <td>carpm002</td>
      <td>Matt Carpenter</td>
      <td>8</td>
      <td>1566</td>
      <td>0.005109</td>
      <td>0.007534</td>
    </tr>
    <tr>
      <th>142</th>
      <td>hamib001</td>
      <td>Billy Hamilton</td>
      <td>8</td>
      <td>1476</td>
      <td>0.005420</td>
      <td>0.007822</td>
    </tr>
    <tr>
      <th>289</th>
      <td>rosae001</td>
      <td>Eddie Rosario</td>
      <td>8</td>
      <td>1470</td>
      <td>0.005442</td>
      <td>0.007855</td>
    </tr>
    <tr>
      <th>275</th>
      <td>renda001</td>
      <td>Anthony Rendon</td>
      <td>9</td>
      <td>1564</td>
      <td>0.005754</td>
      <td>0.007966</td>
    </tr>
    <tr>
      <th>8</th>
      <td>alony001</td>
      <td>Yonder Alonso</td>
      <td>8</td>
      <td>1440</td>
      <td>0.005556</td>
      <td>0.008011</td>
    </tr>
  </tbody>
</table>
</div>

<p>It looks to me like players who hit more ground balls are more likely to hit into an error than players who predominately hits fly balls and line-drives. This makes sense since infielders make more errors than outfielders.</p>

<p>Using the posterior distribution of estimated likelihoods to hit into an error, I can assign a probability to whether Carlos Correa is more likely to hit into an error than Daniel Murphy.</p>

<p>{% codeblock lang:python %}
np.mean(trace[‘rates’, 1000:][:, 71] &lt;= trace[‘rates’, 1000:][:, 226])
{% endcodeblock %}</p>

<pre><code>0.0
</code></pre>

<p>The model believes Correa is much more likely to hit into an error than Murphy!</p>

<p>I can also plot these players’ posterior distributions.</p>

<p>{% codeblock lang:python %}
import seaborn as sns</p>

<p>sns.kdeplot(trace[‘rates’, 1000:][:, 226], shade=True, label=”Daniel Murphy”);
sns.kdeplot(trace[‘rates’, 1000:][:, 71], shade=True, label=”Carlos Correa”);
sns.kdeplot(trace[‘rates’, 1000:].flatten(), shade=True, label=”Overall”);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/play_comparison.png" /></p>

<p>Finally, I can look exclusively at how the posterior distributions of the ten most likely and 10 least likely players to hit into an error compare.</p>

<p>{% codeblock lang:python %}
sns.kdeplot(trace[‘rates’, 1000:][:, [x[2] for x in sorted_means_se[-10:]]].flatten(), shade=True, label=”10 Least Likely”);
sns.kdeplot(trace[‘rates’, 1000:][:, [x[2] for x in sorted_means_se[:10]]].flatten(), shade=True, label=”10 Most Likely”);
{% endcodeblock %}</p>

<p><img src="{{ root_url }}/images/mlb/top10.png" /></p>

<p>All in all, this analysis makes it obvious that some players are more likely to hit into errors than other players. This is probably driven by how often players hit ground balls.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing Predeval]]></title>
    <link href="https://danvatterott.com/blog/2019/01/29/introducing-predeval/"/>
    <updated>2019-01-29T20:27:57-06:00</updated>
    <id>https://danvatterott.com/blog/2019/01/29/introducing-predeval</id>
    <content type="html"><![CDATA[<p><a href="https://predeval.readthedocs.io/en/latest/">Predeval</a> is software designed to help you identify changes in a model’s output.</p>

<p>For instance, you might be tasked with building a model to predict churn. When you deploy this model in production, you have to wait to learn which users churned in order to know how your model performed. While Predeval will not free you from this wait, it can provide initial signals as to whether the model is producing reasonable (i.e., expected) predictions. Unexpected predictions <em>might</em> reflect a poor performing model. They also <em>might</em> reflect a change in your input data. Either way, something has changed and you will want to investigate further.</p>

<p>Using predeval, you can detect changes in model output ASAP. You can then use python’s libraries to build a surrounding alerting system that will signal a need to investigate. This system should give you additional confidence that your model is performing reasonably. Here’s a <a href="https://danvatterott.com/blog/2018/06/02/random-weekly-reminders/">post</a> where I configure an alerting system using python, mailutils, and postfix (although the alerting system is not built around predeval).</p>

<p>Predeval operates by forming expectations about what your model’s outputs will look like. For example, you might give predeval the model’s output from a validation dataset. Predeval will then compare new outputs to the outputs produced by the validation dataset, and will report whether it detects a difference.</p>

<p>Predeval works with models producing both categorical and continuous outputs.</p>

<p>Here’s an <a href="https://predeval.readthedocs.io/en/latest/usage.html#categoricalevaluator">example</a> of predeval with a model producing categorical outputs. Predeval will (by default) check whether all expected output categories are present, and whether the output categories occur at their expected frequencies (using a <a href="https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.chi2_contingency.html">Chi-square test of independence of variables in a contingency table</a>).</p>

<p>Here’s an <a href="https://predeval.readthedocs.io/en/latest/usage.html#continuousevaluator">example</a> of predeval with a model producing continuous outputs. Predeval will (by default) check whether the new output have a minimum lower than expected, a maximum greater than expected, a different mean, a different standard deviation, and whether the new output are distributed as expected (using a <a href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ks_2samp.html#scipy.stats.ks_2samp">Kolmogorov-Smirnov test</a>)</p>

<p>I’ve tried to come up with reasonable defaults for determining whether data are different, but you can also <a href="https://predeval.readthedocs.io/en/latest/usage.html#updating-test-parameters">set these thresholds yourself</a>. You can also <a href="https://predeval.readthedocs.io/en/latest/usage.html#changing-evaluation-tests">choose what comparison tests to run</a> (e.g., checking the minimum, maximum etc.).</p>

<p>You will likely need to save your predeval objects so that you can apply them to future data. Here’s an <a href="https://predeval.readthedocs.io/en/latest/usage.html#saving-and-loading-your-evaluator">example</a> of saving the objects.</p>

<p>Documentation about how to install predeval can be found <a href="https://predeval.readthedocs.io/en/latest/installation.html#installation">here</a>.</p>

<p>If you have comments about improvements or would like to <a href="https://predeval.readthedocs.io/en/latest/contributing.html">contribute</a>, please reach out!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Looking Towards the Future of Automated Machine-learning]]></title>
    <link href="https://danvatterott.com/blog/2018/11/03/looking-towards-the-future-of-automated-machine-learning/"/>
    <updated>2018-11-03T08:27:07-05:00</updated>
    <id>https://danvatterott.com/blog/2018/11/03/looking-towards-the-future-of-automated-machine-learning</id>
    <content type="html"><![CDATA[<p>I recently gave a <a href="https://vencafstl.org/event/where-automated-machine-learning-fits-in-your-data-science-toolbox-prepare-ai">presentation</a> at <a href="https://vencafstl.org/">Venture Cafe</a> describing how I see automation changing python, machine-learning workflows in the near future.</p>

<p>In this post, I highlight the presentation’s main points. You can find the slides <a href="https://danvatterott.com/presentations/automation_presentation/">here</a>.</p>

<p>From <a href="https://en.wikipedia.org/wiki/Ray_Kurzweil">Ray Kurzweil’s</a> excitement about a <a href="https://en.wikipedia.org/wiki/Technological_singularity">technological singularity</a> to Elon Musk’s warnings about an <a href="https://www.vanityfair.com/news/2017/03/elon-musk-billion-dollar-crusade-to-stop-ai-space-x">A.I. Apocalypse</a>, automated machine-learning evokes strong feelings. Neither of these futures will be true in the near-term, but where will automation fit in your machine-learning workflows?</p>

<p>Our existing machine-learning workflows might look a little like the following (please forgive the drastic oversimplification of a purely sequential progression across stages!).</p>

<p><img src="{{ root_url }}/presentations/automation_presentation/slides/data_science_pipeline/ds_pipeline.png" style="background-color:white;" /></p>

<p>Where does automation exist in this workflow? Where can automation improve this workflow?</p>

<p>Not all these stages are within the scope of machine-learning. For instance, while you should automate gathering data, I view this as a data engineering problem. In the image below, I depict the stages that I consider ripe for automation, and the stages I consider wrong for automation. For example, data cleaning is too idiosyncratic to each dataset for true automation. I “X” out model evaluation as wrong for automation. In retrospect, I believe this is a great place for automation, but I don’t know of any existing python packages handling it.</p>

<p><img src="{{ root_url }}/presentations/automation_presentation/slides/libraries_pipeline/tpot_pipeline.png" style="background-color:white;" /></p>

<p>I depict feature engineering and model selection as the most promising areas for automation. I consider feature engineering as the stage where advances in automation can have the largest impact on your model performance. In the presentation, I include a <a href="https://www.quora.com/What-generally-improves-a-models-score-more-on-average-feature-engineering-or-hyperparameter-tuning">strong quote</a> from a Quora user saying that <a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization">hyper-parameter tuning</a> (a part of model selection) “hardly matters at all.” I agree with the sentiment of this quote, but it’s not true. Choosing roughly the correct hyper-parameter values is <em>VERY</em> important, and choosing the very best hyper-parameter values can be equally important depending on how your model is used. I highlight feature engineering over model selection because automated model selection is largely solved. For example <a href="http://scikit-learn.org/stable/modules/grid_search.html">grid-search</a> automates model selection. It’s not a fast solution, but given infinite time, it will find the best hyper-parameter values!</p>

<p>There are many python libraries automating these parts of the workflow. I highlight three libraries that automate feature engineering.</p>

<p><img src="{{ root_url }}/presentations/automation_presentation/slides/feature_automation/tpot-logo.jpg" width="200" style="background-color:white;" /></p>

<p>The first is <a href="https://github.com/EpistasisLab/tpot">teapot</a>. Teapot (more or less) takes all the different operations and models available in <a href="http://scikit-learn.org/stable/">scikit-learn</a>, and allows you to assemble these operations into a pipeline. Many of these operations (e.g., <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a>) are forms of feature engineering. Teapot measures which operations lead to the best model performance. Because Teapot enables users to assemble <em>SO MANY</em> different operations, it utilizes a <a href="https://en.wikipedia.org/wiki/Genetic_algorithm">genetic search algorithm</a> to search through the different possibilities more efficiently than grid-search would.</p>

<p>The second is <a href="https://github.com/ClimbsRocks/auto_ml">auto_ml</a>. In auto_ml users simply pass a dataset to the software and it will do model selection and hyper-parameter tuning for you. Users can also <a href="https://auto-ml.readthedocs.io/en/latest/deep_learning.html#feature-learning">ask the software to train a deep learning model that will learn new features</a> from your dataset. The authors claim this approach can improve model accuracy by 5%.</p>

<p><img src="{{ root_url }}/presentations/automation_presentation/slides/feature_automation/featuretools.png" width="400" style="background-color:white;" /></p>

<p>The third is <a href="https://github.com/Featuretools/featuretools">feature tools</a>. Feature Tools is the piece of automation software whose future I am most excited about. I find this software exciting because users can feed it pre-aggregated data. Most machine-learning models expect that for each value of the <a href="https://www.quora.com/What-is-a-response-variable-in-statistics">response variable</a>, you supply a vector of explanatory variables. This is an example of aggregated data. Teapot and auto_ml both expect users to supply aggregated data. Lots of important information is lost in the aggregation process, and allowing automation to thoroughly explore different aggregations will lead to predictive features that we would not have created otherwise (any many believe this is why deep learning is so effective). Feature tools explores different aggregations all while creating easily interpreted variables (in contrast to deep learning). While I am excited about the future of feature tools, it is a new piece of software and has a ways to go before I use it in my workflows. Like most automation machine-learning software it’s very slow/resource intensive. Also, the software is not very intuitive. That said, I created a <a href="https://mybinder.org/v2/gh/dvatterott/explore_feature_automation/master">binder notebook</a> demoing feature tools, so check it out yourself!</p>

<p>We should always keep in mind the possible dangers of automation and machine-learning. Removing humans from decisions accentuates biases baked into data and algorithms. These accentuated biases can have dangerous effects. We should carefully choose which decisions we’re comfortable automating and what safeguards to build around these decisions. Check out <a href="https://en.wikipedia.org/wiki/Cathy_O%27Neil">Cathy O’Neil’s</a> amazing <a href="https://en.wikipedia.org/wiki/Weapons_of_Math_Destruction">Weapons for Math Destruction</a> for an excellent treatment of the topic.</p>

<p>This post makes no attempt to give an exhaustive view of automated machine-learning. This is my single view point on where I think automated machine-learning can have an impact on your python workflows in the near-term. For a more thorough view of automated machine-learning, check out this <a href="https://twitter.com/randal_olson/status/992105498894831616">presentation</a> by <a href="http://www.randalolson.com/">Randy Olson</a> (the creator of teapot).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Custom Email Alerts in Airflow]]></title>
    <link href="https://danvatterott.com/blog/2018/08/29/custom-email-alerts-in-airflow/"/>
    <updated>2018-08-29T18:19:42-05:00</updated>
    <id>https://danvatterott.com/blog/2018/08/29/custom-email-alerts-in-airflow</id>
    <content type="html"><![CDATA[<p><a href="https://airflow.apache.org/">Apache Airflow</a> is great for coordinating automated jobs, and it provides a simple interface for sending email alerts when these jobs fail. Typically, one can request these emails by setting <code>email_on_failure</code> to <code>True</code> in your operators.</p>

<p>These email alerts work great, but I wanted to include additional links in them (I wanted to include a link to my spark cluster which can be grabbed from the <a href="https://airflow.incubator.apache.org/_modules/airflow/contrib/operators/databricks_operator.html#DatabricksSubmitRunOperator">Databricks Operator</a>). Here’s how I created a custom email alert on job failure.</p>

<p>First, I set <code>email_on_failure</code> to <code>False</code> and use the operators’s <code>on_failure_callback</code>. I give <code>on_failure_callback</code> the function described below.</p>

<p>{% codeblock lang:python %}
from airflow.utils.email import send_email</p>

<p>def notify_email(contextDict, **kwargs):
    “"”Send custom email alerts.”””</p>

<pre><code># email title.
title = "Airflow alert: {task_name} Failed".format(**contextDict)

# email contents
body = """
Hi Everyone, &lt;br&gt;
&lt;br&gt;
There's been an error in the {task_name} job.&lt;br&gt;
&lt;br&gt;
Forever yours,&lt;br&gt;
Airflow bot &lt;br&gt;
""".format(**contextDict)

send_email('you_email@address.com', title, body) {% endcodeblock %}
</code></pre>

<p><code>send_email</code> is a function imported from Airflow. <code>contextDict</code> is a dictionary given to the callback function on error. Importantly, <code>contextDict</code> contains lots of relevant information. This includes the Task Instance (key=’ti’) and Operator Instance (key=’task’) associated with your error. I was able to use the Operator Instance, to grab the relevant cluster’s address and I included this address in my email (this exact code is not present here).</p>

<p>To use the <code>notify_email</code>, I set <code>on_failure_callback</code> equal to <code>notify_email</code>.</p>

<p>I write out a short example airflow dag below.</p>

<p>{% codeblock lang:python %}
from airflow.models import DAG
from airflow.operators import PythonOperator
from airflow.utils.dates import days_ago</p>

<p>args = {
  ‘owner’: ‘me’,
  ‘description’: ‘my_example’,
  ‘start_date’: days_ago(1)
}</p>

<h1 id="run-every-day-at-1205-utc">run every day at 12:05 UTC</h1>
<p>dag = DAG(dag_id=’example_dag’, default_args=args, schedule_interval=’0 5 * * *’)</p>

<p>def print_hello():
  return ‘hello!’</p>

<p>py_task = PythonOperator(task_id=’example’,
                         python_callable=print_hello,
                         on_failure_callback=notify_email,
                         dag=dag)</p>

<p>py_task
{% endcodeblock %}</p>

<p>Note where set <code>on_failure_callback</code> equal to <code>notify_email</code> in the <code>PythonOperator</code>.</p>

<p>Hope you find this helpful! Don’t hesitate to reach out if you have a question.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Integrating Apache Airflow and Databricks]]></title>
    <link href="https://danvatterott.com/blog/2018/06/13/integrating-apache-airflow-and-databricks/"/>
    <updated>2018-06-13T18:05:52-05:00</updated>
    <id>https://danvatterott.com/blog/2018/06/13/integrating-apache-airflow-and-databricks</id>
    <content type="html"><![CDATA[<p>Cron is great for automation, but when tasks begin to rely on each other (task C can only run after both tasks A and B finish) cron does not do the trick.</p>

<p><a href="https://airflow.apache.org/">Apache Airflow</a> is open source software (from airbnb) designed to handle the relationship between tasks. I recently setup an airflow server which coordinates automated jobs on <a href="https://databricks.com/">databricks</a> (great software for coordinating spark clusters). Connecting databricks and airflow ended up being a little trickier than it should have been, so I am writing this blog post as a resource to anyone else who attempts to do the same in the future.</p>

<p>For the most part I followed <a href="https://medium.com/a-r-g-o/installing-apache-airflow-on-ubuntu-aws-6ebac15db211">this tutorial from A-R-G-O</a> when setting up airflow. Databricks also has a decent <a href="https://docs.databricks.com/user-guide/dev-tools/data-pipelines.html">tutorial</a> on setting up airflow. The difficulty here is that the airflow software for talking to databricks clusters (DatabricksSubmitRunOperator) was not introduced into airflow until version 1.9 and the A-R-G-O tutorial uses airflow 1.8.</p>

<p>Airflow 1.9 uses Celery version &gt;= 4.0 (I ended up using Celery version 4.1.1). Airflow 1.8 requires Celery &lt; 4.0. In fact, the A-R-G-O tutorial notes that using Celery &gt;= 4.0 will result in the error:</p>

<p>{% codeblock %}
airflow worker: Received and deleted unknown message. Wrong destination?!?
{% endcodeblock %}</p>

<p>I can attest that this is true! If you use airflow 1.9 with Celery &lt; 4.0, everything might appear to work, but airflow will randomly stop scheduling jobs after awhile (check the airflow-scheduler logs if you run into this). You need to use Celery &gt;= 4.0! Preventing the Wrong destination error is easy, but the fix is hard to find (hence why I wrote this post).</p>

<p>After much ado, here’s the fix! If you follow the A-R-G-O tutorial, install airflow 1.9, celery &gt;=4.0 AND set broker_url in airflow.cfg as follows:</p>

<p>{% codeblock %}
broker_url = pyamqp://guest:guest@localhost:5672//
{% endcodeblock %}</p>

<p>Note that compared to the A-R-G-O tutorial, I am just adding “py” in front of amqp. Easy!</p>
]]></content>
  </entry>
  
</feed>
