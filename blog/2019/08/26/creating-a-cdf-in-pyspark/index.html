
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Creating a CDF in PySpark - Dan Vatterott</title>
  
  <meta name="author" content="Dan Vatterott">
  
  <meta name="description" content="CDFs are a useful tool for understanding your data. This tutorial will demonstrate how to create a CDF in PySpark. I start by creating normally &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://danvatterott.com/blog/2019/08/26/creating-a-cdf-in-pyspark/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Dan Vatterott" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<!--- MathJax Configuration -->
<script type="text/javascript"
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML">
</script>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-35559761-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Dan Vatterott</a></h1>
  
    <h2>Data Scientist</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://duckduckgo.com/" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="danvatterott.com">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/about-me/">About Me</a></li>
  <li><a href="/publications/">Publications</a></li>
  <li><a href="/resume/Vatterott_Resume.pdf">Resume</a></li>
  <li><a href="/my-reads/">My Reads</a></li>
  <li><a href="/presentations/">Presentations</a></li>
  <li><a href="/blog/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Creating a CDF in PySpark</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2019-08-26T19:36:15-05:00'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2019</span></span> <span class='time'>7:36 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><p><a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">CDFs</a> are a useful tool for understanding your data. This tutorial will demonstrate how to create a CDF in PySpark.</p>

<p>I start by creating normally distributed, fake data.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkContext</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pyspark.sql.window</span> <span class="kn">import</span> <span class="n">Window</span>
</span><span class="line">
</span><span class="line"><span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="s">&quot;local&quot;</span><span class="p">,</span> <span class="s">&quot;Example&quot;</span><span class="p">)</span>
</span><span class="line"><span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([(</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">),)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)])</span><span class="o">.</span><span class="n">toDF</span><span class="p">([</span><span class="s">&#39;X&#39;</span><span class="p">]))</span>
</span><span class="line"><span class="n">a</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>X</th>
 </tr>
 <tr>
   <td>1.3162087724709406</td>
 </tr>
 <tr>
   <td>-0.9226127327757598</td>
 </tr>
 <tr>
   <td>0.5388249247619141</td>
 </tr>
 <tr>
   <td>-0.38263792383896356</td>
 </tr>
 <tr>
   <td>0.20584675505779562</td>
 </tr>
</table>

<p>To create the CDF I need to use a <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Window">window</a> function to order the data. I can then use <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.percent_rank">percent_rank</a> to retrieve the percentile associated with each value.</p>

<p>The only trick here is I round the column of interest to make sure I donâ€™t retrieve too much data onto the master node (not a concern here, but always good to think about).</p>

<p>After rounding, I group by the variable of interest, again, to limit the amount of data returned.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">win</span> <span class="o">=</span> <span class="n">Window</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s">&#39;X&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span>
</span><span class="line">          <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;cumulative_probability&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">percent_rank</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
</span><span class="line">          <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
</span><span class="line">          <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">)</span>
</span><span class="line">          <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s">&quot;cumulative_probability&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&quot;cumulative_probability&quot;</span><span class="p">),</span><span class="n">F</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s">&#39;*&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&quot;my_count&quot;</span><span class="p">)))</span>
</span><span class="line">
</span><span class="line"><span class="n">output</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>X</th>
   <th>cumulative_probability</th>
   <th>my_count</th>
 </tr>
 <tr>
   <td>-3.5</td>
   <td>0.0</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-3.3</td>
   <td>0.001001001001001001</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-2.9</td>
   <td>0.002002002002002002</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-2.8</td>
   <td>0.003003003003003003</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-2.7</td>
   <td>0.004004004004004004</td>
   <td>1</td>
 </tr>
</table>

<p>A CDF should report the percent of data less than or <em>equal</em> to the specified value. The data returned above is the percent of data less than the specified value. We need to fix this by shifting the data up.</p>

<p>To shift the data, I will use the function, <a href="http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lead">lead</a>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span>
</span><span class="line">          <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&#39;cumulative_probability&#39;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">percent_rank</span><span class="p">()</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
</span><span class="line">          <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
</span><span class="line">          <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">)</span>
</span><span class="line">          <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s">&quot;cumulative_probability&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&quot;cumulative_probability&quot;</span><span class="p">),</span><span class="n">F</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="s">&#39;*&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s">&quot;my_count&quot;</span><span class="p">))</span>
</span><span class="line">          <span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&quot;cumulative_probability&quot;</span><span class="p">,</span> <span class="n">F</span><span class="o">.</span><span class="n">lead</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">col</span><span class="p">(</span><span class="s">&quot;cumulative_probability&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">over</span><span class="p">(</span><span class="n">win</span><span class="p">))</span>
</span><span class="line">          <span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;cumulative_probability&quot;</span><span class="p">]))</span>
</span><span class="line">
</span><span class="line"><span class="n">output</span><span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<table style="width:100%">
 <tr>
   <th>X</th>
   <th>cumulative_probability</th>
   <th>my_count</th>
 </tr>
 <tr>
   <td>-3.5</td>
   <td>0.001001001001001001</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-3.3</td>
   <td>0.002002002002002002</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-2.9</td>
   <td>0.003003003003003003</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-2.8</td>
   <td>0.004004004004004004</td>
   <td>1</td>
 </tr>
 <tr>
   <td>-2.7</td>
   <td>0.005005005005005005</td>
   <td>1</td>
 </tr>
</table>

<p>There we go! A CDF of the data! I hope you find this helpful!</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Dan Vatterott</span></span>

      




<time class='entry-date' datetime='2019-08-26T19:36:15-05:00'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2019</span></span> <span class='time'>7:36 pm</span></time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/data-science/'>data science</a>, <a class='category' href='/blog/categories/pyspark/'>pyspark</a>, <a class='category' href='/blog/categories/python/'>python</a>, <a class='category' href='/blog/categories/spark/'>spark</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2019/07/12/limiting-cardinality-with-a-pyspark-custom-transformer/" title="Previous Post: Limiting Cardinality with a PySpark Custom Transformer">&laquo; Limiting Cardinality with a PySpark Custom Transformer</a>
      
      
        <a class="basic-alignment right" href="/blog/2019/11/18/balancing-model-weights-in-pyspark/" title="Next Post: Balancing Model Weights in PySpark">Balancing Model Weights in PySpark &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
    <div id="social-icons">
        
  <span class="fa-stack fa-lg">
    <a href="mailto:dvatterott@gmail.com"><i class="fa fa-envelope fa-1x"></i></a>
  </span>

        
  <span class="fa-stack fa-lg">
    <a href="http://www.linkedin.com/in/dan-vatterott"><i class="fa fa-linkedin fa-1x"></i></a>
  </span>

        
  <span class="fa-stack fa-lg">
    <a href="https://twitter.com/dvatterott"><i class="fa fa-twitter fa-1x"></i></a>
  </span>

        
  <span class="fa-stack fa-lg">
    <a href="https://github.com/dvatterott"><i class="fa fa-github fa-1x"></i></a>
  </span>


        
  <span class="fa-stack fa-lg">
    <a href="https://scholar.google.com/citations?hl=en&user=-S7mhDQAAAAJ&hl"><i class="fa fa-graduation-cap fa-1x"></i></a>
  </span>

    </div>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2019/11/18/balancing-model-weights-in-pyspark/">Balancing Model Weights in PySpark</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/08/26/creating-a-cdf-in-pyspark/">Creating a CDF in PySpark</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/07/12/limiting-cardinality-with-a-pyspark-custom-transformer/">Limiting Cardinality With a PySpark Custom Transformer</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/06/04/are-some-mlb-players-more-likely-to-hit-into-errors-statistics/">Are Some MLB Players More Likely to Hit Into Errors: Statistics</a>
      </li>
    
      <li class="post">
        <a href="/blog/2019/05/19/data-science-lessons-learned-the-hard-way-coding/">Data Science Lessons Learned the Hard Way: Coding</a>
      </li>
    
  </ul>
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2020 - Dan Vatterott -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'danvatterott';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'https://danvatterott.com/blog/2019/08/26/creating-a-cdf-in-pyspark/';
        var disqus_url = 'https://danvatterott.com/blog/2019/08/26/creating-a-cdf-in-pyspark/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>











</body>
</html>
