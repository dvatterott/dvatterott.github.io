<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Revisiting NBA Career Predictions From Rookie Performance &mdash; Dan Vatterott</title>
  <meta name="author" content="Dan Vatterott">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://danvatterott.com/favicon.ico" rel="icon">

  <link href="https://danvatterott.com/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://danvatterott.com/">Dan Vatterott</a></h1>
    <h2>Data Scientist</h2>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
    <li><a href="/">Home</a></li>
    <li><a href="/about-me.html">About Me</a></li>
    <li><a href="/publications.html">Publications</a></li>
    <li><a href="/extra/Vatterott_Resume.pdf">Resume</a></li>
    <li><a href="/my-reads.html">My Reads</a></li>
    <li><a href="/blog.html">Blog</a></li>
    <li><a href="/archives.html">Archive</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Revisiting NBA Career Predictions From Rookie Performance</h1>
    <p class="meta">
<time datetime="2016-04-08T21:19:25-04:00" pubdate>Fri 08 April 2016</time>    </p>
</header>

  <div class="entry-content"><p>In this post I wanted to do a quick follow up to a previous post about <a href="http://www.danvatterott.com/predicting-career-performance-from-rookie-performance.html">predicting career nba performance from rookie year data</a>.</p>
<p>After my previous post, I started to get a little worried about my career prediction model. Specifically, I started to wonder about whether my model was <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">underfitting or overfitting the data</a>. Underfitting occurs when the model has too much "bias" and cannot accomodate the data's shape. <a href="https://en.wikipedia.org/wiki/Overfitting">Overfitting</a> occurs when the model is too flexible and can account for all variance in a data set - even variance due to noise. In this post, I will quickly re-create my player prediction model, and investigate whether underfitting and overfitting are a problem.</p>
<p>Because this post largely repeats a previous one, I haven't written quite as much about the code. If you would like to read more about the code, see my previous posts.  </p>
<p>As usual, I will post all code as a jupyter notebook on my <a href="https://github.com/dvatterott/jupyter_notebooks/blob/master/nba_rookie_regression2.ipynb">github</a>.</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="c1">#import some libraries and tell ipython we want inline figures rather than interactive figures.</span>
<span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span><span class="o">,</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span><span class="o">,</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span><span class="o">,</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpl</span>

<span class="w"> </span><span class="kn">from</span><span class="w"> </span><span class="nn">__future__</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">print_function</span>

<span class="w"> </span><span class="o">%</span><span class="n">matplotlib</span><span class="w"> </span><span class="n">inline</span>
<span class="w"> </span><span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">mpl_style</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;default&#39;</span><span class="w"> </span><span class="c1">#load matplotlib for plotting</span>
<span class="w"> </span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span><span class="w"> </span><span class="c1">#im addicted to ggplot. so pretty.</span>
<span class="w"> </span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s1">&#39;Bitstream Vera Sans&#39;</span><span class="p">]</span>
</code></pre></div>

<p>Load the data. Reminder - this data is still available on my <a href="https://github.com/dvatterott/nba_project">github</a>.</p>
<div class="highlight"><pre><span></span><code> rookie_df = pd.read_pickle(&#39;nba_bballref_rookie_stats_2016_Mar_15.pkl&#39;) #here&#39;s the rookie year data

 rook_games = rookie_df[&#39;Career Games&#39;]&gt;50
 rook_year = rookie_df[&#39;Year&#39;]&gt;1980

 #remove rookies from before 1980 and who have played less than 50 games. I also remove some features that seem irrelevant or unfair
 rookie_df_games = rookie_df[rook_games &amp; rook_year] #only players with more than 50 games.
 rookie_df_drop = rookie_df_games.drop([&#39;Year&#39;,&#39;Career Games&#39;,&#39;Name&#39;],1)
</code></pre></div>

<p>Load more data, and normalize it data for the <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA transformation</a>.</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">StandardScaler</span>

<span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s1">&#39;nba_bballref_career_stats_2016_Mar_15.pkl&#39;</span><span class="p">)</span>
<span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;G&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">50</span><span class="p">]</span>
<span class="w"> </span><span class="n">df_drop</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Year&#39;</span><span class="p">,</span><span class="s1">&#39;Name&#39;</span><span class="p">,</span><span class="s1">&#39;G&#39;</span><span class="p">,</span><span class="s1">&#39;GS&#39;</span><span class="p">,</span><span class="s1">&#39;MP&#39;</span><span class="p">,</span><span class="s1">&#39;FG&#39;</span><span class="p">,</span><span class="s1">&#39;FGA&#39;</span><span class="p">,</span><span class="s1">&#39;FG%&#39;</span><span class="p">,</span><span class="s1">&#39;3P&#39;</span><span class="p">,</span><span class="s1">&#39;2P&#39;</span><span class="p">,</span><span class="s1">&#39;FT&#39;</span><span class="p">,</span><span class="s1">&#39;TRB&#39;</span><span class="p">,</span><span class="s1">&#39;PTS&#39;</span><span class="p">,</span><span class="s1">&#39;ORtg&#39;</span><span class="p">,</span><span class="s1">&#39;DRtg&#39;</span><span class="p">,</span><span class="s1">&#39;PER&#39;</span><span class="p">,</span><span class="s1">&#39;TS%&#39;</span><span class="p">,</span><span class="s1">&#39;3PAr&#39;</span><span class="p">,</span><span class="s1">&#39;FTr&#39;</span><span class="p">,</span><span class="s1">&#39;ORB%&#39;</span><span class="p">,</span><span class="s1">&#39;DRB%&#39;</span><span class="p">,</span><span class="s1">&#39;TRB%&#39;</span><span class="p">,</span><span class="s1">&#39;AST%&#39;</span><span class="p">,</span><span class="s1">&#39;STL%&#39;</span><span class="p">,</span><span class="s1">&#39;BLK%&#39;</span><span class="p">,</span><span class="s1">&#39;TOV%&#39;</span><span class="p">,</span><span class="s1">&#39;USG%&#39;</span><span class="p">,</span><span class="s1">&#39;OWS&#39;</span><span class="p">,</span><span class="s1">&#39;DWS&#39;</span><span class="p">,</span><span class="s1">&#39;WS&#39;</span><span class="p">,</span><span class="s1">&#39;WS/48&#39;</span><span class="p">,</span><span class="s1">&#39;OBPM&#39;</span><span class="p">,</span><span class="s1">&#39;DBPM&#39;</span><span class="p">,</span><span class="s1">&#39;BPM&#39;</span><span class="p">,</span><span class="s1">&#39;VORP&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span>
<span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_drop</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span><span class="w"> </span><span class="c1">#take data out of dataframe</span>
<span class="w"> </span><span class="n">ScaleModel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ScaleModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div>

<p>Use <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-means</a> to group players according to their performance. See my post on <a href="http://www.danvatterott.com/blog/2016/02/21/grouping-nba-players/">grouping players</a> for more info.</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">PCA</span>
<span class="w"> </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">KMeans</span>

<span class="w"> </span><span class="n">reduced_model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="n">whiten</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="w"> </span><span class="n">reduced_data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">reduced_model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="c1">#transform data into the 5 PCA components space</span>
<span class="w"> </span><span class="n">final_fit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">reduced_data</span><span class="p">)</span><span class="w"> </span><span class="c1">#fit 6 clusters</span>
<span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="w"> </span><span class="c1">#label each data point with its clusters</span>
</code></pre></div>

<p>Run a separate regression on each group of players. I calculate mean absolute error (a variant of <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error</a>) for each model. I used mean absolute error because it's on the same scale as the data, and easier to interpret. I will use this later to evaluate just how accurate these models are. Quick reminder - I am trying to predict career WS/48 with MANY predictor variables from rookie year performance such rebounding and scoring statistics.</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>
<span class="w"> </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">mean_absolute_error</span><span class="w"> </span><span class="c1">#import function for calculating mean squared error.</span>

<span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rookie_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span><span class="w"> </span><span class="c1">#take data out of dataframe</span>

<span class="w"> </span><span class="n">cluster_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Year&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">1980</span><span class="p">][</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span>
<span class="w"> </span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cluster_labels</span><span class="w"> </span><span class="c1">#label each data point with its clusters</span>

<span class="w"> </span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">));</span>

<span class="w"> </span><span class="n">estHold</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[[],[],[],[],[],[]]</span>

<span class="w"> </span><span class="n">score</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[]</span>

<span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="n">group</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">)):</span>

<span class="w">     </span><span class="n">Grouper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="w"> </span><span class="c1">#do one regression at a time</span>
<span class="w">     </span><span class="n">Yearer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Year&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">1980</span>

<span class="w">     </span><span class="n">Group1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">Grouper</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Yearer</span><span class="p">]</span>
<span class="w">     </span><span class="n">Y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Group1</span><span class="p">[</span><span class="s1">&#39;WS/48&#39;</span><span class="p">]</span><span class="w"> </span><span class="c1">#get predictor data</span>

<span class="w">     </span><span class="n">Group1_rookie</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">]</span>
<span class="w">     </span><span class="n">Group1_rookie</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Group1_rookie</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="c1">#get predicted data</span>

<span class="w">     </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Group1_rookie</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span><span class="w"> </span><span class="c1">#take data out of dataframe</span>

<span class="w">     </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w">  </span><span class="c1"># Adds a constant term to the predictor</span>
<span class="w">     </span><span class="n">est</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="c1">#fit with linear regression model</span>
<span class="w">     </span><span class="n">est</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">est</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="w">     </span><span class="n">estHold</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">est</span>
<span class="w">     </span><span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span><span class="w"> </span><span class="c1">#calculate the mean squared error</span>
<span class="w">     </span><span class="c1">#print est.summary()</span>

<span class="w">     </span><span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="c1">#plot each regression&#39;s prediction against actual data</span>
<span class="w">     </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">est</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span><span class="n">Y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.color_cycle&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
<span class="w">     </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.01</span><span class="p">),</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="w">     </span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Group </span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="w">     </span><span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span><span class="s1">&#39;$r^2$=</span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">est</span><span class="o">.</span><span class="n">rsquared</span><span class="p">)</span>
<span class="w">     </span><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.25</span><span class="p">])</span>
<span class="w">     </span><span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.12</span><span class="p">,</span><span class="mf">0.25</span><span class="p">]);</span>
</code></pre></div>

<p><img src="https://danvatterott.com/images/regression2NBA/original_model.png" /></p>
<p>More quick reminders - predicted performances are on the Y-axis, actual performances are on the X-axis, and the red line is the <a href="https://en.wikipedia.org/wiki/Identity_line">identity line</a>. Thus far, everything has been exactly the same as my previous post (although my group labels are different).</p>
<p>I want to investigate whether the model is overfitting the data. If the data is overfitting the data, then the error should go up when training and testing with different datasets (because the model was fitting itself to noise and noise changes when the datasets change). To investigate whether the model overfits the data, I will evaluate whether the model "generalizes" via <a href="https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29">cross-validation</a>.</p>
<p>The reason I'm worried about overfitting is I used a LOT of predictors in these models and the number of predictors might have allowed the model the model to fit noise in the predictors.</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">LinearRegression</span><span class="w"> </span><span class="c1">#I am using sklearns linear regression because it plays well with their cross validation function</span>
<span class="w">          </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span><span class="w"> </span><span class="n">cross_validation</span><span class="w"> </span><span class="c1">#import the cross validation function</span>

<span class="w">          </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rookie_df</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span><span class="w"> </span><span class="c1">#take data out of dataframe</span>

<span class="w">          </span><span class="n">cluster_labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Year&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">1980</span><span class="p">][</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span>
<span class="w"> </span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cluster_labels</span><span class="w"> </span><span class="c1">#label each data point with its clusters</span>

<span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="n">group</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">final_fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">)):</span>

<span class="w"> </span><span class="n">Grouper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="w"> </span><span class="c1">#do one regression at a time</span>
<span class="w"> </span><span class="n">Yearer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Year&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">1980</span>

<span class="w"> </span><span class="n">Group1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">Grouper</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="n">Yearer</span><span class="p">]</span>
<span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Group1</span><span class="p">[</span><span class="s1">&#39;WS/48&#39;</span><span class="p">]</span><span class="w"> </span><span class="c1">#get predictor data</span>

<span class="w"> </span><span class="n">Group1_rookie</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="n">rookie_df_drop</span><span class="p">[</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">]</span><span class="o">==</span><span class="n">group</span><span class="p">]</span>
<span class="w"> </span><span class="n">Group1_rookie</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Group1_rookie</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;kmeans_label&#39;</span><span class="p">],</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="c1">#get predicted data</span>

<span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Group1_rookie</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span><span class="w"> </span><span class="c1">#take data out of dataframe    </span>
<span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w">  </span><span class="c1"># Adds a constant term to the predictor</span>

<span class="w"> </span><span class="n">est</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">LinearRegression</span><span class="p">()</span><span class="w"> </span><span class="c1">#fit with linear regression model</span>

<span class="w"> </span><span class="n">this_scores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cross_validation</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">est</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;mean_absolute_error&#39;</span><span class="p">)</span><span class="w"> </span><span class="c1">#find mean square error across different datasets via cross validations</span>
<span class="w"> </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Group &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
<span class="w"> </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Initial Mean Absolute Error: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">score</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">])</span>
<span class="w"> </span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cross Validation MAE: &#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">this_scores</span><span class="p">)))[</span><span class="mi">0</span><span class="p">:</span><span class="mi">6</span><span class="p">])</span><span class="w"> </span><span class="c1">#find the mean MSE across validations</span>

<span class="n">Group</span><span class="w"> </span><span class="mi">0</span>
<span class="n">Initial</span><span class="w"> </span><span class="n">Mean</span><span class="w"> </span><span class="n">Absolute</span><span class="w"> </span><span class="nb">Error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0161</span>
<span class="n">Cross</span><span class="w"> </span><span class="n">Validation</span><span class="w"> </span><span class="n">MAE</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0520</span>
<span class="n">Group</span><span class="w"> </span><span class="mi">1</span>
<span class="n">Initial</span><span class="w"> </span><span class="n">Mean</span><span class="w"> </span><span class="n">Absolute</span><span class="w"> </span><span class="nb">Error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0251</span>
<span class="n">Cross</span><span class="w"> </span><span class="n">Validation</span><span class="w"> </span><span class="n">MAE</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0767</span>
<span class="n">Group</span><span class="w"> </span><span class="mi">2</span>
<span class="n">Initial</span><span class="w"> </span><span class="n">Mean</span><span class="w"> </span><span class="n">Absolute</span><span class="w"> </span><span class="nb">Error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0202</span>
<span class="n">Cross</span><span class="w"> </span><span class="n">Validation</span><span class="w"> </span><span class="n">MAE</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0369</span>
<span class="n">Group</span><span class="w"> </span><span class="mi">3</span>
<span class="n">Initial</span><span class="w"> </span><span class="n">Mean</span><span class="w"> </span><span class="n">Absolute</span><span class="w"> </span><span class="nb">Error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0200</span>
<span class="n">Cross</span><span class="w"> </span><span class="n">Validation</span><span class="w"> </span><span class="n">MAE</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0263</span>
<span class="n">Group</span><span class="w"> </span><span class="mi">4</span>
<span class="n">Initial</span><span class="w"> </span><span class="n">Mean</span><span class="w"> </span><span class="n">Absolute</span><span class="w"> </span><span class="nb">Error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0206</span>
<span class="n">Cross</span><span class="w"> </span><span class="n">Validation</span><span class="w"> </span><span class="n">MAE</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0254</span>
<span class="n">Group</span><span class="w"> </span><span class="mi">5</span>
<span class="n">Initial</span><span class="w"> </span><span class="n">Mean</span><span class="w"> </span><span class="n">Absolute</span><span class="w"> </span><span class="nb">Error</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0244</span>
<span class="n">Cross</span><span class="w"> </span><span class="n">Validation</span><span class="w"> </span><span class="n">MAE</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0665</span>
</code></pre></div>

<p>Above I print out the model's initial mean absolute error and median absolute error when fitting cross-validated data.</p>
<p>The models definitely have more error when cross validated. The change in error is worse in some groups than others. For instance, error dramatically increases in Group 1. Keep in mind that the scoring measure here is mean absolute error, so error is in the same scale as WS/48. An average error of 0.04 in WS/48 is sizable, leaving me worried that the models overfit the data.</p>
<p>Unfortunately, Group 1 is the "scorers" group, so the group with most the interesting players is where the model fails most...</p>
<p>Next, I will look into whether my models underfit the data. I am worried that my models underfit the data because I used linear regression, which has very little flexibility. To investigate this, I will plot the <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">residuals</a> of each model. Residuals are the error between my model's prediction and the actual performance.</p>
<p>Linear regression assumes that residuals are uncorrelated and evenly distributed around 0. If this is not the case, then the linear regression is underfitting the data.</p>
<div class="highlight"><pre><span></span><code><span class="w"> </span><span class="n">#plot</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">residuals</span><span class="p">.</span><span class="w"> </span><span class="n">there</span><span class="s1">&#39;s obviously a problem with under/over prediction</span>

<span class="s1"> plt.figure(figsize=(8,6));</span>

<span class="s1"> for i,group in enumerate(np.unique(final_fit.labels_)):</span>

<span class="s1">     Grouper = df[&#39;</span><span class="n">kmeans_label</span><span class="s1">&#39;]==group #do one regression at a time</span>
<span class="s1">     Yearer = df[&#39;</span><span class="nf">Year</span><span class="s1">&#39;]&gt;1980</span>

<span class="s1">     Group1 = df[Grouper &amp; Yearer]</span>
<span class="s1">     Y = Group1[&#39;</span><span class="n">WS</span><span class="o">/</span><span class="mi">48</span><span class="s1">&#39;] #get predictor data</span>
<span class="s1">     resid = estHold[i].resid #extract residuals</span>

<span class="s1">     plt.subplot(3,2,i+1) #plot each regression&#39;</span><span class="n">s</span><span class="w"> </span><span class="n">prediction</span><span class="w"> </span><span class="n">against</span><span class="w"> </span><span class="n">actual</span><span class="w"> </span><span class="k">data</span>
<span class="w">     </span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">resid</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="o">[</span><span class="n">&#39;axes.color_cycle&#39;</span><span class="o">][</span><span class="n">i</span><span class="o">]</span><span class="p">)</span>
<span class="w">     </span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Group %d&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="w">     </span><span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="o">[</span><span class="n">0.0,0.12,0.25</span><span class="o">]</span><span class="p">)</span>
<span class="w">     </span><span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="o">[</span><span class="n">-0.1,0.0,0.1</span><span class="o">]</span><span class="p">);</span>
</code></pre></div>

<p><img src="https://danvatterott.com/images/regression2NBA/residuals.png" /></p>
<p>Residuals are on the Y-axis and career performances are on the X-axis. Negative residuals are over predictions (the player is worse than my model predicts) and postive residuals are under predictions (the player is better than my model predicts). I don't test this, but the residuals appear VERY correlated. That is, the model tends to over estimate bad players (players with WS/48 less than 0.0) and under estimate good players. Just to clarify, non-correlated residuals would have no apparent slope.</p>
<p>This means the model is making systematic errors and not fitting the actual shape of the data. I'm not going to say the model is damned, but this is an obvious sign that the model needs more flexibility.</p>
<p>No model is perfect, but this model definitely needs more work. I've been playing with more flexible models and will post these models here if they do a better job predicting player performance.</p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        Dan Vatterott
    </span>
  </span>
<time datetime="2016-04-08T21:19:25-04:00" pubdate>Fri 08 April 2016</time>  <span class="categories">
    <a class='category' href='https://danvatterott.com/category/nba.html'>nba</a>
  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">


<!-- <section> -->
    <section style="max-width: fit-content; margin-inline: auto;">

            <span class="fa-stack fa-lg">
                <a href="mailto:dvatterott@gmail.com"><i class="fa fa-envelope fa-1x"></i></a>
            </span>
            <span class="fa-stack fa-lg">
                <a href="http://www.linkedin.com/in/dan-vatterott"><i class="fa fa-linkedin fa-1x"></i></a>
            </span>

            <span class="fa-stack fa-lg">
                <a href="https://twitter.com/dvatterott"><i class="fa fa-twitter fa-1x"></i></a>
            </span>

            <span class="fa-stack fa-lg">
                <a href="https://github.com/dvatterott"><i class="fa fa-github fa-1x"></i></a>
            </span>
            <span class="fa-stack fa-lg">
                <a href="https://scholar.google.com/citations?hl=en&user=-S7mhDQAAAAJ&hl"><i class="fa fa-graduation-cap fa-1x"></i></a>
            </span>

            <!-- <h1>Social</h1>
                 <ul>
                 <li><a href="dvatterott@gmail.com" target="_blank">email</a></li>
                 <li><a href="http://www.linkedin.com/in/dan-vatterott" target="_blank">linkedin</a></li>
                 <li><a href="https://twitter.com/dvatterott" target="_blank">twitter</a></li>
                 <li><a href="https://github.com/dvatterott" target="_blank">github</a></li>
                 <li><a href="https://scholar.google.com/citations?hl=en&user=-S7mhDQAAAAJ&hl" target="_blank">google-scholar</a></li>


                 </ul> -->
    </section>


  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://danvatterott.com/modeling-the-relative-speed-of-hot-wheels-cars.html">Modeling the relative speed of Hot Wheels Cars</a>
      </li>
      <li class="post">
          <a href="https://danvatterott.com/data-onboarding-checklist.html">Data Onboarding Checklist</a>
      </li>
      <li class="post">
          <a href="https://danvatterott.com/posting-collections-as-hive-tables.html">Posting Collections as Hive Tables</a>
      </li>
      <li class="post">
          <a href="https://danvatterott.com/balancing-model-weights-in-pyspark.html">Balancing Model Weights in PySpark</a>
      </li>
      <li class="post">
          <a href="https://danvatterott.com/creating-a-cdf-in-pyspark.html">Creating a CDF in PySpark</a>
      </li>
    </ul>
  </section>
</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  Dan Vatterott &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="https://danvatterott.com/theme/js/modernizr-2.0.js"></script>
  <script src="https://danvatterott.com/theme/js/ender.js"></script>
  <script src="https://danvatterott.com/theme/js/octopress.js" type="text/javascript"></script>
  <script type="text/javascript">
    var disqus_shortname = 'danvatterott';
    var disqus_identifier = '/revisiting-nba-career-predictions-from-rookie-performance.html';
    var disqus_url = 'https://danvatterott.com/revisiting-nba-career-predictions-from-rookie-performance.html';
    var disqus_title = 'Revisiting NBA Career Predictions From Rookie Performance';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>